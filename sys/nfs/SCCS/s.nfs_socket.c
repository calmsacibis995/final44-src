h11979
s 00391/00187/01765
d D 8.5 95/03/30 11:26:49 mckusick 52 51
c massive update to incorporate version 3 protocol from Rick Macklem
e
s 00010/00022/01942
d D 8.4 94/08/18 23:33:45 mckusick 51 50
c conversion to queue.h list manipulation (from mycroft)
e
s 00001/00001/01963
d D 8.3 94/01/12 09:33:24 bostic 50 49
c lint
e
s 00002/00001/01962
d D 8.2 93/09/23 15:59:20 bostic 49 48
c changes for 4.4BSD-Lite requested by USL
e
s 00002/00002/01961
d D 8.1 93/06/16 17:29:57 bostic 48 47
c 4.4BSD snapshot (revision 8.1); add 1993 to copyright
e
s 00010/00008/01953
d D 7.44 93/06/16 17:15:17 mckusick 47 45
c fix for trashed TCP/IP connections from Macklem
e
s 00002/00002/01959
d R 8.1 93/06/10 23:39:01 bostic 46 45
c 4.4BSD snapshot (revision 8.1); add 1993 to copyright
e
s 00007/00001/01954
d D 7.43 93/04/27 16:31:20 mckusick 45 44
c bug fixes for LEASES from Rick Macklem
e
s 00026/00008/01929
d D 7.42 93/02/02 15:17:20 mckusick 44 43
c update for 4.4BSD from Rick Macklem
e
s 00005/00001/01932
d D 7.41 92/11/03 16:35:59 mckusick 43 42
c better fix for -r7.40 from Macklem
e
s 00006/00001/01927
d D 7.40 92/10/22 13:06:47 mckusick 42 40
c fix from Macklem for hanging UDP mounts after server death
e
s 00001/00001/01927
d R 7.40 92/10/22 12:38:30 mckusick 41 40
c maximum timeout backoff is 8 not 9 (from Jeff Forys)
e
s 00001/00000/01927
d D 7.39 92/10/11 12:35:09 bostic 40 39
c make kernel includes standard
e
s 00005/00002/01922
d D 7.38 92/09/30 16:03:44 mckusick 39 38
c September update from Rick Macklem to add accept protocol to NQMFS
e
s 00012/00038/01912
d D 7.37 92/09/16 18:23:36 mckusick 38 37
c update from Rick Macklem
e
s 00003/00001/01947
d D 7.36 92/07/12 22:32:38 mckusick 37 36
c lint
e
s 00001/00000/01947
d D 7.35 92/07/12 17:34:55 pendry 36 35
c need to include <sys/systm.h>
e
s 00001/00001/01946
d D 7.34 92/07/12 17:16:49 pendry 35 34
c MIN -> min, MAX -> max
e
s 00000/00001/01947
d D 7.33 92/07/10 00:42:35 mckusick 34 33
c eliminate random stuff
e
s 00023/00247/01925
d D 7.32 92/07/02 20:03:06 mckusick 33 32
c clean up includes; nfs_netaddr_match goes to vfs_addr.c;
c hang_addrlist and free_addrlist move to ufs_vfsops.c
e
s 00001/00001/02171
d D 7.31 92/07/02 17:53:12 mckusick 32 31
c end broken pipes after server reboot
e
s 00006/00001/02166
d D 7.30 92/05/11 18:14:10 mckusick 31 30
c sanity checks (from macklem)
e
s 00024/00001/02143
d D 7.29 92/03/17 17:08:06 mckusick 30 29
c if NFSMNT_RESVPORT used, allocate a reserved port
e
s 00001/00000/02143
d D 7.28 92/03/16 15:26:30 mckusick 29 28
c fix from Rick Macklem for multiple free's of NFSD structures
e
s 00017/00020/02126
d D 7.27 92/03/13 18:06:26 mckusick 28 27
c minor fixes from Macklem
e
s 00005/00000/02141
d D 7.26 92/03/13 17:33:34 mckusick 27 26
c have to set uio_procp for soreceive
e
s 00022/00018/02119
d D 7.25 92/03/09 22:27:35 mckusick 26 25
c first cut at fixing discconect/reconnect hanging confusion
e
s 01407/00657/00730
d D 7.24 92/01/14 12:41:31 mckusick 25 24
c update from Rick Macklem (including leases)
e
s 00014/00014/01373
d D 7.23 91/04/20 16:32:29 karels 24 23
c finish what I was doing when someone checked this in for me (half-done)
e
s 00054/00052/01333
d D 7.22 91/04/16 00:34:56 mckusick 23 22
c use u_long tl in place of u_long p
e
s 00062/00041/01323
d D 7.21 91/04/02 14:08:09 karels 22 21
c more precise logging; proper use of tprint
e
s 00010/00011/01354
d D 7.20 91/03/19 11:27:00 karels 21 20
c bigger buffers for tcp; purge user.h
e
s 00073/00066/01292
d D 7.19 90/10/01 14:13:10 mckusick 20 19
c add Rick Macklem's compressed NFS
e
s 00001/00011/01357
d D 7.18 90/06/28 21:52:19 bostic 19 18
c new copyright notice
e
s 00024/00034/01344
d D 7.17 90/06/21 11:17:34 mckusick 18 17
c "update from Rick Macklem"
e
s 00002/00001/01376
d D 7.16 90/06/08 15:31:18 mckusick 17 16
c have to set so to point to new socket
e
s 00008/00008/01369
d D 7.15 90/06/08 15:13:32 marc 16 15
c new parameter to tprintf
e
s 00002/00002/01375
d D 7.14 90/06/05 10:24:09 mckusick 15 14
c make the kernel self consistent
e
s 00012/00006/01365
d D 7.13 90/05/18 14:55:20 mckusick 14 13
c "nfs_mknod update from Rick Macklem"
e
s 00807/00567/00564
d D 7.12 90/05/14 11:43:12 mckusick 13 12
c "update from Rick Macklem adding TCP support to NFS"
e
s 00006/00006/01125
d D 7.11 90/05/04 20:52:33 mckusick 12 11
c mount structure prefixes go from m_ to mnt_ and M_ to MNT_
e
s 00005/00002/01126
d D 7.10 90/04/04 21:19:05 karels 11 10
c new sblock, sbwait (unwind on signal)
e
s 00001/00001/01127
d D 7.9 90/03/13 14:34:23 mckusick 10 9
c only interrupt for user requested signals
e
s 00005/00004/01123
d D 7.8 90/03/06 23:33:27 mckusick 9 8
c nm_host is now m_stat.f_mntfromname
e
s 00002/00002/01125
d D 7.7 90/03/06 17:25:48 sklower 8 7
c change in parameters to *_usrreq()
e
s 00569/00200/00558
d D 7.6 90/02/16 14:01:27 mckusick 7 6
c move socket dependent code entirely into this module;
c add TCP rrt and congestion avoidance algorithms (from tmt@osf.org)
e
s 00020/00005/00738
d D 7.5 89/12/20 18:09:26 mckusick 6 5
c "December update from Rick Macklem"
e
s 00024/00019/00719
d D 7.4 89/11/03 15:30:23 mckusick 5 4
c lint
e
s 00048/00031/00690
d D 7.3 89/10/19 22:34:36 mckusick 4 2
c "update from Rick Macklem"
e
s 00000/00000/00721
d R 7.3 89/08/30 20:30:02 macklem 3 2
c first buffer cache implementation; name cache usage; code cleanups
e
s 00004/00001/00717
d D 7.2 89/07/06 17:42:29 mckusick 2 1
c update of July 5th from Rick Macklem
e
s 00718/00000/00000
d D 7.1 89/07/05 11:32:24 mckusick 1 0
c first bootable NFS from Rick Macklem
e
u
U
t
T
I 1
/*
D 21
 * Copyright (c) 1989 The Regents of the University of California.
E 21
I 21
D 48
 * Copyright (c) 1989, 1991 The Regents of the University of California.
E 21
 * All rights reserved.
E 48
I 48
D 52
 * Copyright (c) 1989, 1991, 1993
E 52
I 52
 * Copyright (c) 1989, 1991, 1993, 1995
E 52
 *	The Regents of the University of California.  All rights reserved.
E 48
 *
 * This code is derived from software contributed to Berkeley by
 * Rick Macklem at The University of Guelph.
 *
D 19
 * Redistribution and use in source and binary forms are permitted
 * provided that the above copyright notice and this paragraph are
 * duplicated in all such forms and that any documentation,
 * advertising materials, and other materials related to such
 * distribution and use acknowledge that the software was developed
 * by the University of California, Berkeley.  The name of the
 * University may not be used to endorse or promote products derived
 * from this software without specific prior written permission.
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND WITHOUT ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.
E 19
I 19
 * %sccs.include.redist.c%
E 19
 *
 *	%W% (Berkeley) %G%
 */

/*
D 13
 * Socket operations for use by nfs (similar to uipc_socket.c, but never
 * with copies to/from a uio vector)
D 7
 * NB: For now, they only work for UDP datagram sockets.
E 7
I 7
 * NB: For now, they only work for datagram sockets.
E 7
 * (Use on stream sockets would require some record boundary mark in the
D 6
 *  stream such as Sun's RM (Section 3.2 of the Sun RPC Message Protocol
 *  manual, in Networking on the Sun Workstation, Part #800-1324-03
E 6
I 6
 *  stream as defined by "RPC: Remote Procedure Call Protocol
 *  Specification" RFC1057 Section 10)
E 6
 *  and different versions of send, receive and reply that do not assume
 *  an atomic protocol
E 13
I 13
 * Socket operations for use by nfs
E 13
 */

I 25
D 33
#include "types.h"
E 25
D 21
#include "types.h"
E 21
#include "param.h"
I 25
#include "uio.h"
E 25
D 21
#include "uio.h"
#include "user.h"
E 21
I 7
#include "proc.h"
I 25
#include "signal.h"
E 25
D 21
#include "signal.h"
E 21
E 7
#include "mount.h"
#include "kernel.h"
#include "malloc.h"
#include "mbuf.h"
I 23
D 25
#include "namei.h"
E 25
E 23
#include "vnode.h"
#include "domain.h"
#include "protosw.h"
#include "socket.h"
#include "socketvar.h"
I 21
#include "syslog.h"
I 22
#include "tprintf.h"
E 22
E 21
I 13
D 15
#include "netinet/in.h"
#include "netinet/tcp.h"
E 15
I 15
D 25
#include "../netinet/in.h"
#include "../netinet/tcp.h"
I 21

E 25
I 25
#include "machine/endian.h"
#include "netinet/in.h"
#include "netinet/tcp.h"
#ifdef ISO
#include "netiso/iso.h"
#endif
#include "ufs/ufs/quota.h"
#include "ufs/ufs/ufsmount.h"
E 25
E 21
E 15
E 13
D 7
#include "netinet/in.h"
E 7
#include "rpcv2.h"
#include "nfsv2.h"
#include "nfs.h"
#include "xdr_subs.h"
#include "nfsm_subs.h"
#include "nfsmount.h"
I 25
#include "nfsnode.h"
#include "nfsrtt.h"
#include "nqnfs.h"
E 33
I 33
#include <sys/param.h>
I 36
#include <sys/systm.h>
E 36
#include <sys/proc.h>
#include <sys/mount.h>
#include <sys/kernel.h>
#include <sys/mbuf.h>
#include <sys/vnode.h>
#include <sys/domain.h>
#include <sys/protosw.h>
#include <sys/socket.h>
#include <sys/socketvar.h>
#include <sys/syslog.h>
#include <sys/tprintf.h>
I 40

E 40
#include <netinet/in.h>
#include <netinet/tcp.h>
I 52

E 52
#include <nfs/rpcv2.h>
D 52
#include <nfs/nfsv2.h>
E 52
I 52
#include <nfs/nfsproto.h>
E 52
#include <nfs/nfs.h>
#include <nfs/xdr_subs.h>
#include <nfs/nfsm_subs.h>
#include <nfs/nfsmount.h>
#include <nfs/nfsnode.h>
#include <nfs/nfsrtt.h>
#include <nfs/nqnfs.h>
E 33
E 25

I 25
D 28
#include "syslog.h"

E 28
E 25
I 7
D 21
#include "syslog.h"
D 13
#define nfs_log(message, host)	log(LOG_ERR, message, host)
E 13

E 21
E 7
#define	TRUE	1
I 18
#define	FALSE	0
E 18

I 25
D 34
int netnetnet = sizeof (struct netaddrhash);
E 34
E 25
D 13
/* set lock on sockbuf sb, sleep at neg prio */
#define nfs_sblock(sb) { \
	while ((sb)->sb_flags & SB_LOCK) { \
		(sb)->sb_flags |= SB_WANT; \
		sleep((caddr_t)&(sb)->sb_flags, PZERO-1); \
	} \
	(sb)->sb_flags |= SB_LOCK; \
}
E 13
I 7
/*
I 25
 * Estimate rto for an nfs rpc sent via. an unreliable datagram.
 * Use the mean and mean deviation of rtt for the appropriate type of rpc
 * for the frequent rpcs and a default for the others.
 * The justification for doing "other" this way is that these rpcs
 * happen so infrequently that timer est. would probably be stale.
 * Also, since many of these rpcs are
 * non-idempotent, a conservative timeout is desired.
 * getattr, lookup - A+2D
 * read, write     - A+4D
 * other           - nm_timeo
 */
#define	NFS_RTO(n, t) \
	((t) == 0 ? (n)->nm_timeo : \
	 ((t) < 3 ? \
	  (((((n)->nm_srtt[t-1] + 3) >> 2) + (n)->nm_sdrtt[t-1] + 1) >> 1) : \
	  ((((n)->nm_srtt[t-1] + 7) >> 3) + (n)->nm_sdrtt[t-1] + 1)))
#define	NFS_SRTT(r)	(r)->r_nmp->nm_srtt[proct[(r)->r_procnum] - 1]
#define	NFS_SDRTT(r)	(r)->r_nmp->nm_sdrtt[proct[(r)->r_procnum] - 1]
/*
E 25
D 13
 * nfs_sbwait() is simply sbwait() but at a negative priority so that it
 * can not be interrupted by a signal.
 */
nfs_sbwait(sb)
	struct sockbuf *sb;
{
	sb->sb_flags |= SB_WAIT;
	sleep((caddr_t)&sb->sb_cc, PZERO-2);
}
E 7

/*
E 13
 * External data, mostly RPC constants in XDR form
 */
extern u_long rpc_reply, rpc_msgdenied, rpc_mismatch, rpc_vers, rpc_auth_unix,
D 25
	rpc_msgaccepted, rpc_call;
extern u_long nfs_prog, nfs_vers;
I 18
/* Maybe these should be bits in a u_long ?? */
E 25
I 25
D 52
	rpc_msgaccepted, rpc_call, rpc_autherr, rpc_rejectedcred,
E 52
I 52
	rpc_msgaccepted, rpc_call, rpc_autherr,
E 52
	rpc_auth_kerb;
D 52
extern u_long nfs_prog, nfs_vers, nqnfs_prog, nqnfs_vers;
E 52
I 52
extern u_long nfs_prog, nqnfs_prog;
E 52
extern time_t nqnfsstarttime;
E 25
E 18
I 13
D 52
extern int nonidempotent[NFS_NPROCS];
E 52
I 52
extern struct nfsstats nfsstats;
extern int nfsv3_procid[NFS_NPROCS];
extern int nfs_ticks;
E 52
I 20
D 25
static int compressrequest[NFS_NPROCS] = {
	FALSE,
	TRUE,
	TRUE,
	FALSE,
	TRUE,
	TRUE,
	TRUE,
	FALSE,
	FALSE,
	TRUE,
	TRUE,
	TRUE,
	TRUE,
	TRUE,
	TRUE,
	TRUE,
	TRUE,
	TRUE,
E 25
I 25

/*
D 52
 * Maps errno values to nfs error numbers.
 * Use NFSERR_IO as the catch all for ones not specifically defined in
 * RFC 1094.
 */
static int nfsrv_errmap[ELAST] = {
  NFSERR_PERM,	NFSERR_NOENT,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_NXIO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_ACCES,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_EXIST,	NFSERR_IO,	NFSERR_NODEV,	NFSERR_NOTDIR,
  NFSERR_ISDIR,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_FBIG,	NFSERR_NOSPC,	NFSERR_IO,	NFSERR_ROFS,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_NAMETOL,	NFSERR_IO,	NFSERR_IO,
  NFSERR_NOTEMPTY, NFSERR_IO,	NFSERR_IO,	NFSERR_DQUOT,	NFSERR_STALE,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,	NFSERR_IO,
  NFSERR_IO,
E 25
};
I 25

/*
E 52
 * Defines which timer to use for the procnum.
 * 0 - default
 * 1 - getattr
 * 2 - lookup
 * 3 - read
 * 4 - write
 */
static int proct[NFS_NPROCS] = {
D 39
	0, 1, 0, 0, 2, 3, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0,
E 39
I 39
D 52
	0, 1, 0, 0, 2, 3, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0,
E 52
I 52
	0, 1, 0, 2, 1, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0,
	0, 0, 0,
E 52
E 39
};

/*
 * There is a congestion window for outstanding rpcs maintained per mount
 * point. The cwnd size is adjusted in roughly the way that:
 * Van Jacobson, Congestion avoidance and Control, In "Proceedings of
 * SIGCOMM '88". ACM, August 1988.
 * describes for TCP. The cwnd size is chopped in half on a retransmit timeout
 * and incremented by 1/cwnd when each rpc reply is received and a full cwnd
 * of rpcs is in progress.
 * (The sent count and cwnd are scaled for integer arith.)
 * Variants of "slow start" were tried and were found to be too much of a
 * performance hit (ave. rtt 3 times larger),
 * I suspect due to the large rtt that nfs rpcs have.
 */
#define	NFS_CWNDSCALE	256
#define	NFS_MAXCWND	(NFS_CWNDSCALE * 32)
static int nfs_backoff[8] = { 2, 4, 8, 16, 32, 64, 128, 256, };
E 25
E 20
int	nfs_sbwait();
D 25
void	nfs_disconnect();
I 20
struct mbuf *nfs_compress(), *nfs_uncompress();
E 25
I 25
void	nfs_disconnect(), nfs_realign(), nfsrv_wakenfsd(), nfs_sndunlock();
D 38
void	nfs_rcvunlock(), nqnfs_serverd();
E 38
I 38
void	nfs_rcvunlock(), nqnfs_serverd(), nqnfs_clientlease();
E 38
struct mbuf *nfsm_rpchead();
int nfsrtton = 0;
struct nfsrtt nfsrtt;
D 51
struct nfsd nfsd_head;
E 51
E 25
E 20

E 13
int	nfsrv_null(),
	nfsrv_getattr(),
	nfsrv_setattr(),
	nfsrv_lookup(),
I 52
	nfsrv3_access(),
E 52
	nfsrv_readlink(),
	nfsrv_read(),
	nfsrv_write(),
	nfsrv_create(),
I 52
	nfsrv_mknod(),
E 52
	nfsrv_remove(),
	nfsrv_rename(),
	nfsrv_link(),
	nfsrv_symlink(),
	nfsrv_mkdir(),
	nfsrv_rmdir(),
	nfsrv_readdir(),
I 52
	nfsrv_readdirplus(),
E 52
	nfsrv_statfs(),
I 52
	nfsrv_fsinfo(),
	nfsrv_pathconf(),
	nfsrv_commit(),
E 52
D 25
	nfsrv_noop();
E 25
I 25
	nfsrv_noop(),
D 52
	nqnfsrv_readdirlook(),
E 52
	nqnfsrv_getlease(),
D 39
	nqnfsrv_vacated();
E 39
I 39
D 52
	nqnfsrv_vacated(),
	nqnfsrv_access();
E 52
I 52
	nqnfsrv_vacated();
E 52
E 39
E 25

D 52
int (*nfsrv_procs[NFS_NPROCS])() = {
E 52
I 52
int (*nfsrv3_procs[NFS_NPROCS])() = {
E 52
	nfsrv_null,
	nfsrv_getattr,
	nfsrv_setattr,
D 52
	nfsrv_noop,
E 52
	nfsrv_lookup,
I 52
	nfsrv3_access,
E 52
	nfsrv_readlink,
	nfsrv_read,
D 52
	nfsrv_noop,
E 52
	nfsrv_write,
	nfsrv_create,
I 52
	nfsrv_mkdir,
	nfsrv_symlink,
	nfsrv_mknod,
E 52
	nfsrv_remove,
I 52
	nfsrv_rmdir,
E 52
	nfsrv_rename,
	nfsrv_link,
D 52
	nfsrv_symlink,
	nfsrv_mkdir,
	nfsrv_rmdir,
E 52
	nfsrv_readdir,
I 52
	nfsrv_readdirplus,
E 52
	nfsrv_statfs,
I 25
D 52
	nqnfsrv_readdirlook,
E 52
I 52
	nfsrv_fsinfo,
	nfsrv_pathconf,
	nfsrv_commit,
E 52
	nqnfsrv_getlease,
	nqnfsrv_vacated,
I 39
	nfsrv_noop,
D 52
	nqnfsrv_access,
E 52
I 52
	nfsrv_noop
E 52
E 39
E 25
};

I 7
D 13
struct nfshost *nfshosth;
E 13
D 51
struct nfsreq nfsreqh;
D 25
int nfsrexmtthresh = NFS_FISHY;
I 13
int nfs_tcpnodelay = 1;
E 25
E 13
E 7

E 51
/*
D 7
 * This is a stripped down version of sosend() specific to
 * udp/ip and uses the mbuf list provdied
E 7
I 7
D 13
 * Initialize sockets and per-host congestion for a new NFS connection.
E 13
I 13
 * Initialize sockets and congestion for a new NFS connection.
E 13
 * We do not free the sockaddr if error.
E 7
 */
I 52
int
E 52
D 7
nfs_udpsend(so, nam, top, flags, siz)
E 7
I 7
D 13
nfs_connect(nmp, saddr)
E 13
I 13
D 25
nfs_connect(nmp)
E 25
I 25
nfs_connect(nmp, rep)
E 25
E 13
	register struct nfsmount *nmp;
I 25
	struct nfsreq *rep;
E 25
D 13
	struct mbuf *saddr;
E 13
{
D 13
	int s, error, srvaddrlen;
E 13
I 13
	register struct socket *so;
D 24
	int s, error;
E 24
I 24
D 25
	int s, error, bufsize;
E 25
I 25
	int s, error, rcvreserve, sndreserve;
I 30
	struct sockaddr *saddr;
	struct sockaddr_in *sin;
E 30
E 25
E 24
E 13
	struct mbuf *m;
I 30
	u_short tport;
E 30
D 13
	register struct nfshost *nfshp;
E 13

D 13
	nmp->nm_so = 0;
	if (error = socreate(mtod(saddr, struct sockaddr *)->sa_family,
				&nmp->nm_so, SOCK_DGRAM, 0))
E 13
I 13
	nmp->nm_so = (struct socket *)0;
D 30
	if (error = socreate(mtod(nmp->nm_nam, struct sockaddr *)->sa_family,
E 30
I 30
	saddr = mtod(nmp->nm_nam, struct sockaddr *);
D 52
	if (error = socreate(saddr->sa_family,
E 30
		&nmp->nm_so, nmp->nm_sotype, nmp->nm_soproto))
E 52
I 52
	error = socreate(saddr->sa_family, &nmp->nm_so, nmp->nm_sotype, 
		nmp->nm_soproto);
	if (error)
E 52
E 13
		goto bad;
I 13
	so = nmp->nm_so;
	nmp->nm_soflags = so->so_proto->pr_flags;
I 30

	/*
	 * Some servers require that the client port be a reserved port number.
	 */
	if (saddr->sa_family == AF_INET && (nmp->nm_flag & NFSMNT_RESVPORT)) {
		MGET(m, M_WAIT, MT_SONAME);
		sin = mtod(m, struct sockaddr_in *);
		sin->sin_len = m->m_len = sizeof (struct sockaddr_in);
		sin->sin_family = AF_INET;
		sin->sin_addr.s_addr = INADDR_ANY;
		tport = IPPORT_RESERVED - 1;
		sin->sin_port = htons(tport);
		while ((error = sobind(so, m)) == EADDRINUSE &&
		       --tport > IPPORT_RESERVED / 2)
			sin->sin_port = htons(tport);
		m_freem(m);
		if (error)
			goto bad;
	}
E 30
E 13

I 24
D 25
	if (nmp->nm_sotype == SOCK_DGRAM)
		bufsize = min(4 * (nmp->nm_wsize + NFS_MAXPKTHDR),
		    NFS_MAXPACKET);
	else
		bufsize = min(4 * (nmp->nm_wsize + NFS_MAXPKTHDR + sizeof(u_long)),
		    NFS_MAXPACKET + sizeof(u_long));
	if (error = soreserve(so, bufsize, bufsize))
		goto bad;

E 25
E 24
D 13
	/* Unix sockets do not provide a local bind for server reply */
	if (mtod(saddr, struct sockaddr *)->sa_family == AF_UNIX) {
		struct sockaddr *sa;
		static char client[] = "/tmp/.nfs/nfsclient##";
		static int serial;
		int firstserial;
		m = m_getclr(M_WAIT, MT_SONAME);
		if (m == NULL) {
			error = ENOBUFS;
E 13
I 13
	/*
	 * Protocols that do not require connections may be optionally left
	 * unconnected for servers that reply from a port other than NFS_PORT.
	 */
	if (nmp->nm_flag & NFSMNT_NOCONN) {
		if (nmp->nm_soflags & PR_CONNREQUIRED) {
			error = ENOTCONN;
E 13
			goto bad;
		}
D 13
		m->m_len = sizeof (client) + 2;
		sa = mtod(m, struct sockaddr *);
		sa->sa_family = AF_UNIX;
#ifdef	MSG_TRUNC	/* Have sa_len to set? */
		sa->sa_len = m->m_len;
#endif
		bcopy(client, sa->sa_data, sizeof(client));
		firstserial = serial;
		do {
			if (++serial >= 100) serial = 0;
			sa->sa_data[19] = (serial / 10) + '0';
			sa->sa_data[20] = (serial % 10) + '0';
			error = sobind(nmp->nm_so, m);
			if (firstserial == serial) break;
		} while (error == EADDRINUSE);
		m_freem(m);
		if (error)
E 13
I 13
	} else {
D 52
		if (error = soconnect(so, nmp->nm_nam))
E 52
I 52
		error = soconnect(so, nmp->nm_nam);
		if (error)
E 52
E 13
			goto bad;
I 13

		/*
		 * Wait for the connection to complete. Cribbed from the
D 25
		 * connect system call but with the wait at negative prio.
E 25
I 25
		 * connect system call but with the wait timing out so
		 * that interruptible mounts don't hang here for a long time.
E 25
		 */
		s = splnet();
D 25
		while ((so->so_state & SS_ISCONNECTING) && so->so_error == 0)
D 18
			sleep((caddr_t)&so->so_timeo, PZERO-2);
E 18
I 18
			(void) tsleep((caddr_t)&so->so_timeo, PSOCK, "nfscon", 0);
E 18
		splx(s);
E 25
I 25
		while ((so->so_state & SS_ISCONNECTING) && so->so_error == 0) {
			(void) tsleep((caddr_t)&so->so_timeo, PSOCK,
				"nfscon", 2 * hz);
			if ((so->so_state & SS_ISCONNECTING) &&
			    so->so_error == 0 && rep &&
			    (error = nfs_sigintr(nmp, rep, rep->r_procp))) {
				so->so_state &= ~SS_ISCONNECTING;
				splx(s);
				goto bad;
			}
		}
E 25
		if (so->so_error) {
			error = so->so_error;
I 25
			so->so_error = 0;
			splx(s);
E 25
			goto bad;
		}
I 25
		splx(s);
E 25
E 13
	}
I 25
	if (nmp->nm_flag & (NFSMNT_SOFT | NFSMNT_INT)) {
		so->so_rcv.sb_timeo = (5 * hz);
		so->so_snd.sb_timeo = (5 * hz);
	} else {
		so->so_rcv.sb_timeo = 0;
		so->so_snd.sb_timeo = 0;
	}
E 25
I 13
	if (nmp->nm_sotype == SOCK_DGRAM) {
D 18
		if (nmp->nm_flag & (NFSMNT_SOFT | NFSMNT_INT)) {
E 18
I 18
D 25
		if (nmp->nm_flag & (NFSMNT_SOFT | NFSMNT_SPONGY | NFSMNT_INT)) {
E 18
			so->so_rcv.sb_timeo = (5 * hz);
			so->so_snd.sb_timeo = (5 * hz);
		} else {
			so->so_rcv.sb_timeo = 0;
			so->so_snd.sb_timeo = 0;
		}
D 21
		if (error = soreserve(so, nmp->nm_wsize + NFS_MAXPKTHDR,
D 18
		    (nmp->nm_rsize + NFS_MAXPKTHDR) * 4))
E 18
I 18
		    nmp->nm_rsize + NFS_MAXPKTHDR))
E 21
I 21
D 24
		if (error = soreserve(so,
		    min(4 * (nmp->nm_wsize + NFS_MAXPKTHDR), NFS_MAXPACKET),
		    min(4 * (nmp->nm_rsize + NFS_MAXPKTHDR), NFS_MAXPACKET)))
E 21
E 18
			goto bad;
E 24
I 24
		nmp->nm_rto = NFS_TIMEO;
E 25
I 25
		sndreserve = nmp->nm_wsize + NFS_MAXPKTHDR;
		rcvreserve = nmp->nm_rsize + NFS_MAXPKTHDR;
	} else if (nmp->nm_sotype == SOCK_SEQPACKET) {
		sndreserve = (nmp->nm_wsize + NFS_MAXPKTHDR) * 2;
		rcvreserve = (nmp->nm_rsize + NFS_MAXPKTHDR) * 2;
E 25
E 24
	} else {
D 18
		if (nmp->nm_flag & NFSMNT_INT) {
E 18
I 18
D 25
		if (nmp->nm_flag & (NFSMNT_SOFT | NFSMNT_SPONGY | NFSMNT_INT)) {
E 18
			so->so_rcv.sb_timeo = (5 * hz);
			so->so_snd.sb_timeo = (5 * hz);
		} else {
			so->so_rcv.sb_timeo = 0;
			so->so_snd.sb_timeo = 0;
		}
E 25
I 25
		if (nmp->nm_sotype != SOCK_STREAM)
			panic("nfscon sotype");
E 25
		if (so->so_proto->pr_flags & PR_CONNREQUIRED) {
			MGET(m, M_WAIT, MT_SOOPTS);
			*mtod(m, int *) = 1;
			m->m_len = sizeof(int);
			sosetopt(so, SOL_SOCKET, SO_KEEPALIVE, m);
		}
D 25
		if (so->so_proto->pr_domain->dom_family == AF_INET &&
		    so->so_proto->pr_protocol == IPPROTO_TCP &&
		    nfs_tcpnodelay) {
E 25
I 25
		if (so->so_proto->pr_protocol == IPPROTO_TCP) {
E 25
			MGET(m, M_WAIT, MT_SOOPTS);
			*mtod(m, int *) = 1;
			m->m_len = sizeof(int);
			sosetopt(so, IPPROTO_TCP, TCP_NODELAY, m);
		}
D 24
		if (error = soreserve(so,
D 18
		    (nmp->nm_wsize + NFS_MAXPKTHDR + sizeof(u_long)) * 2,
E 18
I 18
D 21
		    nmp->nm_wsize + NFS_MAXPKTHDR + sizeof(u_long),
E 18
		    nmp->nm_rsize + NFS_MAXPKTHDR + sizeof(u_long)))
E 21
I 21
		    min(4 * (nmp->nm_wsize + NFS_MAXPKTHDR + sizeof(u_long)),
		    NFS_MAXPACKET + sizeof(u_long)),
		    min(4 * (nmp->nm_rsize + NFS_MAXPKTHDR + sizeof(u_long)),
		    NFS_MAXPACKET + sizeof(u_long))))
E 21
			goto bad;
E 24
I 24
D 25
		nmp->nm_rto = 10 * NFS_TIMEO;		/* XXX */
E 25
I 25
		sndreserve = (nmp->nm_wsize + NFS_MAXPKTHDR + sizeof (u_long))
				* 2;
		rcvreserve = (nmp->nm_rsize + NFS_MAXPKTHDR + sizeof (u_long))
				* 2;
E 25
E 24
	}
I 25
D 52
	if (error = soreserve(so, sndreserve, rcvreserve))
E 52
I 52
	error = soreserve(so, sndreserve, rcvreserve);
	if (error)
E 52
		goto bad;
E 25
	so->so_rcv.sb_flags |= SB_NOINTR;
	so->so_snd.sb_flags |= SB_NOINTR;
E 13

D 13
	if (error = soconnect(nmp->nm_so, saddr))
		goto bad;
	error = soreserve(nmp->nm_so,	/* get space ! */
				nmp->nm_wsize + 1024,		/* one out */
				(nmp->nm_rsize + 1024) * 4);	/* four in */
	if (error)
		goto bad;
E 13
I 13
	/* Initialize other non-zero congestion variables */
D 24
	nmp->nm_rto = NFS_TIMEO;
	nmp->nm_window = 2;		    /* Initial send window */
	nmp->nm_ssthresh = NFS_MAXWINDOW; /* Slowstart threshold */
E 24
I 24
D 25
	nmp->nm_window = 2;			/* Initial send window */
	nmp->nm_ssthresh = NFS_MAXWINDOW;	/* Slowstart threshold */
E 24
	nmp->nm_rttvar = nmp->nm_rto << 1;
E 25
I 25
	nmp->nm_srtt[0] = nmp->nm_srtt[1] = nmp->nm_srtt[2] = nmp->nm_srtt[3] =
		nmp->nm_srtt[4] = (NFS_TIMEO << 3);
	nmp->nm_sdrtt[0] = nmp->nm_sdrtt[1] = nmp->nm_sdrtt[2] =
		nmp->nm_sdrtt[3] = nmp->nm_sdrtt[4] = 0;
	nmp->nm_cwnd = NFS_MAXCWND / 2;	    /* Initial send window */
E 25
	nmp->nm_sent = 0;
D 25
	nmp->nm_currexmit = 0;
E 25
I 25
	nmp->nm_timeouts = 0;
E 25
	return (0);
E 13

D 13
	/*
	 * Search mount list for existing server entry.
	 *
	 * Note, even though we have a sockaddr, it is not quite reliable
	 * enough to bcmp against. For instance, a sockaddr_in has a 
	 * sin_zero field which is not reliably zeroed by user code (e.g.
	 * mount). So what we do as an attempt at transport independence
	 * is to get the peeraddr of our connected socket into a zeroed
	 * sockaddr. Then we cache that and compare against it. This is
	 * not exactly perfect. However it is not critical that it be, if
	 * we cannot match the sockaddr we will simply allocate a new nfshp
	 * per mount, which will disable the per-host congestion but
	 * everything else will work as normal.
	 */
	m = m_getclr(M_WAIT, MT_SONAME);
	if (m && (*(nmp->nm_so->so_proto->pr_usrreq))(nmp->nm_so, PRU_PEERADDR,
				(struct mbuf *)0, m, (struct mbuf *)0) == 0) {
		m_freem(saddr);
		saddr = m;
	} else
		m_freem(m);
	srvaddrlen = saddr->m_len;
E 13
I 13
bad:
	nfs_disconnect(nmp);
	return (error);
}
E 13

D 13
	s = splnet();
E 13
I 13
/*
 * Reconnect routine:
 * Called when a connection is broken on a reliable protocol.
 * - clean up the old socket
 * - nfs_connect() again
 * - set R_MUSTRESEND for all outstanding requests on mount point
 * If this fails the mount point is DEAD!
D 25
 * nb: Must be called with the nfs_solock() set on the mount point.
E 25
I 25
 * nb: Must be called with the nfs_sndlock() set on the mount point.
E 25
 */
I 52
int
E 52
D 25
nfs_reconnect(rep, nmp)
E 25
I 25
nfs_reconnect(rep)
E 25
	register struct nfsreq *rep;
D 25
	register struct nfsmount *nmp;
E 25
{
	register struct nfsreq *rp;
I 25
	register struct nfsmount *nmp = rep->r_nmp;
E 25
D 14
	register struct socket *so;
E 14
	int error;
E 13

I 25
	nfs_disconnect(nmp);
E 25
D 13
	for (nfshp = nfshosth; nfshp; nfshp = nfshp->nh_next) {
		if (srvaddrlen != nfshp->nh_salen)
			continue;
		if (!bcmp(mtod(saddr,caddr_t),mtod(nfshp->nh_sockaddr,caddr_t),
				srvaddrlen))
			break;
E 13
I 13
D 22
	if (rep->r_procp)
D 16
		tprintf(rep->r_procp->p_session->s_ttyvp,
E 16
I 16
		tprintf(rep->r_procp->p_session,
E 16
			"Nfs server %s, trying reconnect\n",
			nmp->nm_mountp->mnt_stat.f_mntfromname);
	else
D 16
		tprintf(NULLVP, "Nfs server %s, trying a reconnect\n",
E 16
I 16
		tprintf(NULL, "Nfs server %s, trying a reconnect\n",
E 16
			nmp->nm_mountp->mnt_stat.f_mntfromname);
E 22
I 22
D 26
	nfs_msg(rep->r_procp, nmp->nm_mountp->mnt_stat.f_mntfromname,
	    "trying reconnect");
E 26
E 22
D 25
	while (error = nfs_connect(nmp)) {
I 14
#ifdef lint
		error = error;
#endif /* lint */
E 14
		if ((nmp->nm_flag & NFSMNT_INT) && nfs_sigintr(rep->r_procp))
E 25
I 25
D 52
	while (error = nfs_connect(nmp, rep)) {
E 52
I 52
	while ((error = nfs_connect(nmp, rep))) {
E 52
		if (error == EINTR || error == ERESTART)
E 25
			return (EINTR);
D 18
		tsleep((caddr_t)&lbolt, PSOCK, "nfscon", 0);
E 18
I 18
		(void) tsleep((caddr_t)&lbolt, PSOCK, "nfscon", 0);
E 18
E 13
	}
D 13
	if (nfshp)		/* Have an existing mount host */
		m_freem(saddr);
	else {
		MALLOC(nfshp,struct nfshost *,sizeof *nfshp,M_NFSMNT,M_WAITOK);
		bzero((caddr_t)nfshp, sizeof *nfshp);
		nfshp->nh_sockaddr = saddr;
		nfshp->nh_salen = srvaddrlen;
		/* Initialize other non-zero congestion variables */
		nfshp->nh_currto = NFS_TIMEO;
		nfshp->nh_window = 1;		    /* Initial send window */
		nfshp->nh_ssthresh = NFS_MAXWINDOW; /* Slowstart threshold */
		if (nfshosth) nfshosth->nh_prev = nfshp;	/* Chain in */
		nfshp->nh_next = nfshosth;
		nfshosth = nfshp;
E 13
I 13
D 22
	if (rep->r_procp)
D 16
		tprintf(rep->r_procp->p_session->s_ttyvp,
E 16
I 16
		tprintf(rep->r_procp->p_session,
E 16
			"Nfs server %s, reconnected\n",
			nmp->nm_mountp->mnt_stat.f_mntfromname);
	else
D 16
		tprintf(NULLVP, "Nfs server %s, reconnected\n",
E 16
I 16
		tprintf(NULL, "Nfs server %s, reconnected\n",
E 16
			nmp->nm_mountp->mnt_stat.f_mntfromname);
E 22
I 22
D 26
	nfs_msg(rep->r_procp, nmp->nm_mountp->mnt_stat.f_mntfromname,
	    "reconnected");
E 26
E 22

	/*
	 * Loop through outstanding request list and fix up all requests
	 * on old socket.
	 */
D 51
	rp = nfsreqh.r_next;
	while (rp != &nfsreqh) {
E 51
I 51
	for (rp = nfs_reqq.tqh_first; rp != 0; rp = rp->r_chain.tqe_next) {
E 51
		if (rp->r_nmp == nmp)
			rp->r_flags |= R_MUSTRESEND;
D 51
		rp = rp->r_next;
E 51
E 13
	}
D 13
	nfshp->nh_refcnt++;
	splx(s);
	nmp->nm_hostinfo = nfshp;
	if (nmp->nm_rto == NFS_TIMEO) {
		nmp->nm_rto = nfshp->nh_currto;
		nmp->nm_rttvar = nmp->nm_rto << 1;
	}
E 13
	return (0);
D 13

bad:
	if (nmp->nm_so) (void) soclose(nmp->nm_so);
	nmp->nm_so = 0;
	return (error);
E 13
}

/*
 * NFS disconnect. Clean up and unlink.
 */
I 13
void
E 13
nfs_disconnect(nmp)
	register struct nfsmount *nmp;
{
D 13
	register struct nfshost *nfshp;
E 13
I 13
	register struct socket *so;
E 13

D 13
	if (nmp->nm_so)
		soclose(nmp->nm_so);
	nmp->nm_so = 0;
	if (nfshp = nmp->nm_hostinfo) {
		int s = splnet();
		if (--nfshp->nh_refcnt <= 0) {
			if (nfshp->nh_next)
				nfshp->nh_next->nh_prev = nfshp->nh_prev;
			if (nfshp->nh_prev)
				nfshp->nh_prev->nh_next = nfshp->nh_next;
			else
				nfshosth = nfshp->nh_next;
			/* If unix family, remove the nfsclient from /tmp */
			if (mtod(nfshp->nh_sockaddr,
				struct sockaddr *)->sa_family == AF_UNIX) {
					/* Lookup sa_data, do VOP_REMOVE... */
			}
			m_freem(nfshp->nh_sockaddr);
			FREE(nfshp, M_NFSMNT);
		}
		nmp->nm_hostinfo = 0;
		splx(s);
E 13
I 13
	if (nmp->nm_so) {
		so = nmp->nm_so;
		nmp->nm_so = (struct socket *)0;
		soshutdown(so, 2);
		soclose(so);
E 13
	}
}

/*
D 13
 * This is a stripped down non-interruptible version of sosend().
E 13
I 13
 * This is the nfs send routine. For connection based socket types, it
D 25
 * must be called with an nfs_solock() on the socket.
E 25
I 25
 * must be called with an nfs_sndlock() on the socket.
E 25
 * "rep == NULL" indicates that it has been called from a server.
I 25
 * For the client side:
 * - return EINTR if the RPC is terminated, 0 otherwise
 * - set R_MUSTRESEND if the send fails for any reason
 * - do any cleanup required by recoverable socket errors (???)
 * For the server side:
 * - return EINTR or ERESTART if interrupted by a signal
 * - return EPIPE if a connection is lost for connection based sockets (TCP...)
 * - do any cleanup required by recoverable socket errors (???)
E 25
E 13
 */
I 52
int
E 52
D 13
nfs_send(so, nam, top, flags, siz)
E 13
I 13
nfs_send(so, nam, top, rep)
E 13
E 7
	register struct socket *so;
	struct mbuf *nam;
D 13
	struct mbuf *top;
	int flags;
	int siz;
E 13
I 13
	register struct mbuf *top;
	struct nfsreq *rep;
E 13
{
D 7
	register int space;
D 5
	int error = 0, s, dontroute, first = 1;
E 5
I 5
	int error = 0, s, dontroute;
E 7
I 7
D 13
	int error, s;
E 13
I 13
	struct mbuf *sendnam;
D 25
	int error, soflags;
E 25
I 25
	int error, soflags, flags;
E 25
E 13
E 7
E 5

D 7
	dontroute =
	    (flags & MSG_DONTROUTE) && (so->so_options & SO_DONTROUTE) == 0 &&
	    (so->so_proto->pr_flags & PR_ATOMIC);
#define	snderr(errno)	{ error = errno; splx(s); goto release; }

E 7
D 13
#ifdef MGETHDR
	top->m_pkthdr.len = siz;
#endif
D 7
restart:
	nfs_sblock(&so->so_snd);
	s = splnet();
	if (so->so_state & SS_CANTSENDMORE)
		snderr(EPIPE);
	if (so->so_error)
		snderr(so->so_error);
	space = sbspace(&so->so_snd);
	if (space < siz) {
		sbunlock(&so->so_snd);
		nfs_sbwait(&so->so_snd);
E 7
I 7
	for (;;) {
		nfs_sblock(&so->so_snd);
		s = splnet();
		if (error = nfs_sockerr(so, 1)) {
			splx(s);
E 13
I 13
	if (rep) {
		if (rep->r_flags & R_SOFTTERM) {
E 13
			m_freem(top);
D 13
			break;
E 13
I 13
			return (EINTR);
E 13
		}
D 13
		if (sbspace(&so->so_snd) < siz) {
			sbunlock(&so->so_snd);
			nfs_sbwait(&so->so_snd);
			splx(s);
			continue;
E 13
I 13
D 17
		if ((so = rep->r_nmp->nm_so) == NULL &&
E 17
I 17
D 25
		if (rep->r_nmp->nm_so == NULL &&
E 17
		    (error = nfs_reconnect(rep, rep->r_nmp)))
			return (error);
E 25
I 25
		if ((so = rep->r_nmp->nm_so) == NULL) {
			rep->r_flags |= R_MUSTRESEND;
			m_freem(top);
			return (0);
		}
E 25
		rep->r_flags &= ~R_MUSTRESEND;
I 17
D 25
		so = rep->r_nmp->nm_so;
E 25
E 17
		soflags = rep->r_nmp->nm_soflags;
	} else
		soflags = so->so_proto->pr_flags;
	if ((soflags & PR_CONNREQUIRED) || (so->so_state & SS_ISCONNECTED))
		sendnam = (struct mbuf *)0;
	else
		sendnam = nam;
I 25
	if (so->so_type == SOCK_SEQPACKET)
		flags = MSG_EOR;
	else
		flags = 0;
E 25

	error = sosend(so, sendnam, (struct uio *)0, top,
D 25
		(struct mbuf *)0, 0);
	if (error == EWOULDBLOCK && rep) {
		if (rep->r_flags & R_SOFTTERM)
			error = EINTR;
		else {
			rep->r_flags |= R_MUSTRESEND;
			error = 0;
E 25
I 25
		(struct mbuf *)0, flags);
D 28
if(error) printf("nfssnd err=%d\n",error);
E 28
	if (error) {
		if (rep) {
I 28
			log(LOG_INFO, "nfs send error %d for server %s\n",error,
			    rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
E 28
			/*
			 * Deal with errors for the client side.
			 */
			if (rep->r_flags & R_SOFTTERM)
				error = EINTR;
			else
				rep->r_flags |= R_MUSTRESEND;
E 25
E 13
D 28
		}
E 28
I 28
		} else
			log(LOG_INFO, "nfsd send error %d\n", error);
E 28
I 25

		/*
		 * Handle any recoverable (soft) socket errors here. (???)
		 */
		if (error != EINTR && error != ERESTART &&
			error != EWOULDBLOCK && error != EPIPE)
			error = 0;
E 25
D 13
		error = (*so->so_proto->pr_usrreq)(so, PRU_SEND, top,
D 8
			(struct mbuf *)nam, (struct mbuf *)0, (struct mbuf *)0);
E 8
I 8
			(struct mbuf *)nam, (struct mbuf *)0);
E 8
E 7
		splx(s);
D 7
		goto restart;
E 7
I 7
		break;
E 13
E 7
	}
D 7
	splx(s);
	if (dontroute)
		so->so_options |= SO_DONTROUTE;
	s = splnet();					/* XXX */
	error = (*so->so_proto->pr_usrreq)(so,
	    PRU_SEND,
	    top, (caddr_t)nam, (struct mbuf *)0, (struct mbuf *)0);
	splx(s);
	if (dontroute)
		so->so_options &= ~SO_DONTROUTE;
	top = (struct mbuf *)0;

release:
E 7
D 13
	sbunlock(&so->so_snd);
E 13
I 13
D 25
	/*
	 * Ignore socket errors??
	 */
	if (error && error != EINTR && error != ERESTART)
		error = 0;
E 25
E 13
D 7
	if (top)
		m_freem(top);
E 7
	return (error);
}

/*
D 7
 * This is a stripped down udp specific version of soreceive()
E 7
I 7
D 13
 * This is a stripped down datagram specific version of soreceive()
E 13
I 13
 * Receive a Sun RPC Request/Reply. For SOCK_DGRAM, the work is all
 * done by soreceive(), but for SOCK_STREAM we must deal with the Record
 * Mark and consolidate the data into a new mbuf list.
 * nb: Sometimes TCP passes the data up to soreceive() in long lists of
 *     small mbufs.
 * For SOCK_STREAM we must be very careful to read an entire record once
 * we have read any of it, even if the system call has been interrupted.
E 13
E 7
 */
I 52
int
E 52
D 6
nfs_udpreceive(so, aname, mp)
E 6
I 6
D 7
nfs_udpreceive(so, msk, mtch, aname, mp)
E 7
I 7
D 13
nfs_dgreceive(so, msk, mtch, aname, mp)
E 13
I 13
D 25
nfs_receive(so, aname, mp, rep)
E 13
E 7
E 6
	register struct socket *so;
E 25
I 25
nfs_receive(rep, aname, mp)
	register struct nfsreq *rep;
E 25
I 6
D 13
	u_long msk;
	u_long mtch;
E 13
E 6
	struct mbuf **aname;
	struct mbuf **mp;
I 13
D 25
	register struct nfsreq *rep;
E 25
E 13
{
I 25
	register struct socket *so;
E 25
I 13
	struct uio auio;
	struct iovec aio;
E 13
	register struct mbuf *m;
D 13
	int s, error = 0;
D 5
	struct protosw *pr = so->so_proto;
E 5
	struct mbuf *nextrecord;
E 13
I 13
D 20
	struct mbuf *m2, *m3, *mnew, **mbp;
E 20
I 20
D 25
	struct mbuf *m2, *mnew, **mbp;
E 20
	caddr_t fcp, tcp;
E 25
I 25
	struct mbuf *control;
E 25
	u_long len;
	struct mbuf **getnam;
D 22
	int error, siz, mlen, soflags, rcvflg = MSG_WAITALL;
E 22
I 22
D 25
	int error, siz, mlen, soflags, rcvflg;
E 25
I 25
	int error, sotype, rcvflg;
I 27
	struct proc *p = curproc;	/* XXX */
E 27
E 25
E 22
E 13
I 6
D 7
	struct sockaddr_in *saddr;
E 7
E 6

D 13
	if (aname)
		*aname = 0;
E 13
I 13
	/*
	 * Set up arguments for soreceive()
	 */
	*mp = (struct mbuf *)0;
	*aname = (struct mbuf *)0;
D 25
	if (rep)
		soflags = rep->r_nmp->nm_soflags;
	else
		soflags = so->so_proto->pr_flags;
E 25
I 25
	sotype = rep->r_nmp->nm_sotype;
E 25
E 13

D 7
restart:
	sblock(&so->so_rcv);
	s = splnet();
E 7
I 7
D 13
	for (;;) {
D 11
		sblock(&so->so_rcv);
E 11
I 11
		if (error = sblock(&so->so_rcv))
			return (error);
E 11
		s = splnet();
E 7

D 7
	if (so->so_rcv.sb_cc == 0) {
		if (so->so_error) {
			error = so->so_error;
			so->so_error = 0;
			goto release;
		}
		if (so->so_state & SS_CANTRCVMORE)
			goto release;
		sbunlock(&so->so_rcv);
		sbwait(&so->so_rcv);
		splx(s);
		goto restart;
	}
	m = so->so_rcv.sb_mb;
	if (m == 0)
		panic("nfs_receive 1");
	nextrecord = m->m_nextpkt;
	if (m->m_type != MT_SONAME)
		panic("nfs_receive 1a");
I 6
	if (msk) {
		saddr = mtod(m, struct sockaddr_in *);
		if ((saddr->sin_addr.s_addr & msk) != mtch) {
			sbdroprecord(&so->so_rcv);
E 7
I 7
		if (so->so_rcv.sb_cc == 0) {
			if (error = nfs_sockerr(so, 0)) {
				so->so_error = 0;
				break;
E 13
I 13
	/*
	 * For reliable protocols, lock against other senders/receivers
	 * in case a reconnect is necessary.
	 * For SOCK_STREAM, first get the Record Mark to find out how much
	 * more there is to get.
	 * We must lock the socket against other receivers
	 * until we have an entire rpc request/reply.
	 */
D 25
	if (soflags & PR_CONNREQUIRED) {
E 25
I 25
	if (sotype != SOCK_DGRAM) {
D 52
		if (error = nfs_sndlock(&rep->r_nmp->nm_flag, rep))
E 52
I 52
		error = nfs_sndlock(&rep->r_nmp->nm_flag, rep);
		if (error)
E 52
			return (error);
E 25
tryagain:
		/*
		 * Check for fatal errors and resending request.
		 */
D 25
		if (rep) {
			/*
			 * Ugh: If a reconnect attempt just happened, nm_so
			 * would have changed. NULL indicates a failed
			 * attempt that has essentially shut down this
			 * mount point.
			 */
			if (rep->r_mrep || (so = rep->r_nmp->nm_so) == NULL ||
				(rep->r_flags & R_SOFTTERM))
				return (EINTR);
			while (rep->r_flags & R_MUSTRESEND) {
				m = m_copym(rep->r_mreq, 0, M_COPYALL, M_WAIT);
				nfsstats.rpcretries++;
				if (error = nfs_send(so, rep->r_nmp->nm_nam, m,
					rep))
					goto errout;
E 25
I 25
		/*
		 * Ugh: If a reconnect attempt just happened, nm_so
		 * would have changed. NULL indicates a failed
		 * attempt that has essentially shut down this
		 * mount point.
		 */
		if (rep->r_mrep || (rep->r_flags & R_SOFTTERM)) {
			nfs_sndunlock(&rep->r_nmp->nm_flag);
			return (EINTR);
		}
D 52
		if ((so = rep->r_nmp->nm_so) == NULL) {
			if (error = nfs_reconnect(rep)) {
E 52
I 52
		so = rep->r_nmp->nm_so;
		if (!so) {
			error = nfs_reconnect(rep); 
			if (error) {
E 52
				nfs_sndunlock(&rep->r_nmp->nm_flag);
				return (error);
E 25
E 13
			}
I 25
			goto tryagain;
E 25
E 7
D 13
			sbunlock(&so->so_rcv);
I 7
D 11
			sbwait(&so->so_rcv);
E 11
I 11
			error = sbwait(&so->so_rcv);
E 11
E 7
			splx(s);
I 11
			if (error)
				return (error);
E 11
D 7
			goto restart;
E 7
I 7
			continue;
E 13
E 7
		}
D 7
	}
E 6
	sbfree(&so->so_rcv, m);
	if (aname) {
		*aname = m;
		so->so_rcv.sb_mb = m->m_next;
		m->m_next = 0;
E 7
D 13
		m = so->so_rcv.sb_mb;
D 7
	} else {
		MFREE(m, so->so_rcv.sb_mb);
		m = so->so_rcv.sb_mb;
	}
	if (m && m->m_type == MT_RIGHTS)
		panic("nfs_receive 2");
	if (m && m->m_type == MT_CONTROL) {
E 7
I 7
		if (m == 0)
			panic("nfs_dgreceive 1");
		nextrecord = m->m_nextpkt;
		/* Save sender's address */
		if (m->m_type != MT_SONAME)
			panic("nfs_dgreceive 1a");
E 7
		sbfree(&so->so_rcv, m);
D 7
		MFREE(m, so->so_rcv.sb_mb);
		m = so->so_rcv.sb_mb;
E 7
I 7
		if (aname) {
			*aname = m;
			so->so_rcv.sb_mb = m->m_next;
			m->m_next = 0;
			m = so->so_rcv.sb_mb;
E 13
I 13
D 25
		if ((soflags & PR_ATOMIC) == 0) {
E 25
I 25
		while (rep->r_flags & R_MUSTRESEND) {
			m = m_copym(rep->r_mreq, 0, M_COPYALL, M_WAIT);
			nfsstats.rpcretries++;
D 52
			if (error = nfs_send(so, rep->r_nmp->nm_nam, m, rep)) {
E 52
I 52
			error = nfs_send(so, rep->r_nmp->nm_nam, m, rep);
			if (error) {
E 52
				if (error == EINTR || error == ERESTART ||
				    (error = nfs_reconnect(rep))) {
					nfs_sndunlock(&rep->r_nmp->nm_flag);
					return (error);
				}
				goto tryagain;
			}
		}
		nfs_sndunlock(&rep->r_nmp->nm_flag);
		if (sotype == SOCK_STREAM) {
E 25
			aio.iov_base = (caddr_t) &len;
			aio.iov_len = sizeof(u_long);
			auio.uio_iov = &aio;
			auio.uio_iovcnt = 1;
			auio.uio_segflg = UIO_SYSSPACE;
			auio.uio_rw = UIO_READ;
I 23
D 25
			auio.uio_procp = (struct proc *)0;
E 25
E 23
			auio.uio_offset = 0;
			auio.uio_resid = sizeof(u_long);
I 27
			auio.uio_procp = p;
E 27
			do {
D 22
			   error = soreceive(so, (struct mbuf **)0, &auio,
E 22
I 22
D 25
			    rcvflg = MSG_WAITALL;
			    error = soreceive(so, (struct mbuf **)0, &auio,
E 25
I 25
			   rcvflg = MSG_WAITALL;
			   error = soreceive(so, (struct mbuf **)0, &auio,
E 25
E 22
				(struct mbuf **)0, (struct mbuf **)0, &rcvflg);
D 22
			   if (error == EWOULDBLOCK && rep) {
E 22
I 22
D 25
			    if (error == EWOULDBLOCK && rep) {
E 25
I 25
			   if (error == EWOULDBLOCK && rep) {
E 25
E 22
				if (rep->r_flags & R_SOFTTERM)
					return (EINTR);
D 25
				if (rep->r_flags & R_MUSTRESEND)
					goto tryagain;
D 22
			   }
E 22
I 22
			    }
E 25
I 25
			   }
E 25
E 22
			} while (error == EWOULDBLOCK);
D 22
			if (!error && auio.uio_resid > 0)
				error = EPIPE;
E 22
I 22
			if (!error && auio.uio_resid > 0) {
D 28
			    if (rep)
				log(LOG_INFO,
				   "short receive (%d/%d) from nfs server %s\n",
				   sizeof(u_long) - auio.uio_resid,
				   sizeof(u_long),
E 28
I 28
			    log(LOG_INFO,
				 "short receive (%d/%d) from nfs server %s\n",
				 sizeof(u_long) - auio.uio_resid,
				 sizeof(u_long),
E 28
				 rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
			    error = EPIPE;
			}
E 22
			if (error)
				goto errout;
			len = ntohl(len) & ~0x80000000;
			/*
			 * This is SERIOUS! We are out of sync with the sender
			 * and forcing a disconnect/reconnect is all I can do.
			 */
			if (len > NFS_MAXPACKET) {
D 22
				error = EFBIG;
				goto errout;
E 22
I 22
D 28
			    if (rep)
				log(LOG_ERR, "%s (%d) from nfs server %s\n",
				    "impossible packet length",
				    len,
				 rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
E 28
I 28
			    log(LOG_ERR, "%s (%d) from nfs server %s\n",
				"impossible packet length",
				len,
				rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
E 28
			    error = EFBIG;
			    goto errout;
E 22
			}
			auio.uio_resid = len;
			do {
I 22
			    rcvflg = MSG_WAITALL;
E 22
			    error =  soreceive(so, (struct mbuf **)0,
				&auio, mp, (struct mbuf **)0, &rcvflg);
			} while (error == EWOULDBLOCK || error == EINTR ||
				 error == ERESTART);
D 22
			if (!error && auio.uio_resid > 0)
				error = EPIPE;
E 22
I 22
			if (!error && auio.uio_resid > 0) {
D 28
			    if (rep)
				log(LOG_INFO,
				   "short receive (%d/%d) from nfs server %s\n",
				   len - auio.uio_resid, len,
				 rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
E 28
I 28
			    log(LOG_INFO,
				"short receive (%d/%d) from nfs server %s\n",
				len - auio.uio_resid, len,
				rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
E 28
			    error = EPIPE;
			}
E 22
E 13
		} else {
D 13
			MFREE(m, so->so_rcv.sb_mb);
			m = so->so_rcv.sb_mb;
E 13
I 13
D 25
			auio.uio_resid = len = 1000000;	/* Anything Big */
E 25
I 25
			/*
			 * NB: Since uio_resid is big, MSG_WAITALL is ignored
			 * and soreceive() will return when it has either a
			 * control msg or a data msg.
			 * We have no use for control msg., but must grab them
			 * and then throw them away so we know what is going
			 * on.
			 */
			auio.uio_resid = len = 100000000; /* Anything Big */
I 27
			auio.uio_procp = p;
E 27
E 25
			do {
I 22
			    rcvflg = 0;
E 22
			    error =  soreceive(so, (struct mbuf **)0,
D 25
				&auio, mp, (struct mbuf **)0, &rcvflg);
E 25
I 25
				&auio, mp, &control, &rcvflg);
			    if (control)
				m_freem(control);
E 25
			    if (error == EWOULDBLOCK && rep) {
				if (rep->r_flags & R_SOFTTERM)
					return (EINTR);
D 25
				if (rep->r_flags & R_MUSTRESEND)
					goto tryagain;
E 25
			    }
D 25
			} while (error == EWOULDBLOCK);
E 25
I 25
			} while (error == EWOULDBLOCK ||
				 (!error && *mp == NULL && control));
			if ((rcvflg & MSG_EOR) == 0)
				printf("Egad!!\n");
E 25
			if (!error && *mp == NULL)
				error = EPIPE;
			len -= auio.uio_resid;
E 13
		}
D 13
		/* Drop control mbuf's */
		if (m && m->m_type == MT_RIGHTS)
			panic("nfs_dgreceive 2");
		if (m && m->m_type == MT_CONTROL) {
			sbfree(&so->so_rcv, m);
			MFREE(m, so->so_rcv.sb_mb);
			m = so->so_rcv.sb_mb;
E 13
I 13
errout:
D 25
		if (error && rep && error != EINTR && error != ERESTART) {
E 25
I 25
		if (error && error != EINTR && error != ERESTART) {
E 25
			m_freem(*mp);
			*mp = (struct mbuf *)0;
I 22
D 28
			if (error != EPIPE && rep)
E 28
I 28
			if (error != EPIPE)
E 28
				log(LOG_INFO,
				    "receive error %d from nfs server %s\n",
				    error,
				 rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
E 22
D 25
			nfs_disconnect(rep->r_nmp);
			error = nfs_reconnect(rep, rep->r_nmp);
E 25
I 25
			error = nfs_sndlock(&rep->r_nmp->nm_flag, rep);
E 25
			if (!error)
I 25
				error = nfs_reconnect(rep);
			if (!error)
E 25
				goto tryagain;
E 13
		}
D 13
		/* Dequeue packet from sockbuf */
		*mp = m;
		while (m) {
			if (m->m_type != MT_DATA && m->m_type != MT_HEADER)
				panic("nfs_dgreceive 3");
			sbfree(&so->so_rcv, m);
			m = so->so_rcv.sb_mb = m->m_next;
E 13
I 13
	} else {
I 25
		if ((so = rep->r_nmp->nm_so) == NULL)
			return (EACCES);
E 25
		if (so->so_state & SS_ISCONNECTED)
			getnam = (struct mbuf **)0;
		else
			getnam = aname;
		auio.uio_resid = len = 1000000;
I 27
		auio.uio_procp = p;
E 27
		do {
I 22
			rcvflg = 0;
E 22
			error =  soreceive(so, getnam, &auio, mp,
				(struct mbuf **)0, &rcvflg);
D 25
			if (error == EWOULDBLOCK && rep &&
E 25
I 25
			if (error == EWOULDBLOCK &&
E 25
			    (rep->r_flags & R_SOFTTERM))
				return (EINTR);
		} while (error == EWOULDBLOCK);
		len -= auio.uio_resid;
	}
	if (error) {
		m_freem(*mp);
		*mp = (struct mbuf *)0;
	}
	/*
D 25
	 * Search for any mbufs that are not a multiple of 4 bytes long.
E 25
I 25
	 * Search for any mbufs that are not a multiple of 4 bytes long
	 * or with m_data not longword aligned.
E 25
	 * These could cause pointer alignment problems, so copy them to
	 * well aligned mbufs.
	 */
D 25
	m = *mp;
	mbp = mp;
	while (m) {
		/*
		 * All this for something that may never happen.
		 */
D 20
		if (m->m_len & 0x3) {
E 20
I 20
		if (m->m_next && (m->m_len & 0x3)) {
E 20
			printf("nfs_rcv odd length!\n");
D 20
			fcp = mtod(m, caddr_t);
			mnew = m2 = (struct mbuf *)0;
I 14
#ifdef lint
			m3 = (struct mbuf *)0;
E 20
			mlen = 0;
D 20
#endif /* lint */
E 20
E 14
			while (m) {
D 20
				if (m2 == NULL || mlen == 0) {
					MGET(m2, M_WAIT, MT_DATA);
					if (len > MINCLSIZE)
						MCLGET(m2, M_WAIT);
					m2->m_len = 0;
					mlen = M_TRAILINGSPACE(m2);
					tcp = mtod(m2, caddr_t);
					if (mnew) {
						m3->m_next = m2;
						m3 = m2;
					} else
						mnew = m3 = m2;
E 20
I 20
				fcp = mtod(m, caddr_t);
				while (m->m_len > 0) {
					if (mlen == 0) {
						MGET(m2, M_WAIT, MT_DATA);
						if (len >= MINCLSIZE)
							MCLGET(m2, M_WAIT);
						m2->m_len = 0;
						mlen = M_TRAILINGSPACE(m2);
						tcp = mtod(m2, caddr_t);
						*mbp = m2;
						mbp = &m2->m_next;
					}
					siz = MIN(mlen, m->m_len);
					bcopy(fcp, tcp, siz);
					m2->m_len += siz;
					mlen -= siz;
					len -= siz;
					tcp += siz;
					m->m_len -= siz;
					fcp += siz;
E 20
				}
D 20
				siz = (mlen > m->m_len) ? m->m_len : mlen;
				bcopy(fcp, tcp, siz);
				m2->m_len += siz;
				mlen -= siz;
				len -= siz;
				tcp += siz;
				m->m_len -= siz;
				fcp += siz;
				if (m->m_len == 0) {
					do {
						m = m->m_next;
					} while (m && m->m_len == 0);
					if (m)
						fcp = mtod(m, caddr_t);
				}
E 20
I 20
				MFREE(m, mnew);
				m = mnew;
E 20
			}
D 20
			m = *mbp;
			*mbp = mnew;
			m_freem(m);
E 20
			break;
E 13
		}
D 13
		so->so_rcv.sb_mb = nextrecord;
		/* Return */
		break;
E 13
I 13
		len -= m->m_len;
		mbp = &m->m_next;
		m = m->m_next;
E 13
E 7
	}
E 25
I 25
	nfs_realign(*mp, 5 * NFSX_UNSIGNED);
E 25
D 7
	*mp = m;
	while (m) {
		if (m->m_type != MT_DATA && m->m_type != MT_HEADER)
			panic("nfs_receive 3");
		sbfree(&so->so_rcv, m);
		m = so->so_rcv.sb_mb = m->m_next;
	}
	so->so_rcv.sb_mb = nextrecord;
	so->so_state &= ~SS_RCVATMARK;	/* Necessary ?? */
release:
E 7
D 13
	sbunlock(&so->so_rcv);
	splx(s);
E 13
	return (error);
}

D 7
struct nfsreq nfsreqh = {
	(struct nfsreq *)0,
	(struct nfsreq *)0,
	(struct mbuf *)0,
	(struct mbuf *)0,
	(struct nfsmount *)0,
	0, 0, 0, 0, 0,
};

E 7
D 20
struct rpc_replyhead {
	u_long	r_xid;
	u_long	r_rep;
};

E 20
/*
D 7
 * Implement receipt of reply on a socket.
E 7
I 7
D 13
 * Implement NFS client side datagram receive.
E 7
 * We depend on the way that records are added to the sockbuf
 * by sbappend*.  In particular, each record (mbufs linked through m_next)
 * must begin with an address, followed by optional MT_CONTROL mbuf
 * and then zero or more mbufs of data.
E 13
I 13
 * Implement receipt of reply on a socket.
E 13
D 7
 * Although the sockbuf is locked, new data may still be appended,
 * and thus we must maintain consistency of the sockbuf during that time.
E 7
 * We must search through the list of received datagrams matching them
 * with outstanding requests using the xid, until ours is found.
 */
I 5
D 7
/* ARGSUSED */
E 5
D 4
nfs_udpreply(so, mntp, repl, myrep)
E 4
I 4
nfs_udpreply(so, mntp, myrep)
E 7
I 7
D 13
nfs_dgreply(so, mntp, myrep)
E 7
E 4
	register struct socket *so;
	struct nfsmount *mntp;
E 13
I 13
/* ARGSUSED */
I 52
int
E 52
D 25
nfs_reply(nmp, myrep)
	struct nfsmount *nmp;
E 25
I 25
nfs_reply(myrep)
E 25
E 13
D 4
	struct nfsreq *repl, *myrep;
E 4
I 4
	struct nfsreq *myrep;
E 4
{
D 25
	register struct mbuf *m;
E 25
	register struct nfsreq *rep;
D 13
	register int error = 0, s;
I 7
	int logged = 0;
E 7
D 5
	struct protosw *pr = so->so_proto;
E 5
	struct mbuf *nextrecord;
E 13
I 13
D 25
	register int error = 0;
E 13
D 4
	struct sockaddr_in *sad, *sad2;
E 4
I 4
D 7
	struct sockaddr_in *saddr;
	u_long inaddr;
E 7
E 4
D 20
	struct rpc_replyhead replyh;
E 20
I 20
	u_long rxid;
E 20
I 13
	struct mbuf *mp, *nam;
	char *cp;
	int cnt, xfer;
E 25
I 25
	register struct nfsmount *nmp = myrep->r_nmp;
	register long t1;
	struct mbuf *mrep, *nam, *md;
	u_long rxid, *tl;
	caddr_t dpos, cp2;
	int error;
E 25
E 13
D 7
	struct mbuf *mp;
	char *cp;
	int cnt, xfer;
	int found;
E 7

D 13
restart:
I 4
	nfs_sblock(&so->so_rcv);
E 4
D 7
	/* Already received, bye bye */
E 7
I 7
	s = splnet();
	/* Already received and queued for us, bye bye */
E 7
D 4
	if (myrep->r_mrep != NULL)
E 4
I 4
	if (myrep->r_mrep != NULL) {
D 7
		sbunlock(&so->so_rcv);
E 4
		return (0);
E 7
I 7
		error = 0;
		goto release;
E 7
I 4
	}
E 4
D 7
	/* If a soft mount and we have run out of retries */
D 4
	if (myrep->r_retry == 0 && myrep->r_timer == 0)
E 4
I 4
	if (myrep->r_retry == 0 && myrep->r_timer == 0) {
		sbunlock(&so->so_rcv);
E 4
		return (ETIMEDOUT);
E 7
I 7
	/* If we have run out of retries (hard mounts have bogus count) */
	if (myrep->r_rexmit > myrep->r_retry) {
		error = ETIMEDOUT;
		nfsstats.rpctimeouts++;
giveup:
		if (myrep->r_flags & R_TIMING) {
			myrep->r_flags &= ~R_TIMING;
			mntp->nm_rtt = -1;
		}
		if (myrep->r_flags & R_SENT) {
			myrep->r_flags &= ~R_SENT;
			--mntp->nm_hostinfo->nh_sent;
			/* If count now 0, want to initiate new req */
		}
		goto release;
E 7
D 4
	nfs_sblock(&so->so_rcv);
E 4
I 4
	}
E 4
D 7
	s = splnet();
E 7

D 4
	if (so->so_rcv.sb_cc == 0) {
E 4
I 4
	m = so->so_rcv.sb_mb;
	if (m == 0) {
		if (so->so_rcv.sb_cc)
			panic("nfs_soreply 1");
E 4
D 7
		if (so->so_error) {
			error = so->so_error;
E 7
I 7
		if (error = nfs_sockerr(so, 0)) {
E 7
			so->so_error = 0;
D 7
			goto release;
E 7
I 7
			goto giveup;
E 7
		}
D 7
		if (so->so_state & SS_CANTRCVMORE)
			goto release;
E 7
I 7
		/* Allow signals to interrupt request? (nfs_timer wakes up) */
		if ((mntp->nm_flag & NFSMNT_INT) &&
D 10
		    u.u_procp->p_sig & ~u.u_procp->p_sigmask) {
E 10
I 10
		    (u.u_sigintr & sigmask(u.u_procp->p_cursig)) != 0) {
E 10
			error = EINTR;
			goto giveup;
		}
		if (mntp->nm_rexmit >= nfsrexmtthresh && logged++ == 0)
			uprintf("NFS server %s not responding, retrying\n",
D 9
				mntp->nm_host);
E 9
I 9
D 12
				mntp->nm_mountp->m_stat.f_mntfromname);
E 12
I 12
				mntp->nm_mountp->mnt_stat.f_mntfromname);
E 12
E 9
E 7
		sbunlock(&so->so_rcv);
		nfs_sbwait(&so->so_rcv);
		splx(s);
		goto restart;
	}
D 4
	m = so->so_rcv.sb_mb;
	if (m == 0)
		panic("nfs_soreply 1");
E 4
D 7
	nextrecord = m->m_nextpkt;
E 7

E 13
	/*
D 13
	 * Take off the address, check for rights and ditch any control
	 * mbufs.
E 13
I 13
	 * Loop around until we get our own reply
E 13
	 */
I 7
D 13
	nextrecord = m->m_nextpkt;
E 7
	if (m->m_type != MT_SONAME)
		panic("nfs reply SONAME");
D 4
	sad = mtod(m, struct sockaddr_in *);
	sad2 = mtod(mntp->nm_sockaddr, struct sockaddr_in *);
	found = 0;
	if (sad->sin_addr.s_addr != sad2->sin_addr.s_addr)
		goto dropit;
E 4
I 4
D 7
	saddr = mtod(m, struct sockaddr_in *);
	inaddr = saddr->sin_addr.s_addr;
E 7
E 4
	sbfree(&so->so_rcv, m);
	MFREE(m, so->so_rcv.sb_mb);
	m = so->so_rcv.sb_mb;
	if (m && m->m_type == MT_RIGHTS)
		panic("nfs reply RIGHTS");
	if (m && m->m_type == MT_CONTROL) {
		sbfree(&so->so_rcv, m);
		MFREE(m, so->so_rcv.sb_mb);
		m = so->so_rcv.sb_mb;
	}
D 4
	if (m)
E 4
I 4
	if (m) {
E 4
		m->m_nextpkt = nextrecord;
D 4
	else {
E 4
I 4
	} else {
		so->so_rcv.sb_mb = nextrecord;
E 4
		sbunlock(&so->so_rcv);
		splx(s);
		goto restart;
	}
E 13
I 13
	for (;;) {
		/*
		 * Lock against other receivers so that I don't get stuck in
		 * sbwait() after someone else has received my reply for me.
		 * Also necessary for connection based protocols to avoid
		 * race conditions during a reconnect.
		 */
D 18
		nfs_solock(&nmp->nm_flag, 1);
E 18
I 18
D 25
		nfs_solock(&nmp->nm_flag);
E 25
I 25
D 52
		if (error = nfs_rcvlock(myrep))
E 52
I 52
		error = nfs_rcvlock(myrep);
		if (error)
E 52
			return (error);
E 25
E 18
		/* Already received, bye bye */
		if (myrep->r_mrep != NULL) {
D 25
			nfs_sounlock(&nmp->nm_flag);
E 25
I 25
			nfs_rcvunlock(&nmp->nm_flag);
E 25
			return (0);
		}
		/*
		 * Get the next Rpc reply off the socket
		 */
D 25
		if (error = nfs_receive(nmp->nm_so, &nam, &mp, myrep)) {
			nfs_sounlock(&nmp->nm_flag);
E 25
I 25
		error = nfs_receive(myrep, &nam, &mrep);
		nfs_rcvunlock(&nmp->nm_flag);
D 44
if (error) printf("rcv err=%d\n",error);
E 44
		if (error) {
E 25
E 13

D 13
	/*
	 * Get the xid and check that it is an rpc reply
	 */
D 7
	mp = m;
	if (m->m_len >= 2*NFSX_UNSIGNED)
		bcopy(mtod(m, caddr_t), (caddr_t)&replyh, 2*NFSX_UNSIGNED);
E 7
I 7
	if (m->m_len >= sizeof replyh)
		bcopy(mtod(m, caddr_t), (caddr_t)&replyh, sizeof replyh);
E 7
	else {
D 7
		cnt = 2*NFSX_UNSIGNED;
		cp = (caddr_t)&replyh;
		while (mp && cnt > 0) {
E 7
I 7
		struct mbuf *mp = m;
		caddr_t cp = (caddr_t)&replyh;
		int cnt = sizeof replyh;
		do {
E 7
			if (mp->m_len > 0) {
D 7
				xfer = (mp->m_len >= cnt) ? cnt : mp->m_len;
E 7
I 7
				int xfer = (mp->m_len >= cnt) ? cnt : mp->m_len;
E 7
				bcopy(mtod(mp, caddr_t), cp, xfer);
				cnt -= xfer;
				cp += xfer;
E 13
I 13
			/*
			 * Ignore routing errors on connectionless protocols??
			 */
			if (NFSIGNORE_SOERROR(nmp->nm_soflags, error)) {
				nmp->nm_so->so_error = 0;
I 45
				if (myrep->r_flags & R_GETONEREP)
					return (0);
E 45
				continue;
E 13
			}
D 13
			if (cnt > 0)
				mp = mp->m_next;
I 7
		} while (mp && cnt > 0);
		if (mp == NULL) {		/* Insufficient length */
E 13
I 13
D 25

			/*
			 * Otherwise cleanup and return a fatal error.
			 */
			if (myrep->r_flags & R_TIMING) {
				myrep->r_flags &= ~R_TIMING;
				nmp->nm_rtt = -1;
			}
			if (myrep->r_flags & R_SENT) {
				myrep->r_flags &= ~R_SENT;
				nmp->nm_sent--;
			}
E 25
			return (error);
		}
I 25
		if (nam)
			m_freem(nam);
E 25
	
		/*
		 * Get the xid and check that it is an rpc reply
		 */
D 25
		m = mp;
D 20
		if (m->m_len >= 2*NFSX_UNSIGNED)
			bcopy(mtod(m, caddr_t), (caddr_t)&replyh,
				2*NFSX_UNSIGNED);
		else {
			cnt = 2*NFSX_UNSIGNED;
			cp = (caddr_t)&replyh;
			while (m && cnt > 0) {
				if (m->m_len > 0) {
					xfer = (m->m_len >= cnt) ? cnt :
						m->m_len;
					bcopy(mtod(m, caddr_t), cp, xfer);
					cnt -= xfer;
					cp += xfer;
				}
				if (cnt > 0)
					m = m->m_next;
			}
		}
		if (replyh.r_rep != rpc_reply || m == NULL) {
E 20
I 20
		while (m && m->m_len == 0)
			m = m->m_next;
		if (m == NULL) {
E 20
E 13
			nfsstats.rpcinvalid++;
D 13
			goto dropit;
E 13
I 13
			m_freem(mp);
			nfs_sounlock(&nmp->nm_flag);
E 25
I 25
		md = mrep;
		dpos = mtod(md, caddr_t);
		nfsm_dissect(tl, u_long *, 2*NFSX_UNSIGNED);
		rxid = *tl++;
		if (*tl != rpc_reply) {
			if (nmp->nm_flag & NFSMNT_NQNFS) {
				if (nqnfs_callback(nmp, mrep, md, dpos))
					nfsstats.rpcinvalid++;
			} else {
				nfsstats.rpcinvalid++;
				m_freem(mrep);
			}
nfsmout:
I 45
			if (myrep->r_flags & R_GETONEREP)
				return (0);
E 45
E 25
			continue;
E 13
E 7
		}
I 20
D 25
		bcopy(mtod(m, caddr_t), (caddr_t)&rxid, NFSX_UNSIGNED);
E 25
I 25

E 25
E 20
D 13
	}
I 4
D 7
	found = 0;
E 4
	if (replyh.r_rep != rpc_reply || mp == NULL)
E 7
I 7
	if (replyh.r_rep != rpc_reply) {	/* Not a reply */
		nfsstats.rpcinvalid++;
E 7
		goto dropit;
I 7
	}
E 7
	/*
	 * Loop through the request list to match up the reply
D 7
	 * Iff no match, just drop the datagram
E 7
I 7
	 * If no match, just drop the datagram
E 7
	 */
D 4
	rep = repl;
	while (!found && rep) {
		if (rep->r_mrep == NULL && replyh.r_xid == rep->r_xid) {
E 4
I 4
D 7
	rep = nfsreqh.r_next;
	while (!found && rep != &nfsreqh) {
		if (rep->r_mrep == NULL && replyh.r_xid == rep->r_xid &&
		    inaddr == rep->r_inaddr) {
E 7
I 7
	if (rep = nfsreqh.r_next) {
	    while (rep != &nfsreqh) {
		/* The socket, being connected, will only queue matches */
		if (replyh.r_xid == rep->r_xid && so == rep->r_mntp->nm_so) {
E 7
E 4
			/* Found it.. */
I 7
			if (rep->r_mrep)	/* Already there - duplicate */
E 13
I 13
		/*
		 * Loop through the request list to match up the reply
		 * Iff no match, just drop the datagram
		 */
D 25
		m = mp;
E 25
D 51
		rep = nfsreqh.r_next;
		while (rep != &nfsreqh) {
E 51
I 51
		for (rep = nfs_reqq.tqh_first; rep != 0;
		    rep = rep->r_chain.tqe_next) {
E 51
D 20
			if (rep->r_mrep == NULL && replyh.r_xid == rep->r_xid) {
E 20
I 20
			if (rep->r_mrep == NULL && rxid == rep->r_xid) {
E 20
				/* Found it.. */
D 25
				rep->r_mrep = m;
E 25
I 25
				rep->r_mrep = mrep;
				rep->r_md = md;
				rep->r_dpos = dpos;
				if (nfsrtton) {
					struct rttl *rt;

					rt = &nfsrtt.rttl[nfsrtt.pos];
					rt->proc = rep->r_procnum;
					rt->rto = NFS_RTO(nmp, proct[rep->r_procnum]);
					rt->sent = nmp->nm_sent;
					rt->cwnd = nmp->nm_cwnd;
					rt->srtt = nmp->nm_srtt[proct[rep->r_procnum] - 1];
					rt->sdrtt = nmp->nm_sdrtt[proct[rep->r_procnum] - 1];
					rt->fsid = nmp->nm_mountp->mnt_stat.f_fsid;
					rt->tstamp = time;
					if (rep->r_flags & R_TIMING)
						rt->rtt = rep->r_rtt;
					else
						rt->rtt = 1000000;
					nfsrtt.pos = (nfsrtt.pos + 1) % NFSRTTLOGSIZ;
				}
E 25
				/*
D 25
				 * Update timing
E 25
I 25
				 * Update congestion window.
				 * Do the additive increase of
				 * one rpc/rtt.
E 25
				 */
I 25
				if (nmp->nm_cwnd <= nmp->nm_sent) {
					nmp->nm_cwnd +=
					   (NFS_CWNDSCALE * NFS_CWNDSCALE +
					   (nmp->nm_cwnd >> 1)) / nmp->nm_cwnd;
					if (nmp->nm_cwnd > NFS_MAXCWND)
						nmp->nm_cwnd = NFS_MAXCWND;
				}
I 43
				rep->r_flags &= ~R_SENT;
				nmp->nm_sent -= NFS_CWNDSCALE;
E 43
D 42
				nmp->nm_sent -= NFS_CWNDSCALE;
E 42
				/*
				 * Update rtt using a gain of 0.125 on the mean
				 * and a gain of 0.25 on the deviation.
				 */
E 25
				if (rep->r_flags & R_TIMING) {
D 25
					nfs_updatetimer(rep->r_nmp);
					rep->r_flags &= ~R_TIMING;
					rep->r_nmp->nm_rtt = -1;
E 25
I 25
					/*
					 * Since the timer resolution of
					 * NFS_HZ is so course, it can often
					 * result in r_rtt == 0. Since
					 * r_rtt == N means that the actual
					 * rtt is between N+dt and N+2-dt ticks,
					 * add 1.
					 */
					t1 = rep->r_rtt + 1;
					t1 -= (NFS_SRTT(rep) >> 3);
					NFS_SRTT(rep) += t1;
					if (t1 < 0)
						t1 = -t1;
					t1 -= (NFS_SDRTT(rep) >> 2);
					NFS_SDRTT(rep) += t1;
E 25
				}
D 25
				if (rep->r_flags & R_SENT) {
					rep->r_flags &= ~R_SENT;
					rep->r_nmp->nm_sent--;
				}
E 25
I 25
				nmp->nm_timeouts = 0;
E 25
E 13
				break;
E 7
D 13
			rep->r_mrep = m;
			while (m) {
				if (m->m_type != MT_DATA && m->m_type != MT_HEADER)
					panic("nfs_soreply 3");
				sbfree(&so->so_rcv, m);
				m = so->so_rcv.sb_mb = m->m_next;
E 13
			}
D 13
			so->so_rcv.sb_mb = nextrecord;
D 7
			if (rep == myrep)
E 7
I 7
			if (rep->r_flags & R_TIMING) {
				nfs_updatetimer(mntp);
				rep->r_flags &= ~R_TIMING;
				mntp->nm_rtt = -1;	/* re-arm timer */
			}
			if (rep->r_flags & R_SENT) {
				rep->r_flags &= ~R_SENT;
				--mntp->nm_hostinfo->nh_sent;
				/* If count now 0, want to initiate new req */
			}
			if (rep == myrep) {		/* This is success */
				if (logged)
D 12
					uprintf("NFS server %s responded\n",
D 9
						mntp->nm_host);
E 9
I 9
					mntp->nm_mountp->m_stat.f_mntfromname);
E 12
I 12
				    uprintf("NFS server %s responded\n",
				       mntp->nm_mountp->mnt_stat.f_mntfromname);
E 12
E 9
E 7
				goto release;
D 7
			found++;
E 7
I 7
			}
			/* Else wake up other sleeper and wait for next */
			sbunlock(&so->so_rcv);
			sorwakeup(so);
			splx(s);
			goto restart;
E 13
I 13
D 51
			rep = rep->r_next;
E 51
E 13
E 7
		}
D 13
		rep = rep->r_next;
I 7
	    }
E 13
I 13
D 25
		nfs_sounlock(&nmp->nm_flag);
		if (nam)
			m_freem(nam);
E 25
		/*
		 * If not matched to a request, drop it.
		 * If it's mine, get out.
		 */
D 51
		if (rep == &nfsreqh) {
E 51
I 51
		if (rep == 0) {
E 51
			nfsstats.rpcunexpected++;
D 25
			m_freem(m);
E 25
I 25
			m_freem(mrep);
E 25
D 31
		} else if (rep == myrep)
E 31
I 31
		} else if (rep == myrep) {
			if (rep->r_mrep == NULL)
				panic("nfsreply nil");
E 31
			return (0);
I 31
		}
I 45
		if (myrep->r_flags & R_GETONEREP)
			return (0);
E 45
E 31
E 13
E 7
	}
D 7
	/* Iff not matched to request, drop it */
E 7
I 7
D 13
	/* If not matched to request, drop it */
	nfsstats.rpcunexpected++;
E 7
dropit:
D 4
	if (!found)
E 4
I 4
D 7
	if (!found) {
E 4
		sbdroprecord(&so->so_rcv);
I 4
	} else if (so->so_rcv.sb_flags & SB_WAIT) {
		so->so_rcv.sb_flags &= ~SB_WAIT;
		wakeup((caddr_t)&so->so_rcv.sb_cc);
	}
E 7
I 7
	sbdroprecord(&so->so_rcv);
E 7
E 4
	sbunlock(&so->so_rcv);
	splx(s);
	goto restart;
I 7

E 7
release:
	sbunlock(&so->so_rcv);
	splx(s);
	return (error);
E 13
}

/*
 * nfs_request - goes something like this
 *	- fill in request struct
 *	- links it into list
D 13
 *	- calls nfs_sosend() for first transmit
 *	- calls nfs_soreceive() to get reply
E 13
I 13
 *	- calls nfs_send() for first transmit
 *	- calls nfs_receive() to get reply
E 13
 *	- break down rpc header and return with nfs reply pointed to
 *	  by mrep or error
 * nb: always frees up mreq mbuf list
 */
I 52
int
E 52
D 7
nfs_request(vp, mreq, xid, mp, mrp, mdp, dposp)
E 7
I 7
D 13
nfs_request(vp, mreq, xid, idem, mp, mrp, mdp, dposp)
E 13
I 13
D 18
nfs_request(vp, mreq, xid, procnum, procp, mp, mrp, mdp, dposp)
E 18
I 18
D 25
nfs_request(vp, mreq, xid, procnum, procp, tryhard, mp, mrp, mdp, dposp)
E 25
I 25
nfs_request(vp, mrest, procnum, procp, cred, mrp, mdp, dposp)
E 25
E 18
E 13
E 7
	struct vnode *vp;
D 25
	struct mbuf *mreq;
	u_long xid;
E 25
I 25
	struct mbuf *mrest;
E 25
I 7
D 13
	int idem;
E 13
I 13
	int procnum;
	struct proc *procp;
I 18
D 25
	int tryhard;
E 18
E 13
E 7
	struct mount *mp;
E 25
I 25
	struct ucred *cred;
E 25
	struct mbuf **mrp;
	struct mbuf **mdp;
	caddr_t *dposp;
{
	register struct mbuf *m, *mrep;
	register struct nfsreq *rep;
D 23
	register u_long *p;
E 23
I 23
	register u_long *tl;
E 23
D 25
	register int len;
E 25
I 25
	register int i;
E 25
D 13
	struct nfsmount *mntp;
E 13
I 13
	struct nfsmount *nmp;
E 13
D 25
	struct mbuf *md;
E 25
I 25
	struct mbuf *md, *mheadend;
E 25
I 4
D 7
	struct sockaddr_in *saddr;
E 7
D 52
	struct nfsreq *reph;
E 52
E 4
D 25
	caddr_t dpos;
	char *cp2;
	int t1;
D 20
	int s;
E 20
I 20
	int s, compressed;
E 20
D 13
	int error;
E 13
I 13
	int error = 0;
E 25
I 25
D 50
	struct nfsnode *tp, *np;
E 50
I 50
	struct nfsnode *np;
I 52
	char nickv[RPCX_NICKVERF];
E 52
E 50
	time_t reqtime, waituntil;
	caddr_t dpos, cp2;
	int t1, nqlflag, cachable, s, error = 0, mrest_len, auth_len, auth_type;
	int trylater_delay = NQ_TRYLATERDEL, trylater_cnt = 0, failed_auth = 0;
I 52
	int verf_len, verf_type;
E 52
	u_long xid;
I 38
	u_quad_t frev;
E 38
D 52
	char *auth_str;
E 52
I 52
	char *auth_str, *verf_str;
	NFSKERBKEY_T key;		/* save session key */
E 52
E 25
E 13

D 12
	mntp = vfs_to_nfs(mp);
E 12
I 12
D 13
	mntp = VFSTONFS(mp);
E 13
I 13
D 25
	nmp = VFSTONFS(mp);
E 13
E 12
	m = mreq;
E 25
I 25
	nmp = VFSTONFS(vp->v_mount);
E 25
	MALLOC(rep, struct nfsreq *, sizeof(struct nfsreq), M_NFSREQ, M_WAITOK);
D 25
	rep->r_xid = xid;
E 25
D 13
	rep->r_mntp = mntp;
E 13
I 13
	rep->r_nmp = nmp;
E 13
I 4
D 7
	saddr = mtod(mntp->nm_sockaddr, struct sockaddr_in *);
	rep->r_inaddr = saddr->sin_addr.s_addr;
E 7
E 4
	rep->r_vp = vp;
D 13
	if (mntp->nm_flag & NFSMNT_SOFT)
D 7
		rep->r_retry = mntp->nm_retrans;
E 7
I 7
		rep->r_retry = mntp->nm_retry;
E 13
I 13
	rep->r_procp = procp;
D 18
	if (nmp->nm_flag & NFSMNT_SOFT)
E 18
I 18
D 25
	if ((nmp->nm_flag & NFSMNT_SOFT) ||
	    ((nmp->nm_flag & NFSMNT_SPONGY) && !tryhard))
E 18
		rep->r_retry = nmp->nm_retry;
E 13
E 7
	else
D 7
		rep->r_retry = VNOVAL;
E 7
I 7
		rep->r_retry = NFS_MAXREXMIT + 1;	/* past clip limit */
	rep->r_flags = rep->r_rexmit = 0;
D 13
	/* Idempotency: add N * MINTIMEO to requests if not, else use 0 */
	rep->r_timer = rep->r_timerinit = -(idem * NFS_MINTIMEO);
E 13
I 13
	/*
	 * Three cases:
	 * - non-idempotent requests on SOCK_DGRAM use NFS_MINIDEMTIMEO
	 * - idempotent requests on SOCK_DGRAM use 0
	 * - Reliable transports, NFS_RELIABLETIMEO
	 *   Timeouts are still done on reliable transports to ensure detection
D 18
	 *   of connection loss.
E 18
I 18
	 *   of excessive connection delay.
E 18
	 */
	if (nmp->nm_sotype != SOCK_DGRAM)
		rep->r_timerinit = -NFS_RELIABLETIMEO;
	else if (nonidempotent[procnum])
		rep->r_timerinit = -NFS_MINIDEMTIMEO;
	else
		rep->r_timerinit = 0;
	rep->r_timer = rep->r_timerinit;
E 13
E 7
	rep->r_mrep = NULL;
D 13
	rep->r_mreq = m;
E 13
D 7
	rep->r_timer = rep->r_timeout = mntp->nm_timeo;
E 7
	len = 0;
E 25
I 25
	rep->r_procnum = procnum;
	i = 0;
	m = mrest;
E 25
	while (m) {
D 25
		len += m->m_len;
E 25
I 25
		i += m->m_len;
E 25
		m = m->m_next;
	}
D 13
	rep->r_msiz = len;
E 13
I 13
D 25
	mreq->m_pkthdr.len = len;
	mreq->m_pkthdr.rcvif = (struct ifnet *)0;
I 20
	compressed = 0;
	m = mreq;
	if ((nmp->nm_flag & NFSMNT_COMPRESS) && compressrequest[procnum]) {
		mreq = nfs_compress(mreq);
		if (mreq != m) {
			len = mreq->m_pkthdr.len;
			compressed++;
E 25
I 25
	mrest_len = i;

	/*
	 * Get the RPC header with authorization.
	 */
kerbauth:
D 52
	auth_str = (char *)0;
E 52
I 52
	verf_str = auth_str = (char *)0;
E 52
	if (nmp->nm_flag & NFSMNT_KERB) {
D 52
		if (failed_auth) {
			error = nfs_getauth(nmp, rep, cred, &auth_type,
				&auth_str, &auth_len);
E 52
I 52
		verf_str = nickv;
		verf_len = sizeof (nickv);
		auth_type = RPCAUTH_KERB4;
		bzero((caddr_t)key, sizeof (key));
		if (failed_auth || nfs_getnickauth(nmp, cred, &auth_str,
			&auth_len, verf_str, verf_len)) {
			error = nfs_getauth(nmp, rep, cred, &auth_str,
				&auth_len, verf_str, &verf_len, key);
E 52
			if (error) {
				free((caddr_t)rep, M_NFSREQ);
				m_freem(mrest);
				return (error);
			}
D 52
		} else {
			auth_type = RPCAUTH_UNIX;
			auth_len = 5 * NFSX_UNSIGNED;
E 52
E 25
		}
I 25
	} else {
		auth_type = RPCAUTH_UNIX;
I 31
		if (cred->cr_ngroups < 1)
			panic("nfsreq nogrps");
E 31
		auth_len = ((((cred->cr_ngroups - 1) > nmp->nm_numgrps) ?
			nmp->nm_numgrps : (cred->cr_ngroups - 1)) << 2) +
			5 * NFSX_UNSIGNED;
E 25
	}
I 25
D 52
	m = nfsm_rpchead(cred, (nmp->nm_flag & NFSMNT_NQNFS), procnum,
	     auth_type, auth_len, auth_str, mrest, mrest_len, &mheadend, &xid);
E 52
I 52
	m = nfsm_rpchead(cred, nmp->nm_flag, procnum, auth_type, auth_len,
	     auth_str, verf_len, verf_str, mrest, mrest_len, &mheadend, &xid);
E 52
	if (auth_str)
		free(auth_str, M_TEMP);

E 25
E 20
	/*
D 25
	 * For non-atomic protocols, insert a Sun RPC Record Mark.
E 25
I 25
	 * For stream protocols, insert a Sun RPC Record Mark.
E 25
	 */
D 25
	if ((nmp->nm_soflags & PR_ATOMIC) == 0) {
		M_PREPEND(mreq, sizeof(u_long), M_WAIT);
		*mtod(mreq, u_long *) = htonl(0x80000000 | len);
E 25
I 25
	if (nmp->nm_sotype == SOCK_STREAM) {
		M_PREPEND(m, NFSX_UNSIGNED, M_WAIT);
		*mtod(m, u_long *) = htonl(0x80000000 |
			 (m->m_pkthdr.len - NFSX_UNSIGNED));
E 25
	}
D 25
	rep->r_mreq = mreq;
E 25
I 25
	rep->r_mreq = m;
	rep->r_xid = xid;
tryagain:
	if (nmp->nm_flag & NFSMNT_SOFT)
		rep->r_retry = nmp->nm_retry;
	else
		rep->r_retry = NFS_MAXREXMIT + 1;	/* past clip limit */
	rep->r_rtt = rep->r_rexmit = 0;
	if (proct[procnum] > 0)
		rep->r_flags = R_TIMING;
	else
		rep->r_flags = 0;
	rep->r_mrep = NULL;
E 25
E 13
D 7
	m = NFSMCOPY(mreq, 0, M_COPYALL, M_WAIT);
E 7

D 7
	/* Chain it into list of outstanding requests */
I 4
	reph = &nfsreqh;
E 7
I 7
	/*
	 * Do the client side RPC.
	 */
	nfsstats.rpcrequests++;
I 13
	/*
	 * Chain request into list of outstanding requests. Be sure
	 * to put it LAST so timer finds oldest requests first.
	 */
E 13
E 7
E 4
D 25
	s = splnet();
E 25
I 25
	s = splsoftclock();
E 25
I 7
D 13
	/* Chain request into list of outstanding requests. Be sure
	 * to put it LAST so timer finds oldest requests first. */
E 13
D 51
	reph = &nfsreqh;
E 7
D 4
	rep->r_next = nfsreqh.r_next;
	if (rep->r_next != NULL)
		rep->r_next->r_prev = rep;
	nfsreqh.r_next = rep;
	rep->r_prev = &nfsreqh;
E 4
I 4
D 13
	if (reph->r_prev == NULL) {
		reph->r_next = rep;
		rep->r_prev = reph;
	} else {
		reph->r_prev->r_next = rep;
		rep->r_prev = reph->r_prev;
	}
E 13
I 13
	reph->r_prev->r_next = rep;
	rep->r_prev = reph->r_prev;
E 13
	reph->r_prev = rep;
	rep->r_next = reph;
E 51
I 51
	TAILQ_INSERT_TAIL(&nfs_reqq, rep, r_chain);
E 51
I 25

	/* Get send time for nqnfs */
	reqtime = time.tv_sec;

E 25
I 7
	/*
	 * If backing off another request or avoiding congestion, don't
	 * send this one now but let timer do it. If not timing a request,
	 * do it now.
	 */
D 13
	if (mntp->nm_hostinfo->nh_sent > 0 &&
	    (mntp->nm_hostinfo->nh_currexmit != 0 ||
	     mntp->nm_hostinfo->nh_sent >= mntp->nm_hostinfo->nh_window)) {
E 13
I 13
D 25
	if (nmp->nm_sent <= 0 || nmp->nm_sotype != SOCK_DGRAM ||
	    (nmp->nm_currexmit == 0 && nmp->nm_sent < nmp->nm_window)) {
		nmp->nm_sent++;
		rep->r_flags |= R_SENT;
		if (nmp->nm_rtt == -1) {
			nmp->nm_rtt = 0;
			rep->r_flags |= R_TIMING;
		}
E 25
I 25
	if (nmp->nm_so && (nmp->nm_sotype != SOCK_DGRAM ||
		(nmp->nm_flag & NFSMNT_DUMBTIMR) ||
		nmp->nm_sent < nmp->nm_cwnd)) {
E 25
E 13
		splx(s);
D 13
		goto skipsend;
	}
	++mntp->nm_hostinfo->nh_sent;	/* Inconsistent if can't NFSMCOPY */
	rep->r_flags |= R_SENT;		/* But not a catastrophe */
	if (mntp->nm_rtt == -1) {
		mntp->nm_rtt = 0;
		rep->r_flags |= R_TIMING;
	}
E 7
E 4
	splx(s);
E 13
I 13
D 25
		m = m_copym(mreq, 0, M_COPYALL, M_WAIT);
E 25
		if (nmp->nm_soflags & PR_CONNREQUIRED)
D 18
			nfs_solock(&nmp->nm_flag, 1);
E 18
I 18
D 25
			nfs_solock(&nmp->nm_flag);
E 18
		error = nfs_send(nmp->nm_so, nmp->nm_nam, m, rep);
		if (nmp->nm_soflags & PR_CONNREQUIRED)
			nfs_sounlock(&nmp->nm_flag);
		if (error && NFSIGNORE_SOERROR(nmp->nm_soflags, error))
			nmp->nm_so->so_error = error = 0;
	} else
E 25
I 25
			error = nfs_sndlock(&nmp->nm_flag, rep);
		if (!error) {
			m = m_copym(m, 0, M_COPYALL, M_WAIT);
			error = nfs_send(nmp->nm_so, nmp->nm_nam, m, rep);
			if (nmp->nm_soflags & PR_CONNREQUIRED)
				nfs_sndunlock(&nmp->nm_flag);
		}
		if (!error && (rep->r_flags & R_MUSTRESEND) == 0) {
			nmp->nm_sent += NFS_CWNDSCALE;
			rep->r_flags |= R_SENT;
		}
	} else {
E 25
		splx(s);
I 25
		rep->r_rtt = -1;
	}
E 25
E 13

	/*
D 7
	 * Iff the NFSMCOPY above succeeded, send it off...
E 7
I 7
D 13
	 * If we can get a packet to send, send it off...
E 7
	 * otherwise the timer will retransmit later
	 */
I 7
	m = NFSMCOPY(mreq, 0, M_COPYALL, M_WAIT);
E 7
	if (m != NULL)
D 7
		error = nfs_udpsend(mntp->nm_so, (struct mbuf *)0, m, 0, len);
D 4
	error = nfs_udpreply(mntp->nm_so, mntp, nfsreqh.r_next, rep);
E 4
I 4
	error = nfs_udpreply(mntp->nm_so, mntp, rep);
E 7
I 7
		(void) nfs_send(mntp->nm_so, (struct mbuf *)0, m, 0, len);
	/*
E 13
	 * Wait for the reply from our send or the timer's.
	 */
D 13
skipsend:
	error = nfs_dgreply(mntp->nm_so, mntp, rep);
E 13
I 13
D 32
	if (!error)
E 32
I 32
	if (!error || error == EPIPE)
E 32
D 25
		error = nfs_reply(nmp, rep);
E 25
I 25
		error = nfs_reply(rep);
E 25
E 13
E 7
E 4

I 7
	/*
	 * RPC done, unlink the request.
	 */
E 7
D 25
	s = splnet();
E 25
I 25
	s = splsoftclock();
E 25
D 51
	rep->r_prev->r_next = rep->r_next;
D 4
	if (rep->r_next != NULL)
		rep->r_next->r_prev = rep->r_prev;
E 4
I 4
	rep->r_next->r_prev = rep->r_prev;
E 51
I 51
	TAILQ_REMOVE(&nfs_reqq, rep, r_chain);
E 51
E 4
	splx(s);
I 42

	/*
	 * Decrement the outstanding request count.
	 */
D 43
	if (rep->r_flags & R_SENT)
E 43
I 43
	if (rep->r_flags & R_SENT) {
		rep->r_flags &= ~R_SENT;	/* paranoia */
E 43
		nmp->nm_sent -= NFS_CWNDSCALE;
I 43
	}
E 43
E 42
I 13

	/*
	 * If there was a successful reply and a tprintf msg.
	 * tprintf a response.
	 */
D 22
	if (!error && (rep->r_flags & R_TPRINTFMSG)) {
		if (rep->r_procp)
D 16
			tprintf(rep->r_procp->p_session->s_ttyvp,
E 16
I 16
			tprintf(rep->r_procp->p_session,
E 16
				"Nfs server %s, is alive again\n",
				rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
		else
D 16
			tprintf(NULLVP, "Nfs server %s, is alive again\n",
E 16
I 16
			tprintf(NULL, "Nfs server %s, is alive again\n",
E 16
				rep->r_nmp->nm_mountp->mnt_stat.f_mntfromname);
	}
E 22
I 22
	if (!error && (rep->r_flags & R_TPRINTFMSG))
		nfs_msg(rep->r_procp, nmp->nm_mountp->mnt_stat.f_mntfromname,
		    "is alive again");
E 22
E 13
D 25
	m_freem(rep->r_mreq);
E 25
D 20
	mrep = md = rep->r_mrep;
E 20
I 20
	mrep = rep->r_mrep;
E 20
D 25
	FREE((caddr_t)rep, M_NFSREQ);
	if (error)
E 25
I 25
	md = rep->r_md;
	dpos = rep->r_dpos;
	if (error) {
		m_freem(rep->r_mreq);
		free((caddr_t)rep, M_NFSREQ);
E 25
		return (error);
I 25
	}
E 25

I 20
D 25
	if (compressed)
		mrep = nfs_uncompress(mrep);
	md = mrep;
E 25
E 20
	/*
	 * break down the rpc header and check if ok
	 */
D 25
	dpos = mtod(md, caddr_t);
D 23
	nfsm_disect(p, u_long *, 5*NFSX_UNSIGNED);
	p += 2;
	if (*p++ == rpc_msgdenied) {
		if (*p == rpc_mismatch)
E 23
I 23
	nfsm_disect(tl, u_long *, 5*NFSX_UNSIGNED);
	tl += 2;
E 25
I 25
D 52
	nfsm_dissect(tl, u_long *, 3*NFSX_UNSIGNED);
E 52
I 52
	nfsm_dissect(tl, u_long *, 3 * NFSX_UNSIGNED);
E 52
E 25
	if (*tl++ == rpc_msgdenied) {
		if (*tl == rpc_mismatch)
E 23
			error = EOPNOTSUPP;
D 25
		else
E 25
I 25
		else if ((nmp->nm_flag & NFSMNT_KERB) && *tl++ == rpc_autherr) {
D 52
			if (*tl == rpc_rejectedcred && failed_auth == 0) {
E 52
I 52
			if (!failed_auth) {
E 52
				failed_auth++;
				mheadend->m_next = (struct mbuf *)0;
				m_freem(mrep);
				m_freem(rep->r_mreq);
				goto kerbauth;
			} else
				error = EAUTH;
		} else
E 25
			error = EACCES;
		m_freem(mrep);
I 25
		m_freem(rep->r_mreq);
		free((caddr_t)rep, M_NFSREQ);
E 25
		return (error);
	}
I 25

E 25
	/*
D 52
	 * skip over the auth_verf, someday we may want to cache auth_short's
	 * for nfs_reqhead(), but for now just dump it
E 52
I 52
	 * Grab any Kerberos verifier, otherwise just throw it away.
E 52
	 */
D 23
	if (*++p != 0) {
		len = nfsm_rndup(fxdr_unsigned(long, *p));
E 23
I 23
D 52
	if (*++tl != 0) {
D 25
		len = nfsm_rndup(fxdr_unsigned(long, *tl));
E 23
		nfsm_adv(len);
E 25
I 25
		i = nfsm_rndup(fxdr_unsigned(long, *tl));
		nfsm_adv(i);
E 25
	}
E 52
I 52
	verf_type = fxdr_unsigned(int, *tl++);
	i = fxdr_unsigned(int, *tl);
	if ((nmp->nm_flag & NFSMNT_KERB) && verf_type == RPCAUTH_KERB4) {
		error = nfs_savenickauth(nmp, cred, i, key, &md, &dpos, mrep);
		if (error)
			goto nfsmout;
	} else if (i > 0)
		nfsm_adv(nfsm_rndup(i));
E 52
D 23
	nfsm_disect(p, u_long *, NFSX_UNSIGNED);
E 23
I 23
D 25
	nfsm_disect(tl, u_long *, NFSX_UNSIGNED);
E 25
I 25
	nfsm_dissect(tl, u_long *, NFSX_UNSIGNED);
E 25
E 23
	/* 0 == ok */
D 23
	if (*p == 0) {
		nfsm_disect(p, u_long *, NFSX_UNSIGNED);
		if (*p != 0) {
			error = fxdr_unsigned(int, *p);
E 23
I 23
	if (*tl == 0) {
D 25
		nfsm_disect(tl, u_long *, NFSX_UNSIGNED);
E 25
I 25
		nfsm_dissect(tl, u_long *, NFSX_UNSIGNED);
E 25
		if (*tl != 0) {
			error = fxdr_unsigned(int, *tl);
E 23
D 52
			m_freem(mrep);
I 25
			if ((nmp->nm_flag & NFSMNT_NQNFS) &&
			    error == NQNFS_TRYLATER) {
E 52
I 52
			if ((nmp->nm_flag & NFSMNT_NFSV3) &&
				error == NFSERR_TRYLATER) {
				m_freem(mrep);
E 52
				error = 0;
				waituntil = time.tv_sec + trylater_delay;
				while (time.tv_sec < waituntil)
					(void) tsleep((caddr_t)&lbolt,
						PSOCK, "nqnfstry", 0);
				trylater_delay *= nfs_backoff[trylater_cnt];
				if (trylater_cnt < 7)
					trylater_cnt++;
				goto tryagain;
			}
I 38

			/*
			 * If the File Handle was stale, invalidate the
			 * lookup cache, just in case.
			 */
			if (error == ESTALE)
				cache_purge(vp);
I 52
			if (nmp->nm_flag & NFSMNT_NFSV3) {
				*mrp = mrep;
				*mdp = md;
				*dposp = dpos;
				error |= NFSERR_RETERR;
			} else
				m_freem(mrep);
E 52
E 38
			m_freem(rep->r_mreq);
			free((caddr_t)rep, M_NFSREQ);
E 25
			return (error);
		}
I 25

		/*
		 * For nqnfs, get any lease in reply
		 */
		if (nmp->nm_flag & NFSMNT_NQNFS) {
			nfsm_dissect(tl, u_long *, NFSX_UNSIGNED);
			if (*tl) {
				np = VTONFS(vp);
				nqlflag = fxdr_unsigned(int, *tl);
				nfsm_dissect(tl, u_long *, 4*NFSX_UNSIGNED);
				cachable = fxdr_unsigned(int, *tl++);
				reqtime += fxdr_unsigned(int, *tl++);
				if (reqtime > time.tv_sec) {
D 38
				    if (np->n_tnext) {
					if (np->n_tnext == (struct nfsnode *)nmp)
					    nmp->nm_tprev = np->n_tprev;
					else
					    np->n_tnext->n_tprev = np->n_tprev;
					if (np->n_tprev == (struct nfsnode *)nmp)
					    nmp->nm_tnext = np->n_tnext;
					else
					    np->n_tprev->n_tnext = np->n_tnext;
					if (nqlflag == NQL_WRITE)
					    np->n_flag |= NQNFSWRITE;
				    } else if (nqlflag == NQL_READ)
					np->n_flag &= ~NQNFSWRITE;
				    else
					np->n_flag |= NQNFSWRITE;
				    if (cachable)
					np->n_flag &= ~NQNFSNONCACHE;
				    else
					np->n_flag |= NQNFSNONCACHE;
				    np->n_expiry = reqtime;
				    fxdr_hyper(tl, &np->n_lrev);
				    tp = nmp->nm_tprev;
				    while (tp != (struct nfsnode *)nmp &&
				           tp->n_expiry > np->n_expiry)
						tp = tp->n_tprev;
				    if (tp == (struct nfsnode *)nmp) {
					np->n_tnext = nmp->nm_tnext;
					nmp->nm_tnext = np;
				    } else {
					np->n_tnext = tp->n_tnext;
					tp->n_tnext = np;
				    }
				    np->n_tprev = tp;
				    if (np->n_tnext == (struct nfsnode *)nmp)
					nmp->nm_tprev = np;
				    else
					np->n_tnext->n_tprev = np;
E 38
I 38
				    fxdr_hyper(tl, &frev);
				    nqnfs_clientlease(nmp, np, nqlflag,
					cachable, reqtime, frev);
E 38
				}
			}
		}
E 25
		*mrp = mrep;
		*mdp = md;
		*dposp = dpos;
I 25
		m_freem(rep->r_mreq);
		FREE((caddr_t)rep, M_NFSREQ);
E 25
		return (0);
	}
	m_freem(mrep);
D 25
	return (EPROTONOSUPPORT);
E 25
I 25
D 52
	m_freem(rep->r_mreq);
	free((caddr_t)rep, M_NFSREQ);
E 52
	error = EPROTONOSUPPORT;
E 25
nfsmout:
I 52
	m_freem(rep->r_mreq);
	free((caddr_t)rep, M_NFSREQ);
E 52
	return (error);
}

/*
D 25
 * Get a request for the server main loop
 * - receive a request via. nfs_soreceive()
 * - verify it
 * - fill in the cred struct.
 */
D 6
nfs_getreq(so, prog, vers, maxproc, nam, mrp, mdp, dposp, retxid, proc, cr)
E 6
I 6
D 14
nfs_getreq(so, prog, vers, maxproc, nam, mrp, mdp, dposp, retxid, proc, cr,
E 14
I 14
nfs_getreq(so, prog, vers, maxproc, nam, mrp, mdp, dposp, retxid, procnum, cr,
E 14
D 13
	   msk, mtch)
E 13
I 13
D 18
	lockp, msk, mtch)
E 18
I 18
D 20
	msk, mtch)
E 20
I 20
	msk, mtch, wascomp)
E 20
E 18
E 13
E 6
	struct socket *so;
	u_long prog;
	u_long vers;
	int maxproc;
	struct mbuf **nam;
	struct mbuf **mrp;
	struct mbuf **mdp;
	caddr_t *dposp;
	u_long *retxid;
D 14
	u_long *proc;
E 14
I 14
	u_long *procnum;
E 14
	register struct ucred *cr;
I 6
D 13
	u_long msk;
	u_long mtch;
E 13
I 13
D 18
	int *lockp;
E 18
	struct mbuf *msk, *mtch;
I 20
	int *wascomp;
E 20
E 13
E 6
{
	register int i;
D 5
	register struct mbuf *m;
	nfsm_vars;
	int len, len2;
E 5
I 5
D 23
	register u_long *p;
E 23
I 23
	register u_long *tl;
E 23
	register long t1;
	caddr_t dpos, cp2;
	int error = 0;
	struct mbuf *mrep, *md;
	int len;
E 5

D 6
	if (error = nfs_udpreceive(so, nam, &mrep))
E 6
I 6
D 7
	if (error = nfs_udpreceive(so, msk, mtch, nam, &mrep))
E 7
I 7
D 13
	if (error = nfs_dgreceive(so, msk, mtch, nam, &mrep))
E 13
I 13
	if (so->so_proto->pr_flags & PR_CONNREQUIRED) {
D 18
		nfs_solock(lockp, 0);
E 18
		error = nfs_receive(so, nam, &mrep, (struct nfsreq *)0);
D 18
		nfs_sounlock(lockp);
E 18
	} else {
		mrep = (struct mbuf *)0;
		do {
			if (mrep) {
				m_freem(*nam);
				m_freem(mrep);
			}
			error = nfs_receive(so, nam, &mrep, (struct nfsreq *)0);
		} while (!error && nfs_badnam(*nam, msk, mtch));
	}
	if (error)
E 13
E 7
E 6
		return (error);
	md = mrep;
I 20
	mrep = nfs_uncompress(mrep);
	if (mrep != md) {
		*wascomp = 1;
		md = mrep;
	} else
		*wascomp = 0;
E 20
	dpos = mtod(mrep, caddr_t);
D 23
	nfsm_disect(p, u_long *, 10*NFSX_UNSIGNED);
	*retxid = *p++;
	if (*p++ != rpc_call) {
E 23
I 23
	nfsm_disect(tl, u_long *, 10*NFSX_UNSIGNED);
	*retxid = *tl++;
	if (*tl++ != rpc_call) {
E 23
		m_freem(mrep);
		return (ERPCMISMATCH);
	}
D 23
	if (*p++ != rpc_vers) {
E 23
I 23
	if (*tl++ != rpc_vers) {
E 23
		m_freem(mrep);
		return (ERPCMISMATCH);
	}
D 23
	if (*p++ != prog) {
E 23
I 23
	if (*tl++ != prog) {
E 23
		m_freem(mrep);
		return (EPROGUNAVAIL);
	}
D 23
	if (*p++ != vers) {
E 23
I 23
	if (*tl++ != vers) {
E 23
		m_freem(mrep);
		return (EPROGMISMATCH);
	}
D 14
	*proc = fxdr_unsigned(u_long, *p++);
	if (*proc == NFSPROC_NULL) {
E 14
I 14
D 23
	*procnum = fxdr_unsigned(u_long, *p++);
E 23
I 23
	*procnum = fxdr_unsigned(u_long, *tl++);
E 23
	if (*procnum == NFSPROC_NULL) {
E 14
		*mrp = mrep;
		return (0);
	}
D 14
	if (*proc > maxproc || *p++ != rpc_auth_unix) {
E 14
I 14
D 23
	if (*procnum > maxproc || *p++ != rpc_auth_unix) {
E 23
I 23
	if (*procnum > maxproc || *tl++ != rpc_auth_unix) {
E 23
E 14
		m_freem(mrep);
		return (EPROCUNAVAIL);
	}
D 5
	len = fxdr_unsigned(int, *p++);
	len2 = fxdr_unsigned(int, *++p);
	nfsm_adv(nfsm_rndup(len2));
E 5
I 5
D 13
	(void) fxdr_unsigned(int, *p++);
E 13
I 13
D 23
	len = fxdr_unsigned(int, *p++);
E 23
I 23
	len = fxdr_unsigned(int, *tl++);
E 23
	if (len < 0 || len > RPCAUTH_MAXSIZ) {
		m_freem(mrep);
		return (EBADRPC);
	}
E 13
D 23
	len = fxdr_unsigned(int, *++p);
E 23
I 23
	len = fxdr_unsigned(int, *++tl);
E 23
I 13
	if (len < 0 || len > NFS_MAXNAMLEN) {
		m_freem(mrep);
		return (EBADRPC);
	}
E 13
	nfsm_adv(nfsm_rndup(len));
E 5
D 23
	nfsm_disect(p, u_long *, 3*NFSX_UNSIGNED);
	cr->cr_uid = fxdr_unsigned(uid_t, *p++);
	cr->cr_gid = fxdr_unsigned(gid_t, *p++);
D 5
	len2 = fxdr_unsigned(int, *p);
	if (len2 > 10) {
E 5
I 5
	len = fxdr_unsigned(int, *p);
E 23
I 23
	nfsm_disect(tl, u_long *, 3*NFSX_UNSIGNED);
	cr->cr_uid = fxdr_unsigned(uid_t, *tl++);
	cr->cr_gid = fxdr_unsigned(gid_t, *tl++);
	len = fxdr_unsigned(int, *tl);
E 23
D 13
	if (len > 10) {
E 13
I 13
	if (len < 0 || len > RPCAUTH_UNIXGIDS) {
E 13
E 5
		m_freem(mrep);
		return (EBADRPC);
	}
D 5
	nfsm_disect(p, u_long *, (len2+2)*NFSX_UNSIGNED);
	for (i = 1; i <= len2; i++)
E 5
I 5
D 23
	nfsm_disect(p, u_long *, (len + 2)*NFSX_UNSIGNED);
E 23
I 23
	nfsm_disect(tl, u_long *, (len + 2)*NFSX_UNSIGNED);
E 23
	for (i = 1; i <= len; i++)
E 5
D 13
		cr->cr_groups[i] = fxdr_unsigned(gid_t, *p++);
D 5
	cr->cr_ngroups = len2+1;
E 5
I 5
	cr->cr_ngroups = len + 1;
E 13
I 13
		if (i < NGROUPS)
D 23
			cr->cr_groups[i] = fxdr_unsigned(gid_t, *p++);
E 23
I 23
			cr->cr_groups[i] = fxdr_unsigned(gid_t, *tl++);
E 23
		else
D 23
			p++;
E 23
I 23
			tl++;
E 23
	cr->cr_ngroups = (len >= NGROUPS) ? NGROUPS : (len + 1);
E 13
E 5
	/*
	 * Do we have any use for the verifier.
	 * According to the "Remote Procedure Call Protocol Spec." it
	 * should be AUTH_NULL, but some clients make it AUTH_UNIX?
	 * For now, just skip over it
	 */
D 5
	len2 = fxdr_unsigned(int, *++p);
	if (len2 > 0)
		nfsm_adv(nfsm_rndup(len2));
E 5
I 5
D 23
	len = fxdr_unsigned(int, *++p);
E 23
I 23
	len = fxdr_unsigned(int, *++tl);
E 23
I 13
	if (len < 0 || len > RPCAUTH_MAXSIZ) {
		m_freem(mrep);
		return (EBADRPC);
	}
E 13
	if (len > 0)
		nfsm_adv(nfsm_rndup(len));
E 5
	*mrp = mrep;
	*mdp = md;
	*dposp = dpos;
	return (0);
nfsmout:
	return (error);
}

/*
E 25
 * Generate the rpc reply header
 * siz arg. is used to decide if adding a cluster is worthwhile
 */
D 25
nfs_rephead(siz, retxid, err, mrq, mbp, bposp)
E 25
I 25
D 52
nfs_rephead(siz, nd, err, cache, frev, mrq, mbp, bposp)
E 52
I 52
int
nfs_rephead(siz, nd, slp, err, cache, frev, mrq, mbp, bposp)
E 52
E 25
	int siz;
D 25
	u_long retxid;
E 25
I 25
D 52
	struct nfsd *nd;
E 52
I 52
	struct nfsrv_descript *nd;
	struct nfssvc_sock *slp;
E 52
E 25
	int err;
I 25
	int cache;
	u_quad_t *frev;
E 25
	struct mbuf **mrq;
	struct mbuf **mbp;
	caddr_t *bposp;
{
D 5
	nfsm_vars;
E 5
I 5
D 23
	register u_long *p;
E 23
I 23
	register u_long *tl;
E 23
D 25
	register long t1;
E 25
I 25
	register struct mbuf *mreq;
E 25
	caddr_t bpos;
D 25
	struct mbuf *mreq, *mb, *mb2;
E 25
I 25
	struct mbuf *mb, *mb2;
E 25
E 5

D 25
	NFSMGETHDR(mreq);
E 25
I 25
	MGETHDR(mreq, M_WAIT, MT_DATA);
E 25
	mb = mreq;
D 25
	if ((siz+RPC_REPLYSIZ) > MHLEN)
E 25
I 25
	/*
	 * If this is a big reply, use a cluster else
	 * try and leave leading space for the lower level headers.
	 */
	siz += RPC_REPLYSIZ;
	if (siz >= MINCLSIZE) {
E 25
D 13
		NFSMCLGET(mreq, M_WAIT);
E 13
I 13
		MCLGET(mreq, M_WAIT);
I 25
	} else
		mreq->m_data += max_hdr;
E 25
E 13
D 23
	p = mtod(mreq, u_long *);
E 23
I 23
	tl = mtod(mreq, u_long *);
E 23
D 52
	mreq->m_len = 6*NFSX_UNSIGNED;
D 23
	bpos = ((caddr_t)p)+mreq->m_len;
	*p++ = retxid;
	*p++ = rpc_reply;
E 23
I 23
	bpos = ((caddr_t)tl)+mreq->m_len;
D 25
	*tl++ = retxid;
E 25
I 25
	*tl++ = nd->nd_retxid;
E 52
I 52
	mreq->m_len = 6 * NFSX_UNSIGNED;
	bpos = ((caddr_t)tl) + mreq->m_len;
	*tl++ = txdr_unsigned(nd->nd_retxid);
E 52
E 25
	*tl++ = rpc_reply;
E 23
D 25
	if (err == ERPCMISMATCH) {
E 25
I 25
D 52
	if (err == ERPCMISMATCH || err == NQNFS_AUTHERR) {
E 52
I 52
	if (err == ERPCMISMATCH || (err & NFSERR_AUTHERR)) {
E 52
E 25
D 23
		*p++ = rpc_msgdenied;
		*p++ = rpc_mismatch;
		*p++ = txdr_unsigned(2);
		*p = txdr_unsigned(2);
E 23
I 23
		*tl++ = rpc_msgdenied;
D 25
		*tl++ = rpc_mismatch;
		*tl++ = txdr_unsigned(2);
		*tl = txdr_unsigned(2);
E 25
I 25
D 52
		if (err == NQNFS_AUTHERR) {
E 52
I 52
		if (err & NFSERR_AUTHERR) {
E 52
			*tl++ = rpc_autherr;
D 52
			*tl = rpc_rejectedcred;
E 52
I 52
			*tl = txdr_unsigned(err & ~NFSERR_AUTHERR);
E 52
			mreq->m_len -= NFSX_UNSIGNED;
			bpos -= NFSX_UNSIGNED;
		} else {
			*tl++ = rpc_mismatch;
D 52
			*tl++ = txdr_unsigned(2);
			*tl = txdr_unsigned(2);
E 52
I 52
			*tl++ = txdr_unsigned(RPC_VER2);
			*tl = txdr_unsigned(RPC_VER2);
E 52
		}
E 25
E 23
	} else {
D 23
		*p++ = rpc_msgaccepted;
		*p++ = 0;
		*p++ = 0;
E 23
I 23
		*tl++ = rpc_msgaccepted;
D 52
		*tl++ = 0;
		*tl++ = 0;
E 52
I 52

		/*
		 * For Kerberos authentication, we must send the nickname
		 * verifier back, otherwise just RPCAUTH_NULL.
		 */
		if (nd->nd_flag & ND_KERBFULL) {
		    register struct nfsuid *nuidp;
		    struct timeval ktvin, ktvout;
		    NFSKERBKEYSCHED_T keys;	/* stores key schedule */

		    for (nuidp = NUIDHASH(slp, nd->nd_cr.cr_uid)->lh_first;
			nuidp != 0; nuidp = nuidp->nu_hash.le_next) {
			if (nuidp->nu_cr.cr_uid == nd->nd_cr.cr_uid &&
			    (!nd->nd_nam2 || netaddr_match(NU_NETFAM(nuidp),
			     &nuidp->nu_haddr, nd->nd_nam2)))
			    break;
		    }
		    if (nuidp) {
			ktvin.tv_sec =
			    txdr_unsigned(nuidp->nu_timestamp.tv_sec - 1);
			ktvin.tv_usec =
			    txdr_unsigned(nuidp->nu_timestamp.tv_usec);

			/*
			 * Encrypt the timestamp in ecb mode using the
			 * session key.
			 */
#ifdef NFSKERB
			XXX
#endif

			*tl++ = rpc_auth_kerb;
			*tl++ = txdr_unsigned(3 * NFSX_UNSIGNED);
			*tl = ktvout.tv_sec;
			nfsm_build(tl, u_long *, 3 * NFSX_UNSIGNED);
			*tl++ = ktvout.tv_usec;
			*tl++ = txdr_unsigned(nuidp->nu_cr.cr_uid);
		    } else {
			*tl++ = 0;
			*tl++ = 0;
		    }
		} else {
			*tl++ = 0;
			*tl++ = 0;
		}
E 52
E 23
		switch (err) {
		case EPROGUNAVAIL:
D 23
			*p = txdr_unsigned(RPC_PROGUNAVAIL);
E 23
I 23
			*tl = txdr_unsigned(RPC_PROGUNAVAIL);
E 23
			break;
		case EPROGMISMATCH:
D 23
			*p = txdr_unsigned(RPC_PROGMISMATCH);
			nfsm_build(p, u_long *, 2*NFSX_UNSIGNED);
			*p++ = txdr_unsigned(2);
			*p = txdr_unsigned(2);	/* someday 3 */
E 23
I 23
			*tl = txdr_unsigned(RPC_PROGMISMATCH);
D 52
			nfsm_build(tl, u_long *, 2*NFSX_UNSIGNED);
			*tl++ = txdr_unsigned(2);
			*tl = txdr_unsigned(2);	/* someday 3 */
E 52
I 52
			nfsm_build(tl, u_long *, 2 * NFSX_UNSIGNED);
			if (nd->nd_flag & ND_NQNFS) {
				*tl++ = txdr_unsigned(3);
				*tl = txdr_unsigned(3);
			} else {
				*tl++ = txdr_unsigned(2);
				*tl = txdr_unsigned(3);
			}
E 52
E 23
			break;
		case EPROCUNAVAIL:
D 23
			*p = txdr_unsigned(RPC_PROCUNAVAIL);
E 23
I 23
			*tl = txdr_unsigned(RPC_PROCUNAVAIL);
E 23
			break;
I 52
		case EBADRPC:
			*tl = txdr_unsigned(RPC_GARBAGE);
			break;
E 52
		default:
D 23
			*p = 0;
E 23
I 23
			*tl = 0;
E 23
D 52
			if (err != VNOVAL) {
E 52
I 52
			if (err != NFSERR_RETVOID) {
E 52
D 23
				nfsm_build(p, u_long *, NFSX_UNSIGNED);
				*p = txdr_unsigned(err);
E 23
I 23
				nfsm_build(tl, u_long *, NFSX_UNSIGNED);
D 25
				*tl = txdr_unsigned(err);
E 25
I 25
				if (err)
D 52
					*tl = txdr_unsigned(nfsrv_errmap[err - 1]);
E 52
I 52
				    *tl = txdr_unsigned(nfsrv_errmap(nd, err));
E 52
				else
D 52
					*tl = 0;
E 52
I 52
				    *tl = 0;
E 52
E 25
E 23
			}
			break;
		};
	}
I 25

	/*
	 * For nqnfs, piggyback lease as requested.
	 */
D 52
	if (nd->nd_nqlflag != NQL_NOVAL && err == 0) {
		if (nd->nd_nqlflag) {
			nfsm_build(tl, u_long *, 5*NFSX_UNSIGNED);
			*tl++ = txdr_unsigned(nd->nd_nqlflag);
E 52
I 52
	if ((nd->nd_flag & ND_NQNFS) && err == 0) {
		if (nd->nd_flag & ND_LEASE) {
			nfsm_build(tl, u_long *, 5 * NFSX_UNSIGNED);
			*tl++ = txdr_unsigned(nd->nd_flag & ND_LEASE);
E 52
			*tl++ = txdr_unsigned(cache);
			*tl++ = txdr_unsigned(nd->nd_duration);
			txdr_hyper(frev, tl);
		} else {
D 52
			if (nd->nd_nqlflag != 0)
				panic("nqreph");
E 52
			nfsm_build(tl, u_long *, NFSX_UNSIGNED);
			*tl = 0;
		}
	}
E 25
	*mrq = mreq;
	*mbp = mb;
	*bposp = bpos;
D 52
	if (err != 0 && err != VNOVAL)
E 52
I 52
	if (err != 0 && err != NFSERR_RETVOID)
E 52
		nfsstats.srvrpc_errs++;
	return (0);
}

/*
 * Nfs timer routine
 * Scan the nfsreq list and retranmit any requests that have timed out
 * To avoid retransmission attempts on STREAM sockets (in the future) make
D 7
 * sure to set the r_retry field to 0.
E 7
I 7
 * sure to set the r_retry field to 0 (implies nm_retry == 0).
E 7
 */
D 37
nfs_timer()
E 37
I 37
void
nfs_timer(arg)
D 52
	void *arg;
E 52
I 52
	void *arg;	/* never used */
E 52
E 37
{
	register struct nfsreq *rep;
	register struct mbuf *m;
	register struct socket *so;
D 5
	int s, len;
E 5
I 5
D 7
	int s;
E 7
I 7
D 13
	register struct nfsmount *mntp;
E 13
I 13
	register struct nfsmount *nmp;
I 25
	register int timeo;
I 52
	register struct nfssvc_sock *slp;
E 52
	static long lasttime = 0;
E 25
E 13
	int s, error;
I 52
	u_quad_t cur_usec;
E 52
E 7
E 5

	s = splnet();
D 13
	rep = nfsreqh.r_next;
D 4
	while (rep != NULL) {
E 4
I 4
D 7
	while (rep && rep != &nfsreqh) {
E 4
		if (rep->r_timer > 0)
			rep->r_timer--;
		else if (rep->r_mrep == NULL && rep->r_retry > 0) {
			so = rep->r_mntp->nm_so;
			if ((so->so_state & SS_CANTSENDMORE) == 0 &&
			    !so->so_error &&
			    sbspace(&so->so_snd) >= rep->r_msiz) {
				m = NFSMCOPY(rep->r_mreq, 0, M_COPYALL, M_DONTWAIT);
				if (m != NULL) {
					nfsstats.rpcretries++;
I 2
					rep->r_timeout <<= 2; /* x4 backoff */
					if (rep->r_timeout > NFS_MAXTIMEO)
						rep->r_timeout = NFS_MAXTIMEO;
E 2
					rep->r_timer = rep->r_timeout;
					if (rep->r_retry != VNOVAL)
						rep->r_retry--;
E 7
I 7
	if (rep) for ( ; rep != &nfsreqh; rep = rep->r_next) {
		mntp = rep->r_mntp;
E 13
I 13
D 51
	for (rep = nfsreqh.r_next; rep != &nfsreqh; rep = rep->r_next) {
E 51
I 51
	for (rep = nfs_reqq.tqh_first; rep != 0; rep = rep->r_chain.tqe_next) {
E 51
		nmp = rep->r_nmp;
D 25
		if (rep->r_mrep || (rep->r_flags & R_SOFTTERM) ||
		    (so = nmp->nm_so) == NULL)
E 25
I 25
		if (rep->r_mrep || (rep->r_flags & R_SOFTTERM))
E 25
			continue;
D 25
		if ((nmp->nm_flag & NFSMNT_INT) && nfs_sigintr(rep->r_procp)) {
E 25
I 25
		if (nfs_sigintr(nmp, rep, rep->r_procp)) {
E 25
			rep->r_flags |= R_SOFTTERM;
			continue;
		}
E 13
D 25
		if (rep->r_flags & R_TIMING)	/* update rtt in mount */
D 13
			mntp->nm_rtt++;
		/* If not timed out or reply already received, skip */
		if (++rep->r_timer < mntp->nm_rto || rep->r_mrep)
E 13
I 13
			nmp->nm_rtt++;
D 18
		if (nmp->nm_sotype != SOCK_DGRAM)
E 13
			continue;
E 18
I 13
		/* If not timed out */
		if (++rep->r_timer < nmp->nm_rto)
			continue;
D 18
#ifdef notdef
		if (nmp->nm_sotype != SOCK_DGRAM) {
			rep->r_flags |= R_MUSTRESEND;
			rep->r_timer = rep->r_timerinit;
			continue;
		}
#endif
E 18
E 13
		/* Do backoff and save new timeout in mount */
		if (rep->r_flags & R_TIMING) {
D 13
			nfs_backofftimer(mntp);
E 13
I 13
			nfs_backofftimer(nmp);
E 13
			rep->r_flags &= ~R_TIMING;
D 13
			mntp->nm_rtt = -1;
E 13
I 13
			nmp->nm_rtt = -1;
E 25
I 25
		if (rep->r_rtt >= 0) {
			rep->r_rtt++;
			if (nmp->nm_flag & NFSMNT_DUMBTIMR)
				timeo = nmp->nm_timeo;
			else
				timeo = NFS_RTO(nmp, proct[rep->r_procnum]);
			if (nmp->nm_timeouts > 0)
				timeo *= nfs_backoff[nmp->nm_timeouts - 1];
			if (rep->r_rtt <= timeo)
				continue;
			if (nmp->nm_timeouts < 8)
				nmp->nm_timeouts++;
E 25
E 13
		}
D 25
		if (rep->r_flags & R_SENT) {
			rep->r_flags &= ~R_SENT;
D 13
			--mntp->nm_hostinfo->nh_sent;
E 13
I 13
			nmp->nm_sent--;
E 13
		}
D 13
		/* Check state of socket, cf nfs_send */
		so = mntp->nm_so;
		if (error = nfs_sockerr(so, 1))
			goto wakeup;
		if (sbspace(&so->so_snd) < rep->r_msiz)
			goto wakeup;
		/* Check for too many retries, cf nfs_dgreply */
		if (++rep->r_rexmit > NFS_MAXREXMIT)	/* clip */
E 13
I 13

E 25
		/*
D 25
		 * Check for too many retries on soft mount.
		 * nb: For hard mounts, r_retry == NFS_MAXREXMIT+1
		 */
		if (++rep->r_rexmit > NFS_MAXREXMIT)
E 13
			rep->r_rexmit = NFS_MAXREXMIT;
D 13
		if (rep->r_rexmit > rep->r_retry)	/* too many */
			goto wakeup;
		/* Check for congestion control, cf nfs_request */
		if (mntp->nm_hostinfo->nh_sent >= mntp->nm_hostinfo->nh_window)
			goto wakeup;
		/* Send it! */
		m = NFSMCOPY(rep->r_mreq, 0, M_COPYALL, M_DONTWAIT);
		if (m == NULL)
			goto wakeup;
		nfsstats.rpcretries++;
E 7
#ifdef MGETHDR
D 7
					m->m_pkthdr.len = rep->r_msiz;
E 7
I 7
		m->m_pkthdr.len = rep->r_msiz;
E 7
#endif
D 7
					(*so->so_proto->pr_usrreq)(so, PRU_SEND,
						m, (caddr_t)0, (struct mbuf *)0,
						(struct mbuf *)0);
				}
E 7
I 7
		(void)(*so->so_proto->pr_usrreq)(so, PRU_SEND, m,
D 8
			(struct mbuf *)0, (struct mbuf *)0, (struct mbuf *)0);
E 8
I 8
			(struct mbuf *)0, (struct mbuf *)0);
E 13
E 8

D 13
		/* We need to time the request even though we're
		 * retransmitting, in order to maintain backoff. */
		mntp->nm_rtt = 0;
		++mntp->nm_hostinfo->nh_sent;
		rep->r_flags |= (R_SENT|R_TIMING);
		rep->r_timer = rep->r_timerinit;
wakeup:
		/* If error or interruptible mount, give user a look */
		if (error || (mntp->nm_flag & NFSMNT_INT))
			sorwakeup(so);
E 13
I 13
		/*
E 25
		 * Check for server not responding
		 */
		if ((rep->r_flags & R_TPRINTFMSG) == 0 &&
D 18
		     rep->r_rexmit > 8) {
E 18
I 18
D 25
		     rep->r_rexmit > NFS_FISHY) {
E 25
I 25
		     rep->r_rexmit > nmp->nm_deadthresh) {
E 25
E 18
D 22
			if (rep->r_procp && rep->r_procp->p_session)
D 16
				tprintf(rep->r_procp->p_session->s_ttyvp,
E 16
I 16
				tprintf(rep->r_procp->p_session,
E 16
					"Nfs server %s, not responding\n",
					nmp->nm_mountp->mnt_stat.f_mntfromname);
			else
D 16
				tprintf(NULLVP,
E 16
I 16
				tprintf(NULL,
E 16
					"Nfs server %s, not responding\n",
					nmp->nm_mountp->mnt_stat.f_mntfromname);
E 22
I 22
			nfs_msg(rep->r_procp,
			    nmp->nm_mountp->mnt_stat.f_mntfromname,
			    "not responding");
E 22
			rep->r_flags |= R_TPRINTFMSG;
		}
D 18
		if (rep->r_rexmit > rep->r_retry) {	/* too many */
E 18
I 18
		if (rep->r_rexmit >= rep->r_retry) {	/* too many */
E 18
			nfsstats.rpctimeouts++;
			rep->r_flags |= R_SOFTTERM;
			continue;
		}
I 18
D 25
		if (nmp->nm_sotype != SOCK_DGRAM)
E 25
I 25
		if (nmp->nm_sotype != SOCK_DGRAM) {
			if (++rep->r_rexmit > NFS_MAXREXMIT)
				rep->r_rexmit = NFS_MAXREXMIT;
E 25
			continue;
I 25
		}
		if ((so = nmp->nm_so) == NULL)
			continue;
E 25
E 18

		/*
		 * If there is enough space and the window allows..
		 *	Resend it
I 25
		 * Set r_rtt to -1 in case we fail to send it now.
E 25
		 */
I 25
		rep->r_rtt = -1;
E 25
		if (sbspace(&so->so_snd) >= rep->r_mreq->m_pkthdr.len &&
D 25
		       nmp->nm_sent < nmp->nm_window &&
		       (m = m_copym(rep->r_mreq, 0, M_COPYALL, M_DONTWAIT))){
			nfsstats.rpcretries++;
E 25
I 25
		   ((nmp->nm_flag & NFSMNT_DUMBTIMR) ||
		    (rep->r_flags & R_SENT) ||
		    nmp->nm_sent < nmp->nm_cwnd) &&
		   (m = m_copym(rep->r_mreq, 0, M_COPYALL, M_DONTWAIT))){
E 25
			if ((nmp->nm_flag & NFSMNT_NOCONN) == 0)
			    error = (*so->so_proto->pr_usrreq)(so, PRU_SEND, m,
D 25
			    (caddr_t)0, (struct mbuf *)0, (struct mbuf *)0);
E 25
I 25
			    (struct mbuf *)0, (struct mbuf *)0);
E 25
			else
			    error = (*so->so_proto->pr_usrreq)(so, PRU_SEND, m,
D 25
			    nmp->nm_nam, (struct mbuf *)0, (struct mbuf *)0);
E 25
I 25
			    nmp->nm_nam, (struct mbuf *)0);
E 25
			if (error) {
				if (NFSIGNORE_SOERROR(nmp->nm_soflags, error))
					so->so_error = 0;
			} else {
				/*
D 25
				 * We need to time the request even though we
				 * are retransmitting.
E 25
I 25
				 * Iff first send, start timing
				 * else turn timing off, backoff timer
				 * and divide congestion window by 2.
E 25
				 */
D 25
				nmp->nm_rtt = 0;
				nmp->nm_sent++;
				rep->r_flags |= (R_SENT|R_TIMING);
				rep->r_timer = rep->r_timerinit;
E 25
I 25
				if (rep->r_flags & R_SENT) {
					rep->r_flags &= ~R_TIMING;
					if (++rep->r_rexmit > NFS_MAXREXMIT)
						rep->r_rexmit = NFS_MAXREXMIT;
					nmp->nm_cwnd >>= 1;
					if (nmp->nm_cwnd < NFS_CWNDSCALE)
						nmp->nm_cwnd = NFS_CWNDSCALE;
					nfsstats.rpcretries++;
				} else {
					rep->r_flags |= R_SENT;
					nmp->nm_sent += NFS_CWNDSCALE;
				}
				rep->r_rtt = 0;
E 25
			}
		}
E 13
	}
I 25

	/*
	 * Call the nqnfs server timer once a second to handle leases.
	 */
	if (lasttime != time.tv_sec) {
		lasttime = time.tv_sec;
		nqnfs_serverd();
	}
I 52

	/*
	 * Scan the write gathering queues for writes that need to be
	 * completed now.
	 */
	cur_usec = (u_quad_t)time.tv_sec * 1000000 + (u_quad_t)time.tv_usec;
	for (slp = nfssvc_sockhead.tqh_first; slp != 0;
	    slp = slp->ns_chain.tqe_next) {
	    if (slp->ns_tq.lh_first && slp->ns_tq.lh_first->nd_time<=cur_usec)
		nfsrv_wakenfsd(slp);
	}
E 52
E 25
	splx(s);
D 45
	timeout(nfs_timer, (caddr_t)0, hz/NFS_HZ);
E 45
I 45
D 52
	timeout(nfs_timer, (void *)0, hz / NFS_HZ);
E 52
I 52
	timeout(nfs_timer, (void *)0, nfs_ticks);
E 52
E 45
}

/*
D 25
 * NFS timer update and backoff. The "Jacobson/Karels/Karn" scheme is
 * used here. The timer state is held in the nfsmount structure and
 * a single request is used to clock the response. When successful
 * the rtt smoothing in nfs_updatetimer is used, when failed the backoff
 * is done by nfs_backofftimer. We also log failure messages in these
 * routines.
 *
 * Congestion variables are held in the nfshost structure which
 * is referenced by nfsmounts and shared per-server. This separation
 * makes it possible to do per-mount timing which allows varying disk
 * access times to be dealt with, while preserving a network oriented
 * congestion control scheme.
 *
 * The windowing implements the Jacobson/Karels slowstart algorithm
 * with adjusted scaling factors. We start with one request, then send
 * 4 more after each success until the ssthresh limit is reached, then
 * we increment at a rate proportional to the window. On failure, we
 * remember 3/4 the current window and clamp the send limit to 1. Note
 * ICMP source quench is not reflected in so->so_error so we ignore that
 * for now.
 *
 * NFS behaves much more like a transport protocol with these changes,
 * shedding the teenage pedal-to-the-metal tendencies of "other"
 * implementations.
 *
 * Timers and congestion avoidance by Tom Talpey, Open Software Foundation.
E 25
I 25
 * Test for a termination condition pending on the process.
 * This is used for NFSMNT_INT mounts.
E 25
 */
I 52
int
E 52
I 25
nfs_sigintr(nmp, rep, p)
	struct nfsmount *nmp;
	struct nfsreq *rep;
	register struct proc *p;
{
E 25

I 25
	if (rep && (rep->r_flags & R_SOFTTERM))
		return (EINTR);
	if (!(nmp->nm_flag & NFSMNT_INT))
		return (0);
D 49
	if (p && p->p_sig && (((p->p_sig &~ p->p_sigmask) &~ p->p_sigignore) &
E 49
I 49
	if (p && p->p_siglist &&
	    (((p->p_siglist & ~p->p_sigmask) & ~p->p_sigignore) &
E 49
	    NFSINT_SIGMASK))
		return (EINTR);
	return (0);
}

E 25
/*
D 25
 * The TCP algorithm was not forgiving enough. Because the NFS server
 * responds only after performing lookups/diskio/etc, we have to be
 * more prepared to accept a spiky variance. The TCP algorithm is:
D 13
 * TCP_RTO(mntp) ((((mntp)->nm_srtt >> 2) + (mntp)->nm_rttvar) >> 1)
E 13
I 13
 * TCP_RTO(nmp) ((((nmp)->nm_srtt >> 2) + (nmp)->nm_rttvar) >> 1)
E 25
I 25
 * Lock a socket against others.
 * Necessary for STREAM sockets to ensure you get an entire rpc request/reply
 * and also to avoid race conditions between the processes with nfs requests
 * in progress when a reconnect is necessary.
E 25
E 13
 */
I 52
int
E 52
D 13
#define NFS_RTO(mntp)	(((mntp)->nm_srtt >> 3) + (mntp)->nm_rttvar)
E 13
I 13
D 25
#define NFS_RTO(nmp)	(((nmp)->nm_srtt >> 3) + (nmp)->nm_rttvar)
E 25
I 25
nfs_sndlock(flagp, rep)
	register int *flagp;
	struct nfsreq *rep;
{
	struct proc *p;
I 44
	int slpflag = 0, slptimeo = 0;
E 44
E 25
E 13

D 13
nfs_updatetimer(mntp)
	register struct nfsmount *mntp;
E 13
I 13
D 25
nfs_updatetimer(nmp)
	register struct nfsmount *nmp;
E 25
I 25
D 44
	if (rep)
E 44
I 44
	if (rep) {
E 44
		p = rep->r_procp;
D 44
	else
E 44
I 44
		if (rep->r_nmp->nm_flag & NFSMNT_INT)
			slpflag = PCATCH;
	} else
E 44
		p = (struct proc *)0;
	while (*flagp & NFSMNT_SNDLOCK) {
		if (nfs_sigintr(rep->r_nmp, rep, p))
			return (EINTR);
		*flagp |= NFSMNT_WANTSND;
D 44
		(void) tsleep((caddr_t)flagp, PZERO-1, "nfsndlck", 0);
E 44
I 44
		(void) tsleep((caddr_t)flagp, slpflag | (PZERO - 1), "nfsndlck",
			slptimeo);
		if (slpflag == PCATCH) {
			slpflag = 0;
			slptimeo = 2 * hz;
		}
E 44
	}
	*flagp |= NFSMNT_SNDLOCK;
	return (0);
}

/*
 * Unlock the stream socket for others.
 */
void
nfs_sndunlock(flagp)
	register int *flagp;
E 25
E 13
{
D 13
	register struct nfshost *nfshp = mntp->nm_hostinfo;
E 13

D 25
	/* If retransmitted, clear and return */
D 13
	if (mntp->nm_rexmit || nfshp->nh_currexmit) {
		if (nfshp->nh_currexmit >= nfsrexmtthresh)
D 9
			nfs_log("NFS server %s OK\n", mntp->nm_host);
E 9
I 9
			nfs_log("NFS server %s OK\n",
D 12
				mntp->nm_mountp->m_stat.f_mntfromname);
E 12
I 12
				mntp->nm_mountp->mnt_stat.f_mntfromname);
E 12
E 9
		mntp->nm_rexmit = nfshp->nh_currexmit = 0;
E 13
I 13
	if (nmp->nm_rexmit || nmp->nm_currexmit) {
		nmp->nm_rexmit = nmp->nm_currexmit = 0;
E 13
		return;
E 25
I 25
	if ((*flagp & NFSMNT_SNDLOCK) == 0)
		panic("nfs sndunlock");
	*flagp &= ~NFSMNT_SNDLOCK;
	if (*flagp & NFSMNT_WANTSND) {
		*flagp &= ~NFSMNT_WANTSND;
		wakeup((caddr_t)flagp);
E 25
	}
D 25
	/* If have a measurement, do smoothing */
D 13
	if (mntp->nm_srtt) {
E 13
I 13
	if (nmp->nm_srtt) {
E 13
		register short delta;
D 13
		delta = mntp->nm_rtt - (mntp->nm_srtt >> 3);
		if ((mntp->nm_srtt += delta) <= 0)
			mntp->nm_srtt = 1;
E 13
I 13
		delta = nmp->nm_rtt - (nmp->nm_srtt >> 3);
		if ((nmp->nm_srtt += delta) <= 0)
			nmp->nm_srtt = 1;
E 13
		if (delta < 0)
			delta = -delta;
D 13
		delta -= (mntp->nm_rttvar >> 2);
		if ((mntp->nm_rttvar += delta) <= 0)
			mntp->nm_rttvar = 1;
E 13
I 13
		delta -= (nmp->nm_rttvar >> 2);
		if ((nmp->nm_rttvar += delta) <= 0)
			nmp->nm_rttvar = 1;
E 13
	/* Else initialize */
	} else {
D 13
		mntp->nm_rttvar = mntp->nm_rtt << 1;
		if (mntp->nm_rttvar == 0) mntp->nm_rttvar = 2;
		mntp->nm_srtt = mntp->nm_rttvar << 2;
E 13
I 13
		nmp->nm_rttvar = nmp->nm_rtt << 1;
		if (nmp->nm_rttvar == 0) nmp->nm_rttvar = 2;
		nmp->nm_srtt = nmp->nm_rttvar << 2;
E 25
I 25
}

I 52
int
E 52
nfs_rcvlock(rep)
	register struct nfsreq *rep;
{
	register int *flagp = &rep->r_nmp->nm_flag;
I 44
	int slpflag, slptimeo = 0;
E 44

I 44
	if (*flagp & NFSMNT_INT)
		slpflag = PCATCH;
	else
		slpflag = 0;
E 44
	while (*flagp & NFSMNT_RCVLOCK) {
		if (nfs_sigintr(rep->r_nmp, rep, rep->r_procp))
			return (EINTR);
		*flagp |= NFSMNT_WANTRCV;
D 44
		(void) tsleep((caddr_t)flagp, PZERO-1, "nfsrcvlck", 0);
E 44
I 44
		(void) tsleep((caddr_t)flagp, slpflag | (PZERO - 1), "nfsrcvlk",
			slptimeo);
		if (slpflag == PCATCH) {
			slpflag = 0;
			slptimeo = 2 * hz;
		}
E 44
E 25
E 13
	}
D 25
	/* Compute new Retransmission TimeOut and clip */
D 13
	mntp->nm_rto = NFS_RTO(mntp);
	if (mntp->nm_rto < NFS_MINTIMEO)
		mntp->nm_rto = NFS_MINTIMEO;
	else if (mntp->nm_rto > NFS_MAXTIMEO)
		mntp->nm_rto = NFS_MAXTIMEO;
	nfshp->nh_currto = mntp->nm_rto;
E 13
I 13
	nmp->nm_rto = NFS_RTO(nmp);
	if (nmp->nm_rto < NFS_MINTIMEO)
		nmp->nm_rto = NFS_MINTIMEO;
	else if (nmp->nm_rto > NFS_MAXTIMEO)
		nmp->nm_rto = NFS_MAXTIMEO;
E 25
I 25
	*flagp |= NFSMNT_RCVLOCK;
	return (0);
}
E 25
E 13

D 25
	/* Update window estimate */
D 13
	if (nfshp->nh_window < nfshp->nh_ssthresh)	/* quickly */
		nfshp->nh_window += 4;
E 13
I 13
	if (nmp->nm_window < nmp->nm_ssthresh)	/* quickly */
		nmp->nm_window += 4;
E 13
	else {						/* slowly */
D 13
		register long incr = ++nfshp->nh_winext;
		incr = (incr * incr) / nfshp->nh_window;
E 13
I 13
		register long incr = ++nmp->nm_winext;
		incr = (incr * incr) / nmp->nm_window;
E 13
		if (incr > 0) {
D 13
			nfshp->nh_winext = 0;
			++nfshp->nh_window;
E 13
I 13
			nmp->nm_winext = 0;
			++nmp->nm_window;
E 13
		}
E 25
I 25
/*
 * Unlock the stream socket for others.
 */
void
nfs_rcvunlock(flagp)
	register int *flagp;
{

	if ((*flagp & NFSMNT_RCVLOCK) == 0)
		panic("nfs rcvunlock");
	*flagp &= ~NFSMNT_RCVLOCK;
	if (*flagp & NFSMNT_WANTRCV) {
		*flagp &= ~NFSMNT_WANTRCV;
		wakeup((caddr_t)flagp);
E 25
	}
D 13
	if (nfshp->nh_window > NFS_MAXWINDOW)
		nfshp->nh_window = NFS_MAXWINDOW;
E 13
I 13
D 25
	if (nmp->nm_window > NFS_MAXWINDOW)
		nmp->nm_window = NFS_MAXWINDOW;
E 25
E 13
D 33
}

D 13
nfs_backofftimer(mntp)
	register struct nfsmount *mntp;
E 13
I 13
D 25
nfs_backofftimer(nmp)
	register struct nfsmount *nmp;
E 25
I 25
/*
 * This function compares two net addresses by family and returns TRUE
 * if they are the same host.
 * If there is any doubt, return FALSE.
 * The AF_INET family is handled as a special case so that address mbufs
 * don't need to be saved to store "struct in_addr", which is only 4 bytes.
 */
nfs_netaddr_match(family, haddr, hmask, nam)
	int family;
	union nethostaddr *haddr;
	union nethostaddr *hmask;
	struct mbuf *nam;
E 25
E 13
{
D 13
	register struct nfshost *nfshp = mntp->nm_hostinfo;
E 13
D 25
	register unsigned long newrto;
E 25
I 25
	register struct sockaddr_in *inetaddr;
#ifdef ISO
	register struct sockaddr_iso *isoaddr1, *isoaddr2;
#endif
E 25

D 25
	/* Clip shift count */
D 13
	if (++mntp->nm_rexmit > 8 * sizeof mntp->nm_rto)
		mntp->nm_rexmit = 8 * sizeof mntp->nm_rto;
E 13
I 13
	if (++nmp->nm_rexmit > 8 * sizeof nmp->nm_rto)
		nmp->nm_rexmit = 8 * sizeof nmp->nm_rto;
E 13
	/* Back off RTO exponentially */
D 13
	newrto = NFS_RTO(mntp);
	newrto <<= (mntp->nm_rexmit - 1);
E 13
I 13
	newrto = NFS_RTO(nmp);
	newrto <<= (nmp->nm_rexmit - 1);
E 13
	if (newrto == 0 || newrto > NFS_MAXTIMEO)
		newrto = NFS_MAXTIMEO;
D 13
	mntp->nm_rto = nfshp->nh_currto = newrto;
E 13
I 13
	nmp->nm_rto = newrto;
E 25
E 13

D 25
	/* If too many retries, message, assume a bogus RTT and re-measure */
D 13
	if (nfshp->nh_currexmit < mntp->nm_rexmit) {
		nfshp->nh_currexmit = mntp->nm_rexmit;
		if (nfshp->nh_currexmit >= nfsrexmtthresh) {
			if (nfshp->nh_currexmit == nfsrexmtthresh) {
				nfs_log("NFS server %s not responding\n",
D 9
								mntp->nm_host);
E 9
I 9
D 12
					mntp->nm_mountp->m_stat.f_mntfromname);
E 12
I 12
				    mntp->nm_mountp->mnt_stat.f_mntfromname);
E 12
E 9
				mntp->nm_rttvar += (mntp->nm_srtt >> 2);
				mntp->nm_srtt = 0;
E 13
I 13
	if (nmp->nm_currexmit < nmp->nm_rexmit) {
		nmp->nm_currexmit = nmp->nm_rexmit;
		if (nmp->nm_currexmit >= nfsrexmtthresh) {
			if (nmp->nm_currexmit == nfsrexmtthresh) {
				nmp->nm_rttvar += (nmp->nm_srtt >> 2);
				nmp->nm_srtt = 0;
E 25
I 25
	switch (family) {
	case AF_INET:
		inetaddr = mtod(nam, struct sockaddr_in *);
		if (inetaddr->sin_family != AF_INET)
			return (0);
		if (hmask) {
			if ((inetaddr->sin_addr.s_addr & hmask->had_inetaddr) ==
			    (haddr->had_inetaddr & hmask->had_inetaddr))
				return (1);
		} else if (inetaddr->sin_addr.s_addr == haddr->had_inetaddr)
			return (1);
		break;
#ifdef ISO
	case AF_ISO:
		isoaddr1 = mtod(nam, struct sockaddr_iso *);
		if (isoaddr1->siso_family != AF_ISO)
			return (0);
		isoaddr2 = mtod(haddr->had_nam, struct sockaddr_iso *);
		if (isoaddr1->siso_nlen > 0 &&
		    isoaddr1->siso_nlen == isoaddr2->siso_nlen &&
		    SAME_ISOADDR(isoaddr1, isoaddr2))
			return (1);
		break;
#endif	/* ISO */
	default:
		break;
	};
	return (0);
}

/*
 * Build hash lists of net addresses and hang them off the mount point.
 * Called by ufs_mount() to set up the lists of export addresses.
 */
hang_addrlist(mp, argp)
	struct mount *mp;
	struct ufs_args *argp;
{
	register struct netaddrhash *np, **hnp;
	register int i;
	struct ufsmount *ump;
	struct sockaddr *saddr;
	struct mbuf *nam, *msk = (struct mbuf *)0;
	union nethostaddr netmsk;
	int error;

	if (error = sockargs(&nam, (caddr_t)argp->saddr, argp->slen,
	    MT_SONAME))
	    return (error);
	saddr = mtod(nam, struct sockaddr *);
	ump = VFSTOUFS(mp);
	if (saddr->sa_family == AF_INET &&
	    ((struct sockaddr_in *)saddr)->sin_addr.s_addr == INADDR_ANY) {
	    m_freem(nam);
	    if (mp->mnt_flag & MNT_DEFEXPORTED)
		return (EPERM);
	    np = &ump->um_defexported;
	    np->neth_exflags = argp->exflags;
	    np->neth_anon = argp->anon;
	    np->neth_anon.cr_ref = 1;
	    mp->mnt_flag |= MNT_DEFEXPORTED;
	    return (0);
	}
	if (argp->msklen > 0) {
	    if (error = sockargs(&msk, (caddr_t)argp->smask, argp->msklen,
		MT_SONAME)) {
		m_freem(nam);
		return (error);
	    }

	    /*
	     * Scan all the hash lists to check against duplications.
	     * For the net list, try both masks to catch a subnet
	     * of another network.
	     */
	    hnp = &ump->um_netaddr[NETMASK_HASH];
	    np = *hnp;
	    if (saddr->sa_family == AF_INET)
		netmsk.had_inetaddr =
		    mtod(msk, struct sockaddr_in *)->sin_addr.s_addr;
	    else
		netmsk.had_nam = msk;
	    while (np) {
		if (nfs_netaddr_match(np->neth_family, &np->neth_haddr,
		    &np->neth_hmask, nam) ||
		    nfs_netaddr_match(np->neth_family, &np->neth_haddr,
		    &netmsk, nam)) {
			m_freem(nam);
			m_freem(msk);
			return (EPERM);
		}
		np = np->neth_next;
	    }
	    for (i = 0; i < NETHASHSZ; i++) {
		np = ump->um_netaddr[i];
		while (np) {
		    if (nfs_netaddr_match(np->neth_family, &np->neth_haddr,
			&netmsk, nam)) {
			m_freem(nam);
			m_freem(msk);
			return (EPERM);
		    }
		    np = np->neth_next;
		}
	    }
	} else {
	    hnp = &ump->um_netaddr[NETADDRHASH(saddr)];
	    np = ump->um_netaddr[NETMASK_HASH];
	    while (np) {
		if (nfs_netaddr_match(np->neth_family, &np->neth_haddr,
		    &np->neth_hmask, nam)) {
		    m_freem(nam);
		    return (EPERM);
		}
		np = np->neth_next;
	    }
	    np = *hnp;
	    while (np) {
		if (nfs_netaddr_match(np->neth_family, &np->neth_haddr,
		    (union nethostaddr *)0, nam)) {
		    m_freem(nam);
		    return (EPERM);
		}
		np = np->neth_next;
	    }
	}
	np = (struct netaddrhash *) malloc(sizeof(struct netaddrhash), M_NETADDR,
	    M_WAITOK);
	np->neth_family = saddr->sa_family;
	if (saddr->sa_family == AF_INET) {
		np->neth_inetaddr = ((struct sockaddr_in *)saddr)->sin_addr.s_addr;
		m_freem(nam);
		if (msk) {
			np->neth_inetmask = netmsk.had_inetaddr;
			m_freem(msk);
			if (np->neth_inetaddr &~ np->neth_inetmask)
				return (EPERM);
		} else
			np->neth_inetmask = 0xffffffff;
	} else {
		np->neth_nam = nam;
		np->neth_msk = msk;
	}
	np->neth_exflags = argp->exflags;
	np->neth_anon = argp->anon;
	np->neth_anon.cr_ref = 1;
	np->neth_next = *hnp;
	*hnp = np;
	return (0);
}

/*
 * Free the net address hash lists that are hanging off the mount points.
 */
free_addrlist(ump)
	struct ufsmount *ump;
{
	register struct netaddrhash *np, *onp;
	register int i;

	for (i = 0; i <= NETHASHSZ; i++) {
		np = ump->um_netaddr[i];
		ump->um_netaddr[i] = (struct netaddrhash *)0;
		while (np) {
			onp = np;
			np = np->neth_next;
			if (onp->neth_family != AF_INET) {
				m_freem(onp->neth_nam);
				m_freem(onp->neth_msk);
E 25
E 13
E 7
			}
I 25
			free((caddr_t)onp, M_NETADDR);
E 25
I 7
D 13
			/* The routing invalidation should be a usrreq PRU */
			if (mtod(nfshp->nh_sockaddr,
				struct sockaddr *)->sa_family == AF_INET)
				in_losing(mntp->nm_so->so_pcb);
E 13
E 7
		}
D 7
		rep = rep->r_next;
E 7
	}
D 7
	splx(s);
D 2
	timeout(nfs_timer, (caddr_t)0, hz);
E 2
I 2
	timeout(nfs_timer, (caddr_t)0, hz/10);
E 7
I 7
D 25
	/* Close down window but remember this point (3/4 current) for later */
D 13
	nfshp->nh_ssthresh = ((nfshp->nh_window << 1) + nfshp->nh_window) >> 2;
	nfshp->nh_window = 1;
	nfshp->nh_winext = 0;
E 13
I 13
	nmp->nm_ssthresh = ((nmp->nm_window << 1) + nmp->nm_window) >> 2;
	nmp->nm_window = 1;
	nmp->nm_winext = 0;
E 25
E 13
E 7
E 2
}

/*
D 7
 * nfs_sbwait() is simply sbwait() but at a negative priority so that it
 * can not be interrupted by a signal.
E 7
I 7
D 13
 * Not all errors are fatal. The closed checks deal
 * with errors a little strangely.
E 13
I 13
D 25
 * Test for a termination signal pending on procp.
 * This is used for NFSMNT_INT mounts.
E 25
I 25
 * Generate a hash code for an iso host address. Used by NETADDRHASH() for
 * iso addresses.
E 25
E 13
E 7
 */
I 13
D 25
nfs_sigintr(p)
	register struct proc *p;
E 25
I 25
iso_addrhash(saddr)
	struct sockaddr *saddr;
E 25
{
D 25
	if (p && p->p_sig && (((p->p_sig &~ p->p_sigmask) &~ p->p_sigignore) &
	    NFSINT_SIGMASK))
		return (1);
	else
		return (0);
E 25
I 25
#ifdef ISO
	register struct sockaddr_iso *siso;
	register int i, sum;

	sum = 0;
	for (i = 0; i < siso->siso_nlen; i++)
		sum += siso->siso_data[i];
	return (sum & (NETHASHSZ - 1));
#else
	return (0);
#endif	/* ISO */
E 33
E 25
I 22
}

D 25
nfs_msg(p, server, msg)
	struct proc *p;
	char *server, *msg;
E 25
I 25
/*
 * Check for badly aligned mbuf data areas and
 * realign data in an mbuf list by copying the data areas up, as required.
 */
void
nfs_realign(m, hsiz)
	register struct mbuf *m;
	int hsiz;
E 25
{
D 25
	tpr_t tpr;
E 25
I 25
	register struct mbuf *m2;
	register int siz, mlen, olen;
	register caddr_t tcp, fcp;
	struct mbuf *mnew;
E 25

D 25
	if (p)
		tpr = tprintf_open(p);
	else
		tpr = NULL;
	tprintf(tpr, "nfs server %s: %s\n", server, msg);
	tprintf_close(tpr);
E 25
I 25
	while (m) {
	    /*
	     * This never happens for UDP, rarely happens for TCP
	     * but frequently happens for iso transport.
	     */
	    if ((m->m_len & 0x3) || (mtod(m, int) & 0x3)) {
		olen = m->m_len;
		fcp = mtod(m, caddr_t);
D 47
		m->m_flags &= ~M_PKTHDR;
		if (m->m_flags & M_EXT)
			m->m_data = m->m_ext.ext_buf;
		else
			m->m_data = m->m_dat;
E 47
I 47
		if ((int)fcp & 0x3) {
			m->m_flags &= ~M_PKTHDR;
			if (m->m_flags & M_EXT)
				m->m_data = m->m_ext.ext_buf +
					((m->m_ext.ext_size - olen) & ~0x3);
			else
				m->m_data = m->m_dat;
		}
E 47
		m->m_len = 0;
		tcp = mtod(m, caddr_t);
		mnew = m;
		m2 = m->m_next;
	
		/*
		 * If possible, only put the first invariant part
		 * of the RPC header in the first mbuf.
		 */
D 47
		if (olen <= hsiz)
E 47
I 47
		mlen = M_TRAILINGSPACE(m);
		if (olen <= hsiz && mlen > hsiz)
E 47
			mlen = hsiz;
D 47
		else
			mlen = M_TRAILINGSPACE(m);
E 47
	
		/*
		 * Loop through the mbuf list consolidating data.
		 */
		while (m) {
			while (olen > 0) {
				if (mlen == 0) {
					m2->m_flags &= ~M_PKTHDR;
					if (m2->m_flags & M_EXT)
						m2->m_data = m2->m_ext.ext_buf;
					else
						m2->m_data = m2->m_dat;
					m2->m_len = 0;
					mlen = M_TRAILINGSPACE(m2);
					tcp = mtod(m2, caddr_t);
					mnew = m2;
					m2 = m2->m_next;
				}
D 35
				siz = MIN(mlen, olen);
E 35
I 35
				siz = min(mlen, olen);
E 35
				if (tcp != fcp)
					bcopy(fcp, tcp, siz);
				mnew->m_len += siz;
				mlen -= siz;
				olen -= siz;
				tcp += siz;
				fcp += siz;
			}
			m = m->m_next;
			if (m) {
				olen = m->m_len;
				fcp = mtod(m, caddr_t);
			}
		}
	
		/*
		 * Finally, set m_len == 0 for any trailing mbufs that have
		 * been copied out of.
		 */
		while (m2) {
			m2->m_len = 0;
			m2 = m2->m_next;
		}
		return;
	    }
	    m = m->m_next;
	}
E 25
E 22
}
E 13
D 7
nfs_sbwait(sb)
	struct sockbuf *sb;
E 7
I 7

D 13
nfs_sockerr(so, sending)
	struct socket *so;
	int sending;
E 13
I 13
/*
D 25
 * Lock a socket against others.
 * Necessary for STREAM sockets to ensure you get an entire rpc request/reply
 * and also to avoid race conditions between the processes with nfs requests
 * in progress when a reconnect is necessary.
E 25
I 25
 * Socket upcall routine for the nfsd sockets.
 * The caddr_t arg is a pointer to the "struct nfssvc_sock".
 * Essentially do as much as possible non-blocking, else punt and it will
 * be called with M_WAIT from an nfsd.
E 25
 */
D 18
nfs_solock(flagp, cant_intr)
	int *flagp;
	int cant_intr;
E 18
I 18
D 25
nfs_solock(flagp)
	register int *flagp;
E 25
I 25
void
nfsrv_rcv(so, arg, waitflag)
	struct socket *so;
	caddr_t arg;
	int waitflag;
E 25
E 18
E 13
E 7
{
I 25
	register struct nfssvc_sock *slp = (struct nfssvc_sock *)arg;
	register struct mbuf *m;
	struct mbuf *mp, *nam;
	struct uio auio;
	int flags, error;
E 25
D 7
	sb->sb_flags |= SB_WAIT;
D 4
	sleep((caddr_t)&sb->sb_cc, PZERO-1);
E 4
I 4
	sleep((caddr_t)&sb->sb_cc, PZERO-2);
E 7
I 7
D 13
	if (sending && (so->so_state & SS_CANTSENDMORE)) {
		so->so_error = EPIPE;
		return (EPIPE);
	}
E 13

I 26
	if ((slp->ns_flag & SLP_VALID) == 0)
		return;
#ifdef notdef
	/*
	 * Define this to test for nfsds handling this under heavy load.
	 */
	if (waitflag == M_DONTWAIT) {
		slp->ns_flag |= SLP_NEEDQ; goto dorecs;
	}
#endif
I 27
	auio.uio_procp = NULL;
E 27
E 26
D 13
	switch (so->so_error) {			/* inhibit certain errors */
	case ENETDOWN:
	case ENETUNREACH:
	case EHOSTDOWN:
	case EHOSTUNREACH:
		so->so_error = 0;
	case 0:
		break;
	default:				/* return all others */
		printf("nfs_sockerr: error %d on %s\n", so->so_error,
			sending?"send":"receive");
		return (so->so_error);
E 13
I 13
D 25
	while (*flagp & NFSMNT_SCKLOCK) {
		*flagp |= NFSMNT_WANTSCK;
D 18
		if (cant_intr)
			(void) sleep((caddr_t)flagp, PZERO-7);
		else
			(void) tsleep((caddr_t)flagp, PZERO+1, "nfssolck", 0);
E 18
I 18
		(void) tsleep((caddr_t)flagp, PZERO-1, "nfsolck", 0);
E 25
I 25
	if (so->so_type == SOCK_STREAM) {
		/*
		 * If there are already records on the queue, defer soreceive()
		 * to an nfsd so that there is feedback to the TCP layer that
		 * the nfs servers are heavily loaded.
		 */
		if (slp->ns_rec && waitflag == M_DONTWAIT) {
			slp->ns_flag |= SLP_NEEDQ;
D 26
			nfsrv_wakenfsd(slp);
			return;
E 26
I 26
			goto dorecs;
E 26
		}

		/*
		 * Do soreceive().
		 */
		auio.uio_resid = 1000000000;
		flags = MSG_DONTWAIT;
		error = soreceive(so, &nam, &auio, &mp, (struct mbuf **)0, &flags);
		if (error || mp == (struct mbuf *)0) {
D 26
			if (error != EWOULDBLOCK) {
E 26
I 26
			if (error == EWOULDBLOCK)
				slp->ns_flag |= SLP_NEEDQ;
			else
E 26
				slp->ns_flag |= SLP_DISCONN;
D 26
				if (waitflag == M_DONTWAIT)
					nfsrv_wakenfsd(slp);
			}
E 26
			goto dorecs;
		}
		m = mp;
		if (slp->ns_rawend) {
			slp->ns_rawend->m_next = m;
			slp->ns_cc += 1000000000 - auio.uio_resid;
		} else {
			slp->ns_raw = m;
			slp->ns_cc = 1000000000 - auio.uio_resid;
		}
		while (m->m_next)
			m = m->m_next;
		slp->ns_rawend = m;

		/*
		 * Now try and parse record(s) out of the raw stream data.
		 */
D 52
		if (error = nfsrv_getstream(slp, waitflag)) {
E 52
I 52
		error = nfsrv_getstream(slp, waitflag);
		if (error) {
E 52
			if (error == EPERM)
				slp->ns_flag |= SLP_DISCONN;
D 26
			if (error == EWOULDBLOCK)
E 26
I 26
			else
E 26
				slp->ns_flag |= SLP_NEEDQ;
D 26
			if (waitflag == M_DONTWAIT)
				nfsrv_wakenfsd(slp);
E 26
		}
	} else {
		do {
			auio.uio_resid = 1000000000;
			flags = MSG_DONTWAIT;
			error = soreceive(so, &nam, &auio, &mp,
						(struct mbuf **)0, &flags);
			if (mp) {
				nfs_realign(mp, 10 * NFSX_UNSIGNED);
				if (nam) {
					m = nam;
					m->m_next = mp;
				} else
					m = mp;
				if (slp->ns_recend)
					slp->ns_recend->m_nextpkt = m;
				else
					slp->ns_rec = m;
				slp->ns_recend = m;
				m->m_nextpkt = (struct mbuf *)0;
			}
			if (error) {
				if ((so->so_proto->pr_flags & PR_CONNREQUIRED)
					&& error != EWOULDBLOCK) {
					slp->ns_flag |= SLP_DISCONN;
D 26
					if (waitflag == M_DONTWAIT)
						nfsrv_wakenfsd(slp);
E 26
I 26
					goto dorecs;
E 26
				}
			}
		} while (mp);
E 25
E 18
E 13
	}
I 13
D 25
	*flagp |= NFSMNT_SCKLOCK;
E 25
I 25

	/*
	 * Now try and process the request records, non-blocking.
	 */
dorecs:
D 26
	if (slp->ns_rec && waitflag == M_DONTWAIT)
E 26
I 26
	if (waitflag == M_DONTWAIT &&
		(slp->ns_rec || (slp->ns_flag & (SLP_NEEDQ | SLP_DISCONN))))
E 26
		nfsrv_wakenfsd(slp);
E 25
}
E 13

D 13
	if (!sending && (so->so_state & SS_CANTRCVMORE)) {
		so->so_error = 0;		/* (no error) */
		return (EPIPE);
E 13
I 13
/*
D 25
 * Unlock the stream socket for others.
E 25
I 25
 * Try and extract an RPC request from the mbuf data list received on a
 * stream socket. The "waitflag" argument indicates whether or not it
 * can sleep.
E 25
 */
I 52
int
E 52
D 25
nfs_sounlock(flagp)
D 18
	int *flagp;
E 18
I 18
	register int *flagp;
E 25
I 25
nfsrv_getstream(slp, waitflag)
	register struct nfssvc_sock *slp;
	int waitflag;
E 25
E 18
{
I 25
D 52
	register struct mbuf *m;
E 52
I 52
	register struct mbuf *m, **mpp;
E 52
	register char *cp1, *cp2;
	register int len;
D 52
	struct mbuf *om, *m2, *recm;
E 52
I 52
	struct mbuf *om, *m2, *recm = 0;
E 52
	u_long recmark;
E 25

D 25
	if ((*flagp & NFSMNT_SCKLOCK) == 0)
		panic("nfs sounlock");
	*flagp &= ~NFSMNT_SCKLOCK;
	if (*flagp & NFSMNT_WANTSCK) {
		*flagp &= ~NFSMNT_WANTSCK;
		wakeup((caddr_t)flagp);
E 25
I 25
	if (slp->ns_flag & SLP_GETSTREAM)
		panic("nfs getstream");
	slp->ns_flag |= SLP_GETSTREAM;
	for (;;) {
	    if (slp->ns_reclen == 0) {
		if (slp->ns_cc < NFSX_UNSIGNED) {
			slp->ns_flag &= ~SLP_GETSTREAM;
			return (0);
		}
		m = slp->ns_raw;
		if (m->m_len >= NFSX_UNSIGNED) {
			bcopy(mtod(m, caddr_t), (caddr_t)&recmark, NFSX_UNSIGNED);
			m->m_data += NFSX_UNSIGNED;
			m->m_len -= NFSX_UNSIGNED;
		} else {
			cp1 = (caddr_t)&recmark;
			cp2 = mtod(m, caddr_t);
			while (cp1 < ((caddr_t)&recmark) + NFSX_UNSIGNED) {
				while (m->m_len == 0) {
					m = m->m_next;
					cp2 = mtod(m, caddr_t);
				}
				*cp1++ = *cp2++;
				m->m_data++;
				m->m_len--;
			}
		}
		slp->ns_cc -= NFSX_UNSIGNED;
D 52
		slp->ns_reclen = ntohl(recmark) & ~0x80000000;
E 52
I 52
		recmark = ntohl(recmark);
		slp->ns_reclen = recmark & ~0x80000000;
		if (recmark & 0x80000000)
			slp->ns_flag |= SLP_LASTFRAG;
		else
			slp->ns_flag &= ~SLP_LASTFRAG;
E 52
		if (slp->ns_reclen < NFS_MINPACKET || slp->ns_reclen > NFS_MAXPACKET) {
			slp->ns_flag &= ~SLP_GETSTREAM;
			return (EPERM);
		}
	    }

	    /*
	     * Now get the record part.
	     */
	    if (slp->ns_cc == slp->ns_reclen) {
		recm = slp->ns_raw;
		slp->ns_raw = slp->ns_rawend = (struct mbuf *)0;
		slp->ns_cc = slp->ns_reclen = 0;
	    } else if (slp->ns_cc > slp->ns_reclen) {
		len = 0;
		m = slp->ns_raw;
		om = (struct mbuf *)0;
		while (len < slp->ns_reclen) {
			if ((len + m->m_len) > slp->ns_reclen) {
				m2 = m_copym(m, 0, slp->ns_reclen - len,
					waitflag);
				if (m2) {
					if (om) {
						om->m_next = m2;
						recm = slp->ns_raw;
					} else
						recm = m2;
					m->m_data += slp->ns_reclen - len;
					m->m_len -= slp->ns_reclen - len;
					len = slp->ns_reclen;
				} else {
					slp->ns_flag &= ~SLP_GETSTREAM;
					return (EWOULDBLOCK);
				}
			} else if ((len + m->m_len) == slp->ns_reclen) {
				om = m;
				len += m->m_len;
				m = m->m_next;
				recm = slp->ns_raw;
				om->m_next = (struct mbuf *)0;
			} else {
				om = m;
				len += m->m_len;
				m = m->m_next;
			}
		}
		slp->ns_raw = m;
		slp->ns_cc -= len;
		slp->ns_reclen = 0;
	    } else {
		slp->ns_flag &= ~SLP_GETSTREAM;
		return (0);
	    }
D 52
	    nfs_realign(recm, 10 * NFSX_UNSIGNED);
	    if (slp->ns_recend)
		slp->ns_recend->m_nextpkt = recm;
	    else
		slp->ns_rec = recm;
	    slp->ns_recend = recm;
E 52
I 52

	    /*
	     * Accumulate the fragments into a record.
	     */
	    mpp = &slp->ns_frag;
	    while (*mpp)
		mpp = &((*mpp)->m_next);
	    *mpp = recm;
	    if (slp->ns_flag & SLP_LASTFRAG) {
		nfs_realign(slp->ns_frag, 10 * NFSX_UNSIGNED);
		if (slp->ns_recend)
		    slp->ns_recend->m_nextpkt = slp->ns_frag;
		else
		    slp->ns_rec = slp->ns_frag;
		slp->ns_recend = slp->ns_frag;
		slp->ns_frag = (struct mbuf *)0;
	    }
E 52
E 25
E 13
	}
D 13
	return (so->so_error);
E 13
I 13
}

/*
D 25
 * This function compares two net addresses by family and returns TRUE
 * if they are the same.
 * If there is any doubt, return FALSE.
E 25
I 25
 * Parse an RPC header.
E 25
 */
D 25
nfs_netaddr_match(nam1, nam2)
	struct mbuf *nam1, *nam2;
E 25
I 25
D 52
nfsrv_dorec(slp, nd)
E 52
I 52
int
nfsrv_dorec(slp, nfsd, ndp)
E 52
	register struct nfssvc_sock *slp;
D 52
	register struct nfsd *nd;
E 52
I 52
	struct nfsd *nfsd;
	struct nfsrv_descript **ndp;
E 52
E 25
{
D 25
	register struct sockaddr *saddr1, *saddr2;
E 25
I 25
D 52
	register struct mbuf *m;
E 52
I 52
	register struct mbuf *m, *nam;
	register struct nfsrv_descript *nd;
E 52
	int error;
E 25

I 52
	*ndp = NULL;
E 52
D 25
	saddr1 = mtod(nam1, struct sockaddr *);
	saddr2 = mtod(nam2, struct sockaddr *);
	if (saddr1->sa_family != saddr2->sa_family)
E 25
I 25
D 26
	if (slp->ns_sref != nd->nd_sref ||
E 26
I 26
	if ((slp->ns_flag & SLP_VALID) == 0 ||
E 26
	    (m = slp->ns_rec) == (struct mbuf *)0)
		return (ENOBUFS);
D 52
	if (slp->ns_rec = m->m_nextpkt)
E 52
I 52
	slp->ns_rec = m->m_nextpkt;
	if (slp->ns_rec)
E 52
		m->m_nextpkt = (struct mbuf *)0;
	else
		slp->ns_recend = (struct mbuf *)0;
	if (m->m_type == MT_SONAME) {
D 52
		nd->nd_nam = m;
		nd->nd_md = nd->nd_mrep = m->m_next;
		m->m_next = (struct mbuf *)0;
	} else {
		nd->nd_nam = (struct mbuf *)0;
		nd->nd_md = nd->nd_mrep = m;
	}
	nd->nd_dpos = mtod(nd->nd_md, caddr_t);
	if (error = nfs_getreq(nd, TRUE)) {
		m_freem(nd->nd_nam);
E 52
I 52
		nam = m;
		m = m->m_next;
		nam->m_next = NULL;
	} else
		nam = NULL;
	MALLOC(nd, struct nfsrv_descript *, sizeof (struct nfsrv_descript),
		M_NFSRVDESC, M_WAITOK);
	nd->nd_md = nd->nd_mrep = m;
	nd->nd_nam2 = nam;
	nd->nd_dpos = mtod(m, caddr_t);
	error = nfs_getreq(nd, nfsd, TRUE);
	if (error) {
		m_freem(nam);
		free((caddr_t)nd, M_NFSRVDESC);
E 52
		return (error);
	}
I 52
	*ndp = nd;
	nfsd->nfsd_nd = nd;
E 52
	return (0);
}

/*
 * Parse an RPC request
 * - verify it
 * - fill in the cred struct.
 */
D 52
nfs_getreq(nd, has_header)
	register struct nfsd *nd;
E 52
I 52
int
nfs_getreq(nd, nfsd, has_header)
	register struct nfsrv_descript *nd;
	struct nfsd *nfsd;
E 52
	int has_header;
{
	register int len, i;
	register u_long *tl;
	register long t1;
	struct uio uio;
	struct iovec iov;
D 52
	caddr_t dpos, cp2;
E 52
I 52
	caddr_t dpos, cp2, cp;
E 52
	u_long nfsvers, auth_type;
D 52
	int error = 0, nqnfs = 0;
E 52
I 52
	uid_t nickuid;
	int error = 0, nqnfs = 0, ticklen;
E 52
	struct mbuf *mrep, *md;
I 52
	register struct nfsuid *nuidp;
	struct timeval tvin, tvout;
	NFSKERBKEYSCHED_T keys;	/* stores key schedule */
E 52

	mrep = nd->nd_mrep;
	md = nd->nd_md;
	dpos = nd->nd_dpos;
	if (has_header) {
D 52
		nfsm_dissect(tl, u_long *, 10*NFSX_UNSIGNED);
		nd->nd_retxid = *tl++;
E 52
I 52
		nfsm_dissect(tl, u_long *, 10 * NFSX_UNSIGNED);
		nd->nd_retxid = fxdr_unsigned(u_long, *tl++);
E 52
		if (*tl++ != rpc_call) {
			m_freem(mrep);
			return (EBADRPC);
		}
D 52
	} else {
		nfsm_dissect(tl, u_long *, 8*NFSX_UNSIGNED);
	}
E 52
I 52
	} else
		nfsm_dissect(tl, u_long *, 8 * NFSX_UNSIGNED);
E 52
	nd->nd_repstat = 0;
I 52
	nd->nd_flag = 0;
E 52
	if (*tl++ != rpc_vers) {
		nd->nd_repstat = ERPCMISMATCH;
		nd->nd_procnum = NFSPROC_NOOP;
E 25
		return (0);
I 25
	}
D 52
	nfsvers = nfs_vers;
E 52
	if (*tl != nfs_prog) {
D 52
		if (*tl == nqnfs_prog) {
E 52
I 52
		if (*tl == nqnfs_prog)
E 52
			nqnfs++;
D 52
			nfsvers = nqnfs_vers;
		} else {
E 52
I 52
		else {
E 52
			nd->nd_repstat = EPROGUNAVAIL;
			nd->nd_procnum = NFSPROC_NOOP;
			return (0);
		}
	}
	tl++;
D 52
	if (*tl++ != nfsvers) {
E 52
I 52
	nfsvers = fxdr_unsigned(u_long, *tl++);
	if (((nfsvers < NFS_VER2 || nfsvers > NFS_VER3) && !nqnfs) ||
		(nfsvers != NQNFS_VER3 && nqnfs)) {
E 52
		nd->nd_repstat = EPROGMISMATCH;
		nd->nd_procnum = NFSPROC_NOOP;
		return (0);
	}
I 52
	if (nqnfs)
		nd->nd_flag = (ND_NFSV3 | ND_NQNFS);
	else if (nfsvers == NFS_VER3)
		nd->nd_flag = ND_NFSV3;
E 52
	nd->nd_procnum = fxdr_unsigned(u_long, *tl++);
	if (nd->nd_procnum == NFSPROC_NULL)
		return (0);
	if (nd->nd_procnum >= NFS_NPROCS ||
D 52
		(!nqnfs && nd->nd_procnum > NFSPROC_STATFS) ||
		(*tl != rpc_auth_unix && *tl != rpc_auth_kerb)) {
E 52
I 52
		(!nqnfs && nd->nd_procnum >= NQNFSPROC_GETLEASE) ||
		(!nd->nd_flag && nd->nd_procnum > NFSV2PROC_STATFS)) {
E 52
		nd->nd_repstat = EPROCUNAVAIL;
		nd->nd_procnum = NFSPROC_NOOP;
		return (0);
	}
I 52
	if ((nd->nd_flag & ND_NFSV3) == 0)
		nd->nd_procnum = nfsv3_procid[nd->nd_procnum];
E 52
	auth_type = *tl++;
	len = fxdr_unsigned(int, *tl++);
	if (len < 0 || len > RPCAUTH_MAXSIZ) {
		m_freem(mrep);
		return (EBADRPC);
	}
E 25

I 52
	nd->nd_flag &= ~ND_KERBAUTH;
E 52
	/*
D 25
	 * Must do each address family separately since unused fields
	 * are undefined values and not always zeroed.
E 25
I 25
	 * Handle auth_unix or auth_kerb.
E 25
	 */
D 25
	switch (saddr1->sa_family) {
	case AF_INET:
		if (((struct sockaddr_in *)saddr1)->sin_addr.s_addr ==
		    ((struct sockaddr_in *)saddr2)->sin_addr.s_addr)
			return (1);
		break;
	default:
		break;
	};
E 25
I 25
	if (auth_type == rpc_auth_unix) {
		len = fxdr_unsigned(int, *++tl);
		if (len < 0 || len > NFS_MAXNAMLEN) {
			m_freem(mrep);
			return (EBADRPC);
		}
		nfsm_adv(nfsm_rndup(len));
D 52
		nfsm_dissect(tl, u_long *, 3*NFSX_UNSIGNED);
E 52
I 52
		nfsm_dissect(tl, u_long *, 3 * NFSX_UNSIGNED);
		bzero((caddr_t)&nd->nd_cr, sizeof (struct ucred));
		nd->nd_cr.cr_ref = 1;
E 52
		nd->nd_cr.cr_uid = fxdr_unsigned(uid_t, *tl++);
		nd->nd_cr.cr_gid = fxdr_unsigned(gid_t, *tl++);
		len = fxdr_unsigned(int, *tl);
		if (len < 0 || len > RPCAUTH_UNIXGIDS) {
			m_freem(mrep);
			return (EBADRPC);
		}
D 52
		nfsm_dissect(tl, u_long *, (len + 2)*NFSX_UNSIGNED);
E 52
I 52
		nfsm_dissect(tl, u_long *, (len + 2) * NFSX_UNSIGNED);
E 52
		for (i = 1; i <= len; i++)
D 52
			if (i < NGROUPS)
				nd->nd_cr.cr_groups[i] = fxdr_unsigned(gid_t, *tl++);
			else
				tl++;
E 52
I 52
		    if (i < NGROUPS)
			nd->nd_cr.cr_groups[i] = fxdr_unsigned(gid_t, *tl++);
		    else
			tl++;
E 52
		nd->nd_cr.cr_ngroups = (len >= NGROUPS) ? NGROUPS : (len + 1);
D 52
	} else if (auth_type == rpc_auth_kerb) {
		nd->nd_cr.cr_uid = fxdr_unsigned(uid_t, *tl++);
		nd->nd_authlen = fxdr_unsigned(int, *tl);
D 44
		iov.iov_len = uio.uio_resid = nfsm_rndup(nd->nd_authlen);
		if (uio.uio_resid > (len - 2*NFSX_UNSIGNED)) {
E 44
I 44
		uio.uio_resid = nfsm_rndup(nd->nd_authlen);
		if (uio.uio_resid > (len - 2 * NFSX_UNSIGNED)) {
E 52
I 52
		if (nd->nd_cr.cr_ngroups > 1)
		    nfsrvw_sort(nd->nd_cr.cr_groups, nd->nd_cr.cr_ngroups);
		len = fxdr_unsigned(int, *++tl);
		if (len < 0 || len > RPCAUTH_MAXSIZ) {
E 52
E 44
			m_freem(mrep);
			return (EBADRPC);
		}
D 52
		uio.uio_offset = 0;
		uio.uio_iov = &iov;
		uio.uio_iovcnt = 1;
		uio.uio_segflg = UIO_SYSSPACE;
		iov.iov_base = (caddr_t)nd->nd_authstr;
I 44
		iov.iov_len = RPCAUTH_MAXSIZ;
E 44
		nfsm_mtouio(&uio, uio.uio_resid);
D 44
		nfsm_dissect(tl, u_long *, 2*NFSX_UNSIGNED);
E 44
I 44
		nfsm_dissect(tl, u_long *, 2 * NFSX_UNSIGNED);
E 44
		nd->nd_flag |= NFSD_NEEDAUTH;
	}
E 52
I 52
		if (len > 0)
			nfsm_adv(nfsm_rndup(len));
	} else if (auth_type == rpc_auth_kerb) {
		switch (fxdr_unsigned(int, *tl++)) {
		case RPCAKN_FULLNAME:
			ticklen = fxdr_unsigned(int, *tl);
			*((u_long *)nfsd->nfsd_authstr) = *tl;
			uio.uio_resid = nfsm_rndup(ticklen) + NFSX_UNSIGNED;
			nfsd->nfsd_authlen = uio.uio_resid + NFSX_UNSIGNED;
			if (uio.uio_resid > (len - 2 * NFSX_UNSIGNED)) {
				m_freem(mrep);
				return (EBADRPC);
			}
			uio.uio_offset = 0;
			uio.uio_iov = &iov;
			uio.uio_iovcnt = 1;
			uio.uio_segflg = UIO_SYSSPACE;
			iov.iov_base = (caddr_t)&nfsd->nfsd_authstr[4];
			iov.iov_len = RPCAUTH_MAXSIZ - 4;
			nfsm_mtouio(&uio, uio.uio_resid);
			nfsm_dissect(tl, u_long *, 2 * NFSX_UNSIGNED);
			if (*tl++ != rpc_auth_kerb ||
				fxdr_unsigned(int, *tl) != 4 * NFSX_UNSIGNED) {
				printf("Bad kerb verifier\n");
				nd->nd_repstat = (NFSERR_AUTHERR|AUTH_BADVERF);
				nd->nd_procnum = NFSPROC_NOOP;
				return (0);
			}
			nfsm_dissect(cp, caddr_t, 4 * NFSX_UNSIGNED);
			tl = (u_long *)cp;
			if (fxdr_unsigned(int, *tl) != RPCAKN_FULLNAME) {
				printf("Not fullname kerb verifier\n");
				nd->nd_repstat = (NFSERR_AUTHERR|AUTH_BADVERF);
				nd->nd_procnum = NFSPROC_NOOP;
				return (0);
			}
			cp += NFSX_UNSIGNED;
			bcopy(cp, nfsd->nfsd_verfstr, 3 * NFSX_UNSIGNED);
			nfsd->nfsd_verflen = 3 * NFSX_UNSIGNED;
			nd->nd_flag |= ND_KERBFULL;
			nfsd->nfsd_flag |= NFSD_NEEDAUTH;
			break;
		case RPCAKN_NICKNAME:
			if (len != 2 * NFSX_UNSIGNED) {
				printf("Kerb nickname short\n");
				nd->nd_repstat = (NFSERR_AUTHERR|AUTH_BADCRED);
				nd->nd_procnum = NFSPROC_NOOP;
				return (0);
			}
			nickuid = fxdr_unsigned(uid_t, *tl);
			nfsm_dissect(tl, u_long *, 2 * NFSX_UNSIGNED);
			if (*tl++ != rpc_auth_kerb ||
				fxdr_unsigned(int, *tl) != 3 * NFSX_UNSIGNED) {
				printf("Kerb nick verifier bad\n");
				nd->nd_repstat = (NFSERR_AUTHERR|AUTH_BADVERF);
				nd->nd_procnum = NFSPROC_NOOP;
				return (0);
			}
			nfsm_dissect(tl, u_long *, 3 * NFSX_UNSIGNED);
			tvin.tv_sec = *tl++;
			tvin.tv_usec = *tl;
E 52

D 52
	/*
	 * Do we have any use for the verifier.
	 * According to the "Remote Procedure Call Protocol Spec." it
	 * should be AUTH_NULL, but some clients make it AUTH_UNIX?
	 * For now, just skip over it
	 */
	len = fxdr_unsigned(int, *++tl);
	if (len < 0 || len > RPCAUTH_MAXSIZ) {
		m_freem(mrep);
		return (EBADRPC);
E 52
I 52
			for (nuidp = NUIDHASH(nfsd->nfsd_slp,nickuid)->lh_first;
			    nuidp != 0; nuidp = nuidp->nu_hash.le_next) {
				if (nuidp->nu_cr.cr_uid == nickuid &&
				    (!nd->nd_nam2 ||
				     netaddr_match(NU_NETFAM(nuidp),
				      &nuidp->nu_haddr, nd->nd_nam2)))
					break;
			}
			if (!nuidp) {
				nd->nd_repstat =
					(NFSERR_AUTHERR|AUTH_REJECTCRED);
				nd->nd_procnum = NFSPROC_NOOP;
				return (0);
			}

			/*
			 * Now, decrypt the timestamp using the session key
			 * and validate it.
			 */
#ifdef NFSKERB
			XXX
#endif

			tvout.tv_sec = fxdr_unsigned(long, tvout.tv_sec);
			tvout.tv_usec = fxdr_unsigned(long, tvout.tv_usec);
			if (nuidp->nu_expire < time.tv_sec ||
			    nuidp->nu_timestamp.tv_sec > tvout.tv_sec ||
			    (nuidp->nu_timestamp.tv_sec == tvout.tv_sec &&
			     nuidp->nu_timestamp.tv_usec > tvout.tv_usec)) {
				nuidp->nu_expire = 0;
				nd->nd_repstat =
				    (NFSERR_AUTHERR|AUTH_REJECTVERF);
				nd->nd_procnum = NFSPROC_NOOP;
				return (0);
			}
			nfsrv_setcred(&nuidp->nu_cr, &nd->nd_cr);
			nd->nd_flag |= ND_KERBNICK;
		};
	} else {
		nd->nd_repstat = (NFSERR_AUTHERR | AUTH_REJECTCRED);
		nd->nd_procnum = NFSPROC_NOOP;
		return (0);
E 52
	}
D 52
	if (len > 0) {
		nfsm_adv(nfsm_rndup(len));
	}
E 52

	/*
	 * For nqnfs, get piggybacked lease request.
	 */
	if (nqnfs && nd->nd_procnum != NQNFSPROC_EVICTED) {
		nfsm_dissect(tl, u_long *, NFSX_UNSIGNED);
D 52
		nd->nd_nqlflag = fxdr_unsigned(int, *tl);
		if (nd->nd_nqlflag) {
E 52
I 52
		nd->nd_flag |= fxdr_unsigned(int, *tl);
		if (nd->nd_flag & ND_LEASE) {
E 52
			nfsm_dissect(tl, u_long *, NFSX_UNSIGNED);
			nd->nd_duration = fxdr_unsigned(int, *tl);
		} else
			nd->nd_duration = NQ_MINLEASE;
D 52
	} else {
		nd->nd_nqlflag = NQL_NOVAL;
E 52
I 52
	} else
E 52
		nd->nd_duration = NQ_MINLEASE;
D 52
	}
E 52
	nd->nd_md = md;
	nd->nd_dpos = dpos;
E 25
	return (0);
I 25
nfsmout:
	return (error);
E 25
}

/*
D 25
 * Check the hostname fields for nfsd's mask and match fields.
 * By address family:
 * - Bitwise AND the mask with the host address field
 * - Compare for == with match
 * return TRUE if not equal
E 25
I 25
 * Search for a sleeping nfsd and wake it up.
 * SIDE EFFECT: If none found, set NFSD_CHECKSLP flag, so that one of the
 * running nfsds will go look for the work in the nfssvc_sock list.
E 25
 */
D 25
nfs_badnam(nam, msk, mtch)
	register struct mbuf *nam, *msk, *mtch;
E 25
I 25
void
nfsrv_wakenfsd(slp)
	struct nfssvc_sock *slp;
E 25
{
D 25
	switch (mtod(nam, struct sockaddr *)->sa_family) {
	case AF_INET:
		return ((mtod(nam, struct sockaddr_in *)->sin_addr.s_addr &
			 mtod(msk, struct sockaddr_in *)->sin_addr.s_addr) !=
			 mtod(mtch, struct sockaddr_in *)->sin_addr.s_addr);
	default:
		printf("nfs_badmatch, unknown sa_family\n");
		return (0);
	};
E 25
I 25
D 51
	register struct nfsd *nd = nfsd_head.nd_next;
E 51
I 51
	register struct nfsd *nd;
E 51

I 26
	if ((slp->ns_flag & SLP_VALID) == 0)
		return;
E 26
D 51
	while (nd != (struct nfsd *)&nfsd_head) {
E 51
I 51
D 52
	for (nd = nfsd_head.tqh_first; nd != 0; nd = nd->nd_chain.tqe_next) {
E 51
		if (nd->nd_flag & NFSD_WAITING) {
			nd->nd_flag &= ~NFSD_WAITING;
			if (nd->nd_slp)
E 52
I 52
	for (nd = nfsd_head.tqh_first; nd != 0; nd = nd->nfsd_chain.tqe_next) {
		if (nd->nfsd_flag & NFSD_WAITING) {
			nd->nfsd_flag &= ~NFSD_WAITING;
			if (nd->nfsd_slp)
E 52
				panic("nfsd wakeup");
I 29
			slp->ns_sref++;
E 29
D 52
			nd->nd_slp = slp;
E 52
I 52
			nd->nfsd_slp = slp;
E 52
D 26
			nd->nd_sref = slp->ns_sref;
E 26
			wakeup((caddr_t)nd);
			return;
		}
D 51
		nd = nd->nd_next;
E 51
	}
I 26
	slp->ns_flag |= SLP_DOREC;
E 26
D 51
	nfsd_head.nd_flag |= NFSD_CHECKSLP;
E 51
I 51
	nfsd_head_flag |= NFSD_CHECKSLP;
E 51
}

I 52
int
E 52
nfs_msg(p, server, msg)
	struct proc *p;
	char *server, *msg;
{
	tpr_t tpr;

	if (p)
		tpr = tprintf_open(p);
	else
		tpr = NULL;
	tprintf(tpr, "nfs server %s: %s\n", server, msg);
	tprintf_close(tpr);
I 52
	return (0);
E 52
E 25
E 13
E 7
E 4
}
E 1
