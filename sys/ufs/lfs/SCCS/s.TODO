h10906
s 00000/00000/00116
d D 8.1 93/06/11 16:26:53 bostic 11 10
c 4.4BSD snapshot (revision 8.1)
e
s 00015/00000/00101
d D 5.10 92/08/02 21:48:34 bostic 10 9
c a new one.
e
s 00018/00034/00083
d D 5.9 92/08/01 15:28:25 bostic 9 8
c update for 4.4BSD-Alpha
e
s 00005/00002/00112
d D 5.8 92/07/20 16:17:02 bostic 8 7
c update
e
s 00003/00000/00111
d D 5.7 92/07/13 19:23:45 bostic 7 6
c note that next segment pointer no longer needed
e
s 00013/00003/00098
d D 5.6 92/06/22 22:26:18 bostic 6 5
c checkpoint
e
s 00015/00002/00086
d D 5.5 92/06/22 22:25:42 bostic 5 4
c checpoint
e
s 00001/00001/00087
d D 5.4 92/02/04 12:30:58 bostic 4 3
c checkpoint
e
s 00012/00009/00076
d D 5.3 92/01/18 16:25:42 bostic 3 2
c checkpoint
e
s 00008/00004/00077
d D 5.2 91/12/31 15:14:25 bostic 2 1
c update
e
s 00081/00000/00000
d D 5.1 91/12/31 15:10:25 bostic 1 0
c date and time created 91/12/31 15:10:25 by bostic
e
u
U
t
T
I 1
#	%W% (Berkeley) %G%

I 6
NOTE: Changed the lookup on a page of inodes to search from the back
in case the same inode gets written twice on the same page.

I 7
D 9
I don't think we still need the next segment pointer in the LFS summary
block. (TK)

E 9
E 7
Make sure that if you are writing a file, but not all the blocks
make it into a single segment, that you do not write the inode in
that segment.

D 9
I added a hack to vinvalbuf to check for lfs -- I believe that
vinvalbuf should be a vnode op.

E 9
E 6
D 5
TODO:  =======================

E 5
Keith:
I 5
	Why not delete the lfs_bmapv call, just mark everything dirty
		that isn't deleted/truncated?  Get some numbers about
		what percentage of the stuff that the cleaner thinks
		might be live is live.  If it's high, get rid of lfs_bmapv.
I 10

	There is a nasty problem in that it may take *more* room to write
	the data to clean a segment than is returned by the new segment
	because of indirect blocks in segment 2 being dirtied by the data
	being copied into the log from segment 1.  The suggested solution
	at this point is to detect it when we have no space left on the
	filesystem, write the extra data into the last segment (leaving
	no clean ones), make it a checkpoint and shut down the file system
	for fixing by a utility reading the raw partition.  Argument is
	that this should never happen and is practically impossible to fix
	since the cleaner would have to theoretically build a model of the
	entire filesystem in memory to detect the condition occurring.
	A file coalescing cleaner will help avoid the problem, and one
	that reads/writes from the raw disk could fix it.

E 10
D 6
	Currently, inodes are being flushed to disk synchronously upon
E 6
I 6
D 9
*	Currently, inodes are being flushed to disk synchronously upon
E 9
I 9
DONE	Currently, inodes are being flushed to disk synchronously upon
E 9
E 6
		creation -- see ufs_makeinode.  However, only the inode
		is flushed, the directory "name" is written using VOP_BWRITE,
		so it's not synchronous.  Possible solutions: 1: get some
		ordering in the writes so that inode/directory entries get
		stuffed into the same segment.  2: do both synchronously
		3: add Mendel's information into the stream so we log
		creation/deletion of inodes.  4: do some form of partial
		segment when changing the inode (creation/deletion/rename).
E 5
D 3
	XXX The problem is that the IFILE vnode isn't getting entered into
	    the vnode cache (nor is the underlying inode being placed into
	    the inode cache).  Q: Should the underlying inode be in the
	    inode cache (does it get flushed)?  Q: Should the mount code
	    update the ifile inode slot to reflect the current disk address?
E 3
I 3
D 9
	Fix i_block increment for indirect blocks.
E 9
I 9
DONE	Fix i_block increment for indirect blocks.
E 9
	If the file system is tar'd, extracted on top of another LFS, the
		IFILE ain't worth diddly.  Is the cleaner writing the IFILE?
		If not, let's make it read-only.
D 9
	Delete unnecessary source from utils in main-line source tree.
	Make sure that we're counting meta blocks in the inode i_block count.
E 9
I 9
DONE	Delete unnecessary source from utils in main-line source tree.
DONE	Make sure that we're counting meta blocks in the inode i_block count.
E 9
	Overlap the version and nextfree fields in the IFILE
D 4
	Talk to Kirk about vinvalbuf:
E 4
I 4
D 9
	Vinvalbuf (Kirk):
E 9
I 9
DONE	Vinvalbuf (Kirk):
E 9
E 4
		Why writing blocks that are no longer useful?
		Are the semantics of close such that blocks have to be flushed?
		How specify in the buf chain the blocks that don't need
		to be written?  (Different numbering of indirect blocks.)
E 3
D 2
	Make syncs reentrant.
E 2

I 2
D 3
	Move utils into main-line source.

E 3
E 2
Margo:
I 5
D 8
	Fix the use of the dinode spare field to use the generation number
		instead.
E 8
I 8
	Change so that only search one sector of inode block file for the
		inode by using sector addresses in the ifile instead of
		logical disk addresses.
	Fix the use of the ifile version field to use the generation
		number instead.
E 8
E 5
D 2
	Extend IFILE as necessary.
E 2
I 2
D 3
	See if lfs_mountfs can just call lfs_vget for IFILE vnode
		by minor hack to lfs_itod.
E 3
E 2
D 6
	Unmount; not doing a bgetvp (VHOLD) in lfs_newbuf call.
E 6
I 6
D 9
*	Unmount; not doing a bgetvp (VHOLD) in lfs_newbuf call.
E 6
D 2
	Document where the checkpoint information is.
E 2
I 2
	Document in the README file where the checkpoint information is
E 9
I 9
DONE	Unmount; not doing a bgetvp (VHOLD) in lfs_newbuf call.
DONE	Document in the README file where the checkpoint information is
E 9
		on disk.
E 2
	Variable block sizes (Margo/Keith).
	Switch the byte accounting to sector accounting.
D 9
	Check lfs.h and make sure that the #defines/structures are all
E 9
I 9
DONE	Check lfs.h and make sure that the #defines/structures are all
E 9
		actually needed.
D 6
	Add a check in lfs_segment.c so that if the segment is empty,
E 6
I 6
D 9
*	Add a check in lfs_segment.c so that if the segment is empty,
E 6
D 2
		we don't write it.
E 2
I 2
		we don't write it.  (Margo, do you remember what this
		meant?  TK)
E 9
I 9
DONE	Add a check in lfs_segment.c so that if the segment is empty,
		we don't write it.
E 9
E 2
	Need to keep vnode v_numoutput up to date for pending writes?
I 9
DONE	USENIX paper (Carl/Margo).
E 9

D 9
Carl:
E 9
I 9

Evelyn:
E 9
	lfsck:	If delete a file that's being executed, the version number
		isn't updated, and lfsck has to figure this out; case is			the same as if have an inode that no directory references,
		so the file should be reattached into lost+found.
D 9
	USENIX paper (Carl/Margo).
E 9
I 9
	Recovery/fsck.

Carl:
E 9
	Investigate: clustering of reads (if blocks in the segment are ordered,
		should read them all) and writes (McVoy paper).
	Investigate: should the access time be part of the IFILE:
		pro: theoretically, saves disk writes
		con: cacheing inodes should obviate this advantage
		     the IFILE is already humongous
	Cleaner.
D 9
	Recovery/fsck.
E 9
	Port to OSF/1 (Carl/Keith).
	Currently there's no notion of write error checking.
		+ Failed data/inode writes should be rescheduled (kernel level
		  bad blocking).
		+ Failed superblock writes should cause selection of new
		  superblock for checkpointing.

FUTURE FANTASIES: ============

D 9
+ unrm
	- versioning
E 9
I 9
+ unrm, versioning
E 9
+ transactions
D 9
+ extended cleaner policies
	- hot/cold data, data placement
E 9
I 9
+ extended cleaner policies (hot/cold data, data placement)
E 9

==============================
Problem with the concept of multiple buffer headers referencing the segment:
Positives:
	Don't lock down 1 segment per file system of physical memory.
	Don't copy from buffers to segment memory.
	Don't tie down the bus to transfer 1M.
	Works on controllers supporting less than large transfers.
	Disk can start writing immediately instead of waiting 1/2 rotation
	    and the full transfer.
Negatives:
	Have to do segment write then segment summary write, since the latter
	is what verifies that the segment is okay.  (Is there another way
	to do this?)
D 9
==============================

We don't plan on doing the DIROP log until we try to do roll-forward.
This is part of what happens if random blocks get trashed and we try to
recover, i.e. the same information that DIROP tries to provided is
required for general recovery.  I believe that we're going to need an
fsck-like tool that resolves the disk (possibly a combination of
resolution, checkpoints and checksums).  The problem is that the current
implementation does not handle the destruction of, for example, the root
inode.
E 9
==============================

The algorithm for selecting the disk addresses of the super-blocks
has to be available to the user program which checks the file system.

(Currently in newfs, becomes a common subroutine.)
E 1
